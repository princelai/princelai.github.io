{"pages":[{"title":"关于我","text":"还没写任何东西","tags":"pages","url":"https://www.solarck.com/pages/aboutme.html"},{"title":"简历","text":"还没制作","tags":"pages","url":"https://www.solarck.com/pages/resume.html"},{"title":"tshark常用命令详解","text":"Wireshark简介 Wireshark 是一款免费开源的包分析器。可用于网络排错、网络分析、软件和通讯协议开发以及教学等。tshark是wireshark的cli版本 安装 Archlinux yaourt -Syu wireshark-cli Debian apt-get update apt-get install tshark 查看权限 $ getcap /usr/bin/dumpcap /usr/bin/dumpcap = cap_net_admin,cap_net_raw+eip dumpcap的位置也可能在 /usr/sbin/dumpcap ，如果输出结果不像上面那样，则还需要设置权限 # setcap 'CAP_NET_RAW+eip CAP_NET_ADMIN+eip' /usr/sbin/dumpcap 把用户添加至wireshark用户组 # gpasswd -a username wireshark 切换至新用户组 $ newgrp wireshark 查看http请求1 tshark -i em1 -n -Y http.request -T fields -e \"ip.src\" -e \"http.request.method\" -e \"http.request.uri\" 参数 -i ：网络设备名，默认为第一个非环路设备，可用 ip link 或 ifconfig 查看 -n ：禁止域名解析，显示原始IP地址 -Y ：显示过滤，使用Wireshark display filter语法，通常用于后接单一过滤器；查看过滤语法， DisplayFilters ， CheatSheet -T ：文本输出格式 -e ：输出Fields的某一字段 输出结果 117.136.0.189 POST /api/anonymous/notice/new 119.123.197.16 POST /web/wechat/login 113.120.250.84 POST /api/projectlib/detail 113.120.250.84 POST /api/projectlib/getProjectFile 113.120.250.84 POST /api/projectlib/getBasicProject 113.120.250.84 POST /api/projectlib/getGuessProjectList 113.120.250.84 POST /api/projectcomment/commentlist 119.123.197.16 POST /web/wechat/login 查看http请求2 tshark -i em1 -f 'tcp dst port 80 and src host 111.207.128.226' -R 'http.host and http.request.uri' -T fields -e http.request.uri -e http.user_agent 参数 -f ：包过滤，使用libpcap filter语法；查看过滤语法， CaptureFilters -R ：显示过滤，使用Wireshark display filter语法，通常用于后接多个过滤器；查看过滤语法， DisplayFilters ， CheatSheet 输出结果 /api/projectlib/getProvincelist290 okhttp/3.3.1 /api/projectlib/findBaseDataInfo okhttp/3.3.1 /api/corpinvestor/getInvestorCity okhttp/3.3.1 /api/advertisement/splashScreen okhttp/3.3.1 /api/commons/check okhttp/3.3.1 /api/userinfo/getPending okhttp/3.3.1 /api/index/getIndexCard okhttp/3.3.1 /api/myinvest/checkPrefer okhttp/3.3.1 /api/index/450/indexInfo okhttp/3.3.1 /api/chat/list okhttp/3.3.1 /api/employee/getMyInfomsgNew okhttp/3.3.1 /api/index/getTopNewsList okhttp/3.3.1 /api/anonymous/list okhttp/3.3.1 /api/anonymous/notice/new okhttp/3.3.1 查看DNS包 tshark -n -f \"dst port 53\" -T fields -e dns.qry.name -e dns.resp.addr 上面是老版本的写法，如果提示无效的过滤器 dns.resp.addr ，可以使用下面的新版命令 tshark -n -f \"dst port 53\" -T fields -e dns.qry.name -e dns.a 输出结果 lightcone.jd.com 211.151.10.150,123.126.36.173 logo.clearbit.com 52.85.82.40,52.85.82.50,52.85.82.241,52.85.82.178 lightcone.jd.com 211.151.10.150,123.126.36.173 www.ipip.net 180.97.158.241 logo.clearbit.com 54.230.147.88,54.230.147.109,54.230.147.76,54.230.147.126 cloud.mongodb.com 18.210.185.2 统计http包 tshark -f \"tcp port 80 or port 443 and host 58.68.234.140\" -n -q -z http,stat, -z http,tree 参数 -q ：只有在抓包结束后才显示结果，通常用于统计 -z ：统计变量，可以使用 tshark -z help 查看 输出结果 2249 packets captured =================================================================== HTTP/Packet Counter value rate percent ------------------------------------------------------------------- Total HTTP Packets 350 0.000077 HTTP Request Packets 175 0.000038 50.00% POST 172 0.000038 98.29% GET 3 0.000001 1.71% HTTP Response Packets 174 0.000038 49.71% ???: broken 0 0.000000 0.00% 1xx: Informational 0 0.000000 0.00% 2xx: Success 174 0.000038 100.00% 200 OK 174 0.000038 100.00% 3xx: Redirection 0 0.000000 0.00% 4xx: Client Error 0 0.000000 0.00% 5xx: Server Error 0 0.000000 0.00% Other HTTP Packets 1 0.000000 0.29% =================================================================== =================================================================== HTTP Statistics * HTTP Status Codes in reply packets HTTP 200 OK * List of HTTP Request methods POST 172 GET 3 ===================================================================","tags":"IT笔记","url":"https://www.solarck.com/tshark-freq-cmd.html"},{"title":"充值卡折现价值分析","text":"前几天，媳妇把收到的一条短信转给我，问我值不值，我的第一反应当然是不值，这种预存方式都是欺负不懂时间价值的人玩的把戏。为了说服她，特地手算折现，但是发现，嗯？好像还是挺值的啊。于是就有了这篇文章，把计算的完整思路和代码贴出来。 注：计算全部使用年华利率按月折现 求真正价值的思路很简单， 真实价值 = 充值卡的标称价值向后折现再折回 \\(T_0\\) - 付出的价格按类似年金的方式收息后把总利息折回 \\(T_0\\) 时刻 代码如下： def calculate_value ( month_after_use , year_yield , price , value , printlog = True ): cash_flow = value / 12 def discount (): fv = sum ( cash_flow * ( 1 + year_yield ) ** ( y / 12 ) for y in range ( 1 , 12 + 1 )) return fv / ( 1 + year_yield ) ** ( month_after_use / 12 ) def interest (): balance = [ price - price / month_after_use * n for n in range ( 1 , int ( month_after_use ) + 1 ) ] return sum ( b * (( 1 + year_yield ) ** ( 1 / month_after_use ) - 1 ) for b in balance ) def real_value (): if month_after_use >= 12 : total_i = interest () else : print ( 'Month afer use must great than 12.' ) exit pv = discount () return pv , total_i pv , total_i = real_value () real = pv - total_i profit = real - price if printlog : print ( f 'real value is {real:.2f}.({pv:.2f} - {total_i:.2f})' ) print ( f 'You earn {profit:.1f} YUAN.' if profit > 0 else f 'You loss {-profit:.1f} YUAN.' ) else : return profit 假设我办理 12000 套餐，24 个月用完，折现利率（市场利率）年化 4%，模拟一下最后的收益，竟然是赚了 738 元！ calculate_value(24, 0.04, 10400, 12000) real value is 11138.01.(11333.62 - 195.61) You earn 738.0 YUAN. 那么是不是办理了就一定稳赚不赔呢？这就要用到 Scipy 中的最优化函数找一找结果。 首先要导入需要用的包 from functools import partial from scipy.optimize import minimize 用偏导函数固定住不变化的参数，lambda 函数用于方便传参 partial_func = partial ( calculate_value , price = 10400 , value = 12000 , printlog = False ) func = lambda x : partial_func ( * x ) 如果是要固定住三个参数，需要传的参数不在第一位，可以用这种方式创建一个偏导函数 partial_func = partial ( lambda a , b , c , d : calculate_value ( b , a , c , d ), b = 24 , c = 10400 , d = 12000 ) 函数初始在 18 个月，利率 4%，边界定在 12-36 个月，3%-6%年化利率。因为最优化函数求的是最小值，我们要求的是最大值，所以还对函数的符号进行改变。 x0 = ( 18 , 0.04 ) bnds = (( 12 , 36 ), ( 0.03 , 0.06 )) res = minimize ( lambda y : - 1 * func (( y [ 0 ], y [ 1 ])), x0 , method = 'SLSQP' , bounds = bnds ) 查看结果，寻找最优解失败，猜想一下，这个函数应该不是凸函数，函数边界为（ - \\(\\infty\\) , + \\(\\infty\\) ），但在我们给定的范围内，结果停留在了 12 个月，3%年化利率，也就是说越快把充值的钱用完、同时你的资金获得的市场利率越低越有利。 print(res) fun: -1297.8802495375876 jac: array([ 31.28442383, 9879.27038574]) message: 'Positive directional derivative for linesearch' nfev: 16 nit: 8 njev: 4 status: 8 success: False x: array([12. , 0.03]) 说了这么多，还是很抽象，不如画出来容易理解。 我使用 matplotlib 的 3D 图，需要导入相关的包 import numpy as np from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.ticker import FormatStrFormatter 利用上面的偏导后 func 函数计算出三个轴的数据 X = np . arange ( 12 , 36 + 1 ) Y = np . round ( np . linspace ( 3 , 6 , len ( X )), 4 ) loss_list = [] for i in range ( 12 , 36 + 1 ): loss_list . append ( [ func (( i , j / 100 )) for j in np . round ( np . linspace ( 3 , 6 , len ( X )), 4 )]) X , Y = np . meshgrid ( X , Y ) Z = np . array ( loss_list ) 最后 plot 出来并做一些美化 fig = plt . figure ( figsize = ( 16 , 12 ), dpi = 100 ) ax = fig . gca ( projection = '3d' ) surf = ax . plot_surface ( X , Y , Z , cmap = cm . rainbow , linewidth = 0 , antialiased = True ) ax . set_xlabel ( 'Month' ) ax . set_ylabel ( 'Yield' ) ax . set_zlabel ( 'Profit' ) ax . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.2f%% ' )) fig . colorbar ( surf , shrink = 0.5 , aspect = 5 ) plt . tight_layout () plt . show () 三维空间的一个平面，其实就是二维空间的一条直线，收益曲线确实不是一个凸函数。找不到最优解实属正常。但是总的来说，这个充值卡还是很值得办理的，在当前 4%的平均利率水平下，他们又不限制使用车辆，所以可以足够快的用完。 最后，虽然这篇文章看起来像个软广，但是我真的不认识发信息的人。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"金融笔记","url":"https://www.solarck.com/gift-card-discount-value.html"},{"title":"升级 Openwrt/ LEDE 大版本至 18.06","text":"下载升级包 首先下载新版文件，点击下方链接中任意一个，进入你的路由器架构，然后搜索路由器型号，如果你已经是 Openwrt/ LEDE 系统，可以下载升级包*-squashfs-sysupgrade.bin，如果不是，则要下载完整安装包*-squashfs-factory.img。 官方下载 中科大 清华大学 备份 & 更新 下载好文件后，进入路由器 Luci 界面，System —-> Backup / Flash Firmware 建议先备份一份配置到本地，备份好后，上传文件，开刷！等待路由器重启后进入后面的步骤。 更新源 关于详细的如何更换源操作，我在 LEDE /OpenWRT 路由器打造家庭媒体影音中心（一） 中有写，这里仅给出自定义源文件的内容。 vim /etc/opkg/customfeeds.conf #Tsinghua src/gz reboot_core https://mirrors.tuna.tsinghua.edu.cn/lede/releases/18.06.0/targets/mvebu/cortexa9/packages src/gz reboot_base https://mirrors.tuna.tsinghua.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/base src/gz reboot_luci https://mirrors.tuna.tsinghua.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/luci src/gz reboot_packages https://mirrors.tuna.tsinghua.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/packages src/gz reboot_routing https://mirrors.tuna.tsinghua.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/routing src/gz reboot_telephony https://mirrors.tuna.tsinghua.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/telephony #USTC #src/gz reboot_core https://mirrors.ustc.edu.cn/lede/releases/18.06.0/targets/mvebu/cortexa9/packages #src/gz reboot_base https://mirrors.ustc.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/base #src/gz reboot_luci https://mirrors.ustc.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/luci #src/gz reboot_packages https://mirrors.ustc.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/packages #src/gz reboot_routing https://mirrors.ustc.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/routing #src/gz reboot_telephony https://mirrors.ustc.edu.cn/lede/releases/18.06.0/packages/arm_cortex-a9_vfpv3/telephony #shadowsocks src/gz openwrt_dist http://openwrt-dist.sourceforge.net/packages/base/arm_cortex-a9_vfpv3 src/gz openwrt_dist_luci http://openwrt-dist.sourceforge.net/packages/luci 改好源后，可以使用下面的命令更新软件 opkg update opkg list-upgradable | cut -f 1 -d ' ' | xargs opkg upgrade 一个无聊的脚本 整个过程到上面就已经结束了，不过本着继(凑)续(字)深(数)挖的态度，花点时间写了个 python 脚本，用来分析所有 ipk 包的升级情况。对了，写这个脚本的时候还发现有个源网址改变了，所以写自定义源的时候一定要注意。 #!/usr/bin/env python3 # -*- coding: utf-8 -*- \"\"\" Created on Tue Jul 31 14:40:26 2018 @author: kevin \"\"\" from requests_html import HTMLSession from collections import defaultdict web_main = [ 'http://downloads.lede-project.org/releases/17.01.5' , 'http://downloads.lede-project.org/releases/18.06.0' ] web_packages = [( '/targets/mvebu/generic/packages/' , '/targets/mvebu/cortexa9/packages/' ), '/packages/arm_cortex-a9_vfpv3/base' , '/packages/arm_cortex-a9_vfpv3/luci' , '/packages/arm_cortex-a9_vfpv3/packages' , '/packages/arm_cortex-a9_vfpv3/routing' , '/packages/arm_cortex-a9_vfpv3/telephony' ] d = defaultdict ( list ) for pack in web_packages : for i , main in enumerate ( web_main ): if isinstance ( pack , tuple ): website = main + pack [ i ] else : website = main + pack session = HTMLSession () resp = session . get ( website , timeout = 10 ) td = resp . html . find ( 'body > table > tr > td > a' ) ispackages = [ elem . text for elem in td if elem . text . endswith ( '.ipk' )] for p in ispackages : packname , version , * _ = p . split ( '_' ) d [ packname ] . append ( version ) output_str = [] for k , v in d . items (): if len ( v ) == 1 : output_str . append ( 'New Add: \\t {}' . format ( k )) elif v [ 0 ] != v [ 1 ]: output_str . append ( 'Version Up: \\t {}|{} --> {}' . format ( k , v [ 0 ], v [ 1 ])) else : pass with open ( 'lede_upgrade.txt' , 'w' ) as f : f . write ( ' \\n ' . join ( output_str )) 写完这个脚本才发现有个 bug，~~但是我懒得改了~~，我忽略了在两个版本的相同 packages 包中，一个有某软件包一个没有的情况，也就是说输出文件的 New Add 不是真正的新增，还有被剔除的包。 两个版本相同源地址的软件包共 6473 个，本次升级有版本升级、新增、剔除的包一共 5665 个，可见大部分还都是进行了例行的升级。 $ cat lede_upgrade.txt | grep \"New Add\" | wc -l 2180 新增、剔除的包共 2180 个，具体那个是新增哪个是剔除我没有区分出来。 $ cat lede_upgrade.txt | grep \"Version Up\" | wc -l 3485 版本升级的包有 3485 个，这两项加起来正好 5665 个。 由于版本号的命名十分不规则，本来还想弄个大版本号、次版本号、小版本号的对比，无奈最终还是搁浅了。","tags":"IT 笔记","url":"https://www.solarck.com/upgrade-lede-to-1806.html"},{"title":"编译 Tensorflow 1.10 + CUDA9 .2 + MKL","text":"我的电脑系统是基于 Archlinux 的 Manjaro，软件包更新的比较激进，很早就已经是 CUDA 9.2 了，而目前 Tensorflow 的官方编译版本对 CUDA 的支持还只停留在 CUDA 9.0。由于还不太会用 mxnet 和 pytorch，这时倍加想念 Keras 的简单。最近忙里偷闲研究了一下编译安装 Tensorflow，发现还挺简单的，把成功的喜悦分享出来，也供有需要的朋友参考。 查看系统信息 查看系统架构和发行版本 我用的 Manjaro x86_64 uname -m && cat /etc/*release x86_64 Manjaro Linux DISTRIB_ID=ManjaroLinux DISTRIB_RELEASE=17.1.11 DISTRIB_CODENAME=Hakoila DISTRIB_DESCRIPTION=\"Manjaro Linux\" Manjaro Linux NAME=\"Manjaro Linux\" ID=manjaro PRETTY_NAME=\"Manjaro Linux\" ANSI_COLOR=\"1;32\" HOME_URL=\"https://www.manjaro.org/\" SUPPORT_URL=\"https://www.manjaro.org/\" BUG_REPORT_URL=\"https://bugs.manjaro.org/\" 查看 CPU 支持的指令集 嗯，这个貌似没什么用 cat /proc/cpuinfo |grep -m1 flags |cut -f2 -d\":\" fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap intel_pt xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts 查看 Python 环境 我用 Anaconda 构建的虚拟环境，Python 3.6.6。这里要注意记住 base environment 环境路径。 conda info active environment : None user config file : /home/kevin/.condarc populated config files : /home/kevin/.condarc conda version : 4.5.8 conda-build version : 3.12.0 python version : 3.6.6.final.0 base environment : /opt/Anaconda3 (writable) channel URLs : https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64 https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/noarch https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/linux-64 https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/noarch https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/linux-64 https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/noarch package cache : /opt/Anaconda3/pkgs /home/kevin/.conda/pkgs envs directories : /opt/Anaconda3/envs /home/kevin/.conda/envs platform : linux-64 user-agent : conda/4.5.8 requests/2.19.1 CPython/3.6.6 Linux/4.18.0-1-MANJARO manjaro/17.1.11 glibc/2.27 UID:GID : 1000:1000 netrc file : None offline mode : False 查看 GPU 信息 如果你执行不了下面这个命令，那么证明你的驱动装的有问题，要用闭源的 Nvidia 驱动，不要用开源的。Manjaro 安装驱动太简单了，就不详细说了。 其次你还要去 CUDA GPU 根据显卡型号查询你 GPU 的算力，这个算力后面会用到。如果你的显卡是 Nvidia 1000 系列，且型号大于 1050，那么算力就是 6.1。 nvidia-smi +-----------------------------------------------------------------------------+ | NVIDIA-SMI 396.45 Driver Version: 396.45 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 108... Off | 00000000:03:00.0 On | N/A | | 0% 59C P5 26W / 250W | 672MiB / 11170MiB | 3% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 625 G /usr/lib/xorg-server/Xorg 370MiB | | 0 3527 G /usr/bin/kwin_x11 53MiB | | 0 3569 G /usr/bin/krunner 2MiB | | 0 3573 G /usr/bin/plasmashell 99MiB | | 0 6489 G ...-token=3E0EB0339C426519FCEB41A77A4FE74E 75MiB | | 0 9846 G /opt/Anaconda3/bin/python 28MiB | | 0 13026 G ...-token=F6A861CA29AB37BD6D50C064EC6A95F0 40MiB | +-----------------------------------------------------------------------------+ 安装编译依赖 安装显卡相关依赖 yaourt -S --needed linux418-nvidia cuda cudnn 安装好之后你还需要记住 cuDNN 的版本和路径 yaourt -Ql cudnn |grep libcudnn.so cudnn /opt/cuda/lib64/libcudnn.so cudnn /opt/cuda/lib64/libcudnn.so.7 cudnn /opt/cuda/lib64/libcudnn.so.7.1.4 一般来说 CUDA 和 cuDNN 的动态链接库文件都在同一个路径下，版本的话，自己安装的什么版本心里没点 B 数吗？ yaourt -Ql cuda |grep libcudart.so cuda /opt/cuda/lib64/libcudart.so cuda /opt/cuda/lib64/libcudart.so.9.2 cuda /opt/cuda/lib64/libcudart.so.9.2.148 cuda /usr/share/man/man7/libcudart.so.7.gz 你还应该确认 CUDA 、cuDNN、Python 的执行文件路径或库文件路径已经加入到了 $PATH 变量中 echo $PATH /opt/bin:/opt/cuda/bin:/opt/Anaconda3/bin:/opt/android-sdk/platform-tools:/opt/android-sdk/tools:/opt/android-sdk/tools/bin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/usr/local/sbin:/usr/local/bin:/usr/bin:/opt/android-sdk/platform-tools:/opt/android-sdk/tools:/opt/android-sdk/tools/bin:/opt/cuda/bin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl 安装编译工具 Tensorflow 需要使用 bazel 构建，gcc7 编译，当前我的系统 gcc 版本是 8.1 我已经帮你试过了，Tensorflow 不允许 gcc 版本高于 7。 yaourt -S bazel gcc7 gcc7-libs 下载源码 git clone https://github.com/tensorflow/tensorflow 选择安装版本 当前稳定版本为 1.9，1.10 处于 rc2 阶段，编译哪个版本自己选择。 cd tensorflow git checkout r1.10 编译安装 编译配置 如没有特殊要求，按照我的选择就可以，注意路径要换成自己的。 $ . / configure Extracting Bazel installation ... WARNING : -- batch mode is deprecated . Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\" . You have bazel 0.15.1 - (@ non - git ) installed . Please specify the location of python . [ Default is / opt / Anaconda3 / bin / python ] : Found possible Python library paths : / opt / Anaconda3 / lib / python3 .6 / site - packages Please input the desired Python library path to use . Default is [ / opt / Anaconda3 / lib / python3 .6 / site - packages ] Do you wish to build TensorFlow with jemalloc as malloc support ? [ Y / n ] : jemalloc as malloc support will be enabled for TensorFlow . Do you wish to build TensorFlow with Google Cloud Platform support ? [ Y / n ] : n No Google Cloud Platform support will be enabled for TensorFlow . Do you wish to build TensorFlow with Hadoop File System support ? [ Y / n ] : n No Hadoop File System support will be enabled for TensorFlow . Do you wish to build TensorFlow with Amazon AWS Platform support ? [ Y / n ] : n No Amazon AWS Platform support will be enabled for TensorFlow . Do you wish to build TensorFlow with Apache Kafka Platform support ? [ Y / n ] : n No Apache Kafka Platform support will be enabled for TensorFlow . Do you wish to build TensorFlow with XLA JIT support ? [ y / N ] : No XLA JIT support will be enabled for TensorFlow . Do you wish to build TensorFlow with GDR support ? [ y / N ] : No GDR support will be enabled for TensorFlow . Do you wish to build TensorFlow with VERBS support ? [ y / N ] : No VERBS support will be enabled for TensorFlow . Do you wish to build TensorFlow with OpenCL SYCL support ? [ y / N ] : No OpenCL SYCL support will be enabled for TensorFlow . Do you wish to build TensorFlow with CUDA support ? [ y / N ] : y CUDA support will be enabled for TensorFlow . Please specify the CUDA SDK version you want to use . [ Leave empty to default to CUDA 9.0 ] : 9.2 Please specify the location where CUDA 9.2 toolkit is installed . Refer to README . md for more details . [ Default is / opt / cuda ] : Please specify the cuDNN version you want to use . [ Leave empty to default to cuDNN 7.0 ] : 7 Please specify the location where cuDNN 7 library is installed . Refer to README . md for more details . [ Default is / opt / cuda ] : Do you wish to build TensorFlow with TensorRT support ? [ y / N ] : No TensorRT support will be enabled for TensorFlow . Please specify the NCCL version you want to use . If NCCL 2.2 is not installed , then you can use version 1.3 that can be fetched automatically but it may have worse performance with multiple GPUs . [ Default is 2.2 ] : 1.3 Please specify a list of comma - separated Cuda compute capabilities you want to build with . You can find the compute capability of your device at : https : //developer.nvidia.com/cuda-gpus. Please note that each additional compute capability significantly increases your build time and binary size . [ Default is : 6.1 ] Do you want to use clang as CUDA compiler ? [ y / N ] : nvcc will be used as CUDA compiler . Please specify which gcc should be used by nvcc as the host compiler . [ Default is / usr / bin / gcc - 7 ] : Do you wish to build TensorFlow with MPI support ? [ y / N ] : No MPI support will be enabled for TensorFlow . Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [ Default is - march = native ] : Would you like to interactively configure . / WORKSPACE for Android builds ? [ y / N ] : Not configuring the WORKSPACE for Android builds . Preconfigured Bazel build configs . You can use any of the below by adding \"--config=<>\" to your build command . See tools / bazel . rc for more details . -- config = mkl # Build with MKL support . -- config = monolithic # Config for mostly static monolithic build . Configuration finished 开始编译 --config=mkl 可以选择不添加，Intel CPU 加了也没什么坏处。 bazel build --config=opt --config=cuda --config=mkl //tensorflow/tools/pip_package:build_pip_package 最终耗时 50 分钟编译完成 INFO : Elapsed time : 3049.910 s , Critical Path : 248.40 s INFO : 8105 processes : 8105 local . INFO : Build completed successfully , 8292 total actions 导出为 wheel 文件 $ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg $ ls -lh /tmp/tensorflow_pkg -rw-r--r-- 1 kevin kevin 135M Jul 30 14 :03 tensorflow-1.10.0rc1-cp36-cp36m-linux_x86_64.whl pip 安装 pip install /tmp/tensorflow_pkg/tensorflow-1.10.0rc1-cp36-cp36m-linux_x86_64.whl 测试 安装好之后，可以通过下面两种不同的方法查看是否已经开启了 GPU 。 方法一 import tensorflow as tf with tf . device ( '/gpu:0' ): a = tf . constant ([ 1.0 , 2.0 , 3.0 , 4.0 , 5.0 , 6.0 ], shape = [ 2 , 3 ], name = 'a' ) b = tf . constant ([ 1.0 , 2.0 , 3.0 , 4.0 , 5.0 , 6.0 ], shape = [ 3 , 2 ], name = 'b' ) c = tf . matmul ( a , b ) sess = tf . Session ( config = tf . ConfigProto ( log_device_placement = True )) print ( sess . run ( c )) 方法二 if tf . test . gpu_device_name (): print ( 'Default GPU Device: {}' . format ( tf . test . gpu_device_name ())) else : print ( \"Please install GPU version of TF\" ) 参考 从源代码安装 TensorFlow","tags":"IT 笔记","url":"https://www.solarck.com/compile-tensorflow-gpu.html"},{"title":"解决 Haproxy 用 Systemd 启动失败的问题","text":"问题描述 配置好 Haproxy 的配置文件，手动可以无错误开启，但是 Systemctl enable haproxy.service 开机启动每次都报错，系统启动后，手动开启还是没有问题。 分析原因 haproxy 配置问题 /etc/haproxy.cfg 是配置文件，因为手动指定配合文件可以启动，而且测试配置文件也没有报错或警报，所以首先排除是配置的问题。 systemd 服务配置问题 haproxy.service 是 systemd 用来启动服务的配置文件，第一眼看配置后，以为是创建 PID 没有权限，增加 User=root 字段，但是重启后依然报错。原版配置只有 After=network.target ，手动添加 Wants=network.target 重启后，依然报错。 查看日志 正要灰心的时候，决定最后一搏，查看 systemd 启动日志，看看能不能找到点线索。 查看最近一次启动中 haproxy 的日志 journalctl -b -0 -u haproxy Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : haproxy.service: Main process exited, code = exited, status = 1 /FAILURE Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : haproxy.service: Failed with result 'exit-code' . Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : Failed to start HAProxy Load Balancer. Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : haproxy.service: Service RestartSec = 100ms expired, scheduling restart. Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : haproxy.service: Scheduled restart job, restart counter is at 1 . Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : Stopped HAProxy Load Balancer. Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : Starting HAProxy Load Balancer... Jul 13 10 :32:20 kevin-pc haproxy [ 554 ] : [ ALERT ] 193 /103220 ( 554 ) : parsing [ /etc/haproxy/haproxy.cfg:36 ] : 'server server1' : could not resolve address 'xxxx.com' . Jul 13 10 :32:20 kevin-pc haproxy [ 554 ] : [ ALERT ] 193 /103220 ( 554 ) : parsing [ /etc/haproxy/haproxy.cfg:37 ] : 'server server2' : could not resolve address 'xxxx.com' . Jul 13 10 :32:20 kevin-pc haproxy [ 554 ] : [ ALERT ] 193 /103220 ( 554 ) : parsing [ /etc/haproxy/haproxy.cfg:38 ] : 'server server3' : could not resolve address 'xxxx.com' . 原因找到了，原来是我在 haproxy 配置文件的 backend 段中，使用了域名而不是 IP ，导致解析失败。但是明明我已经指定了 haproxy 的启动在 network 之后了，为什么还是会这个样子呢？ 答案只能从 network 的服务中找 journalctl -b -0 -u NetworkManager Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2279 ] dhcp4 ( enp0s25 ) : activation: beginning transaction ( timeout in 45 seconds ) Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2566 ] dhcp4 ( enp0s25 ) : address 172 .168.201.33 Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2566 ] dhcp4 ( enp0s25 ) : plen 24 Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2566 ] dhcp4 ( enp0s25 ) : expires in 86400 seconds Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2567 ] dhcp4 ( enp0s25 ) : nameserver '172.168.13.100' Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2567 ] dhcp4 ( enp0s25 ) : nameserver '202.106.0.20' Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2567 ] dhcp4 ( enp0s25 ) : gateway 172 .168.201.1 对比两段日志的时间，原来虽然 haproxy 启动在 network 之后，但是 network 刚刚启动 haproxy 就开始启动，而 network 的启动内容比较多，还有很多网络通信，可能完全启动完需要一点时间。haproxy 的启动时间比 dhcp 启动要早了 2 秒，这时无法进行 DNS 解析，所以就会造成启动失败，之前的所有问题也都说的通了。 解决方法 知道了问题的原因，那么就要解决它。只要让 haproxy 在 network 完全启动后再启动，就应该可以正常启动了。那么如何做呢？ 首先要替换 haproxy.service 中的 After 和 Wants 字段，用 network-online.target 替换 network.target After = network-online.target Wants = network-online.target 然后启动一个自带的网络等待服务 sudo systemctl enable NetworkManager-wait-online.service 如果你是使用 systemd-network 来管理网络服务，那么需要启动另外一个服务 sudo systemctl enable systemd-networkd-wait-online.service 重启后，一切问题都解决了。 参考 Running Services After the Network is up","tags":"IT 笔记","url":"https://www.solarck.com/systemd-wait-network-online.html"},{"title":"快速配置V2ray","text":"服务器端配置 服务器系统使用的是Debian 9 x86_64，Ubuntu大部分操作都通用。如果是CentOS的话，该文章仅作为参考。 优化网络 主要涉及bbr的安装配置，需要VPS是KVM架构，具体可以参照 之前的文章 。 安装V2ray 官方提供了安装脚本，需要系统使用systemd管理系统 wget https://install.direct/go.sh bash go.sh 安装好后，主要文件如下： /etc/systemd/system/v2ray.service ：启动服务 /etc/v2ray/config.json ：配置文件 /usr/bin/v2ray/v2ray ：主程序 TLS域名证书 因为最终配置要用到TLS链接，在这步之前，你需要一个域名，免费的也无所谓。 工具使用 acme.sh ，这是用来签发 Let's Encrypt 免费证书的脚本，非常好用。 安装acme 安装依赖工具 apt-get install -y socat netcat 安装acme.sh脚本 curl https://get.acme.sh | sh 默认是安装在 ～/.acme.sh/ 签发证书 我使用的是ecc证书，需要把domain换成自己的域名 ~/.acme.sh/acme.sh --issue -d domain --standalone -k ec-256 安装证书 证书会被安装到 /etc/v2ray 目录下 ~/.acme.sh/acme.sh --installcert -d domain --fullchainpath /etc/v2ray/v2ray.crt --keypath /etc/v2ray/v2ray.key --ecc 证书续期 执行完签发命令后，系统已经加上了crond自动签发，如果你想手动签发，可以执行下面的命令。 ~/.acme.sh/acme.sh --renew -d domain --force --ecc 本地配置 安装 因为我使用的是Manjaro，一个基于Archlinux的Linux版本，所有安装只要一条命令 yaourt -Sy v2ray 如果你用的是其他系统，可以参考服务器的安装脚本。 配置文件 配置说明 我当前使用的连接方式是TCP+TLS这种，根据官方和网上收集的信息，据说当前最好的配置是WebSocket+ WEB + TLS + CDN ，我没有选择这种连接方式有以下几点原因： Websocket效率低于TCP 多层转发导致速度可能会变慢 配置较麻烦 如果你的ISP没有QOS，没有TCP阻断，你连接服务器的流量没有很大的话，是没有必要折腾这种连接方式的。当然我在写这篇文章之前还使用过H2+TLS的连接方式，但是不知是服务器没有加Caddy转发还是H2方式不稳定，断流严重，换成TCP+TLS后，连接稳定，速度尚可，未出现断流。 每个人每个地区的ISP情况不尽相同，所以多试才能找到最适合你的配置，更多配置可以参考 配置模板 。 TCP +TLS配置 配置说明 我有三台性能较弱的VPS，所以三台分别安装并部署了服务端的配置，而在本地客户端的outbound中连接三个服务器，v2ray可以进行简单的轮寻进行负载均衡。 为了简化操作，UUID设置为相同，当然不嫌麻烦的话可以设置为不同，但要和每台服务器的UUID相对应。 因为我认为vmess协议加密已经足够强壮，所以每台就没有再设置内容加密，如果不放心，可以使用auto或者AEAD方式加密。另外根据官方的测试，貌似 aes-256-gcm 和 chacha20-ietf-poly1305 两种加密方式传输效率比不加密的效率还要高，可能与硬件加密有关系吧。 所有配置的详细内容都可以在官方文档或白话文教程里找到，其实配置v2ray并没有那么复杂。 最后贴上我的自用配置，生成UUID可以使用 UUID Generator 这个网站，或者Linux用户可以使用下面命令 cat /proc/sys/kernel/random/uuid 生成。 服务端 { \"log\" : { \"loglevel\" : \"warning\" , \"access\" : \"/var/log/v2ray/access.log\" , \"error\" : \"/var/log/v2ray/error.log\" }, \"inbound\" : { \"port\" : 443 , \"protocol\" : \"vmess\" , \"settings\" : { \"clients\" : [ { \"id\" : \"xxxxxxxxx-xxxxxxxxxxx-xxxxxx\" , \"alterId\" : 32 , \"security\" : \"none\" , \"udp\" : true } ] }, \"streamSettings\" : { \"network\" : \"tcp\" , \"security\" : \"tls\" , \"tlsSettings\" : { \"certificates\" : [ { \"certificateFile\" : \"/etc/v2ray/v2ray.crt\" , \"keyFile\" : \"/etc/v2ray/v2ray.key\" } ] } } }, \"outbound\" : { \"protocol\" : \"freedom\" , \"settings\" : {} }, \"outboundDetour\" : [ { \"protocol\" : \"blackhole\" , \"settings\" : {}, \"tag\" : \"blocked\" } ], \"routing\" : { \"strategy\" : \"rules\" , \"settings\" : { \"rules\" : [ { \"type\" : \"field\" , \"ip\" : [ \"geoip:private\" ], \"outboundTag\" : \"blocked\" } ] } } } 客户端 { \"log\" : { \"loglevel\" : \"warning\" , \"access\" : \"/var/log/v2ray/access.log\" , \"error\" : \"/var/log/v2ray/error.log\" }, \"inbound\" : { \"port\" : 1080 , \"protocol\" : \"socks\" , \"domainOverride\" : [ \"tls\" , \"http\" ], \"settings\" : { \"auth\" : \"noauth\" , \"udp\" : true } }, \"outbound\" : { \"protocol\" : \"vmess\" , \"settings\" : { \"vnext\" : [ { \"address\" : \"domain.com\" , \"port\" : 443 , \"users\" : [ { \"id\" : \"xxxxxxxxx-xxxxxxxxxxx-xxxxxx\" , \"alterId\" : 32 , \"security\" : \"none\" } ] }, { \"address\" : \"domain.com\" , \"port\" : 443 , \"users\" : [ { \"id\" : \"xxxxxxxxx-xxxxxxxxxxx-xxxxxx\" , \"alterId\" : 32 , \"security\" : \"none\" } ] }, { \"address\" : \"domain.com\" , \"port\" : 443 , \"users\" : [ { \"id\" : \"xxxxxxxxx-xxxxxxxxxxx-xxxxxx\" , \"alterId\" : 32 , \"security\" : \"none\" } ] } ] }, \"streamSettings\" : { \"network\" : \"tcp\" , \"security\" : \"tls\" } }, \"outboundDetour\" : [ { \"protocol\" : \"freedom\" , \"settings\" : {}, \"tag\" : \"direct\" } ], \"dns\" : { \"servers\" : [ \"101.6.6.6\" , \"101.132.183.99\" , \"193.112.15.186\" , \"8.8.8.8\" ] }, \"routing\" : { \"strategy\" : \"rules\" , \"settings\" : { \"domainStrategy\" : \"IPIfNonMatch\" , \"rules\" : [ { \"type\" : \"field\" , \"port\" : 53 , \"network\" : \"udp\" , \"outboundTag\" : \"direct\" }, { \"type\" : \"field\" , \"ip\" : [ \"geoip:cn\" , \"geoip:private\" , \"172.168.0.0/16\" ], \"port\" : \"0-10000\" , \"network\" : \"tcp,udp\" , \"outboundTag\" : \"direct\" }, { \"type\" : \"field\" , \"domain\" : [ \"geosite:cn\" ], \"port\" : \"0-10000\" , \"network\" : \"tcp,udp\" , \"outboundTag\" : \"direct\" } ] } } } 参考 v2ray官方文档 v2ray白话文教程 acme.sh wiki","tags":"IT笔记","url":"https://www.solarck.com/v2ray-quick-config.html"},{"title":"LEDE /OpenWRT 路由器打造家庭媒体影音中心（二）","text":"USB 驱动 查看已安装的驱动 opkg update opkg list-installed | grep usb 安装驱动和工具 如果下列驱动未出现在上一步的结果中，请务必首先安装缺失的驱动 opkg install kmod-usb-core kmod-usb-storage kmod-usb-core : USB 核心驱动 kmod-usb-storage :大容量存储设备驱动 kmod-usb2 : WRT1900ACS 有一个 USB2 .0/eSATA 口，可以不安装 kmod-ata-marvell-sata :Marvell SATA 接口驱动，可以不安装 网上搜到的教程和官方指南里还让安装一些其他的应用，但这些都是不必要或已被编译至内核中，包括： kmod-usb-ohci 、 kmod-usb-uhci 、 kmod-usb3 、 kmod-usb-storage-uas 安装相关工具 opkg install usbutils block-mount e2fsprogs kmod-fs-ext4 gdisk fdisk mount-utils :提供 unmount,findmnt usbutils :提供 lsusb block-mount :提供 block，查看挂载点信息 e2fsprogs :格式化工具 mkfs kmod-fs-ext4 :格式化为 ext4 格式 kmod-fs-ntfs :我不用 ntfs 格式，所以不安装这个，需要可以安装上 gdisk :分区工具，支持 GPT ，硬盘容量超过 2T 需要用这个工具，当然容量小的也可以用这个 fdisk :分区工具，不支持 GPT ，常用来查看分区信息 以下几个命令查看已连接/挂载的 USB 设备 df -h lsusb -t ls -l /dev/sd* block info | grep \"/dev/sd\" 小提示：硬盘格式化为什么格式最好？ 在 Linux 和 LEDE 平台上，微软的 NTFS 和 FAT32 绝对不是一个好的格式，设计的优劣不谈，这两个格式不是 Linux 平台原生支持的，安装额外的驱动可能会带来发热、读写速度慢、不稳定等多种负面效果。所以，对于机械硬盘来说， EXT4 和 BTRFS 是最好的，对于 SSD 来说， F2FS 格式是最好的。 硬盘相关操作 硬盘分区 gdisk /dev/sda 根据软件提示进行操作，主要命令有： n :新建分区 w :保存分区内容 d :删除分区 p :打印分区列表 ? :查看帮助 这里我把一块硬盘分为两个区 /dev/sda1 ， /dev/sda2 ，分区 1 大小 700G，分区 2 大小 231G，总计 1T。 格式化硬盘 mkfs.ext4 /dev/sda1 mkfs.ext4 /dev/sda2 如果是 SSD 硬盘，则可以按照如下方式安装操作 opkg install f2fs-tools opkg install kmod-fs-f2fs mkfs.f2fs /dev/sda1 自动挂载分区 这一部分请根据自己 fstab 实际内容修改使用 block detect > /etc/config/fstab uci set fstab.@mount [ 1 ] .enabled = '1' uci set fstab.@mount [ 2 ] .enabled = '1' uci set fstab.@mount [ 1 ] .options = 'rw' uci set fstab.@mount [ 2 ] .options = 'rw' uci set fstab.@global [ 0 ] .check_fs = '1' uci commit 查看当前挂载点设置 uci show fstab 卸载/挂载服务 block umount && block mount 硬盘休眠 hdparm opkg update opkg install hdparm luci-app-hd-idle 执行下面的命令启动休眠 hdparm -S 120 /dev/sda1 hdparm -S 120 /dev/sda2 -S 后的参数含义为： 0:关闭休眠 1-240：数字乘以 5 秒是时间，在设定时间内未使用则休眠 241-251：以 30 分钟为步进，时间为 30 分钟-5.5 小时 hd-idle 更简单的方法就是安装 Luci 管理工具 opkg update opkg install hd-idle luci-app-hd-idle Samba 安装 Samba 查看可安装的版本 opkg update opkg list | grep samba 根据结果，安装适当的版本 opkg install samba36-server luci-app-samba luci-i18n-samba-zh-cn 配置防火墙 vim /etc/config/firewall config 'rule' option 'src' 'lan' option 'proto' 'udp' option 'dest_port' '137-138' option 'target' 'ACCEPT' config 'rule' option 'src' 'lan' option 'proto' 'tcp' option 'dest_port' '139' option 'target' 'ACCEPT' config 'rule' option 'src' 'lan' option 'proto' 'tcp' option 'dest_port' '445' option 'target' 'ACCEPT' Samba 配置 官方 强烈建议 使用 luci 来配置 Samba，然后通过修改临时文件来完成配置。 路由器每次重启， /etc/samba/smb.conf 文件都将从 /etc/samba/smb.conf.template 文件重新创建，所以修改配置时请修改后者。 全局和共享配置可以在 LuCi 界面编辑也可以直接编辑文件，按照我的配置实现如下几个功能： 禁止 root 用户访问，防止权限出现问题 允许匿名用户访问 /mnt/sda1 ，即 Media 文件夹 访问 /mnt/sda2 ，即 Document 文件夹必须登录，用户只能访问到自己创建的文件夹和文件 全局配置 vim /etc/samba/smb.conf.template [ global ] #netbios name = LEDE #不设置默认是路由器host名 #workgroup = LEDE #不设置默认是WORKGROUP server string = Samba on LEDE syslog = 5 encrypt passwords = true socket options = TCP_NODELAY IPTOS_LOWDELAY unix charset = UTF-8 browseable = yes local master = yes preferred master = yes security = user null passwords = yes guest account = nobody invalid users = root passdb backend = smbpasswd smb passwd file = /etc/samba/smbpasswd map to guest = Bad User 共享文件夹设置 vim /etc/config/samba config samba option charset 'UTF-8' option homes '0' option interface 'loopback lan' option name 'Lede' option description 'Samba on Lede' option workgroup 'Lede' config sambashare option name 'Media' option path '/mnt/sda1' option read_only 'no' option guest_ok 'yes' option create_mask '0777' option dir_mask '0777' config sambashare option path '/mnt/sda2' option read_only 'no' option create_mask '0700' option dir_mask '0700' option name 'Document' option guest_ok 'no' 文件夹初始权限设置 /mnt/sda2 其实没必要更改所属用户和组，但是强迫症就是要给统一了。 chown -R nobody /mnt/sda1 chgrp -R nogroup /mnt/sda1 chmod -R 777 /mnt/sda1 chown -R nobody /mnt/sda2 chgrp -R nogroup /mnt/sda2 chmod -R 777 /mnt/sda2 添加用户 LEDE 默认不带 useradd 命令，需要手动安装 opkg update opkg install shadow-useradd 添加用户和设置密码要分两步走，首先要添加系统用户，然后再为该用户设置 Samba 密码。 useradd newuser passwd newuser smbpasswd -a newuser 最后启动/重启服务 /etc/init.d/samba restart /etc/init.d/samba enable 至此，Samba 设置完成，也达到了我的目的，有可以匿名随意访问的共享文件夹，也有实现了权限控制的私有文件夹。而且是全平台都可以访问，Windows、Linux 和手机（需要有支持 SMB 协议的软件）。 参考链接 Installing USB Drivers Using storage devices Share USB Hard-drive with Samba using the Luci web-interface SMB Samba share overview cifs.server Samba","tags":"IT 笔记","url":"https://www.solarck.com/lede-media-center2.html"},{"title":"LEDE /OpenWRT 路由器打造家庭媒体影音中心（一）","text":"前言 软/硬件 软件：本文系统都是基于 LEDE 17.01.4 硬件：Linksys WRT1900ACS V2 其他：一台电脑，最好是 Linux 带 SSH ，Windows 的话可以下个 putty 安装上 前提：我不会从头写起，而是从路由器已刷好 LEDE 17.01.4， WAN 口已联网，且已经可以 SSH 登录之后开始，其他外设，如硬盘、硬盘盒、用于 Extroot 的 U 盘都已准备好。 实现目的 基于 Linksys WRT1900ACS 强悍的性能和扩展功能丰富的 LEDE ，打造一个有权限控制的 NAS ，支持 DLNA ，可以离线下载和远程访问的 DDNS 系统的多媒体中心。 Extroot extroot 的作用就是扩充存储空间，这样就可以安装更多的软件。详细介绍可以查看很早之前我写过的一篇文章—— 用 extroot 为 openwrt 扩充存储空间 ，这里就不赘述了。由于那篇文章比较老， LEDE 也早已经升级了好几个含本，所以实际的操作还是以下面的内容为主。 安装工具 这里我准备把 U 盘格式化为 f2fs 格式，关于各种存储格式和下面需要安装的工具的作用，我会放在下一篇文章一起讲，这一步照着做就可以了。 opkg update opkg install block-mount kmod-fs-ext4 kmod-usb-storage e2fsprogs kmod-fs-f2fs f2fs-tools 格式化 U 盘 mkfs.f2fs /dev/sda1 迁移系统 mount /dev/sda1 /mnt ; tar -C /overlay -cvf - . | tar -C /mnt -xf - ; umount /mnt 生成分区表 block detect > /etc/config/fstab uci set fstab.@mount[0].target='/overlay' uci set fstab.@mount[0].enabled='1' uci set fstab.@mount[0].options='rw' uci set fstab.@mount[0].fstype='f2fs' uci commit 最后 fstab 应该如下 cat /etc/config/fstab config global option anon_swap '0' option anon_mount '0' option auto_swap '1' option auto_mount '1' option delay_root '5' option check_fs '1' config mount option enabled '1' option uuid 'd9aa4451-780a-4fe5-b08d-d7f0a7ae0ba4' option target '/overlay' option fstype 'f2fs' option options 'rw' 验证 重启系统后执行命令 df -h Filesystem Size Used Available Use% Mounted on /dev/root 2.8M 2.8M 0 100% /rom tmpfs 250.8M 556.0K 250.2M 0% /tmp /dev/sdb1 14.3G 496.6M 13.7G 3% /overlay overlayfs:/overlay 14.3G 496.6M 13.7G 3% / ubi1:syscfg 29.6M 268.0K 27.8M 1% /tmp/syscfg tmpfs 512.0K 0 512.0K 0% /dev 如果 /overlay 分区已经变为 U 盘容量大小，那就是成功了。 block info 信息也已经显示正确 /dev/mtdblock7: TYPE=\"jffs2\" /dev/ubiblock0_0: UUID=\"9f419b56-31564c19-0a0c1b12-a2f9b77b\" VERSION=\"4.0\" MOUNT=\"/rom\" TYPE=\"squashfs\" /dev/ubi0_1: UUID=\"1361ff26-cc87-40f1-8b99-00caf223093c\" VERSION=\"w4r0\" TYPE=\"ubifs\" /dev/ubi1_0: UUID=\"413d13a9-0f0a-4811-a0cb-3e3786ce26d7\" VERSION=\"w4r0\" TYPE=\"ubifs\" /dev/sda1: UUID=\"d9aa4451-780a-4fe5-b08d-d7f0a7ae0ba4\" VERSION=\"1.8\" MOUNT=\"/overlay\" TYPE=\"f2fs\" 更换源 添加对 https 的支持 如果你在替换源后执行更新，那么会收到一条错误消息： SSL support not available, please install one of the libustream-ssl-* libraries as well as the ca-bundle and ca-certificates packages. 很明显，系统还不支持 SSL ，因为官方的源都是 http 的，而我们添加的源都是 https 的。不过也很简单，按照错误信息的提示安装相应的包就可以了。 这一步一定要在替换源之前执行 opkg update opkg install ca-certificates luci-ssl-openssl 更换源 国内访问 LEDE 官方源比较不稳定，速度也很慢，幸好 中科大 和 清华 都提供了 LEDE 的软件镜像源，为了后边操作能够顺利进行，首先需要更换源。 LEDE OPKG 的软件源配置文件有两个： /etc/opkg/distfeeds.conf ：发行版本自带的官方源，需要把里面的内容全部注释掉或者清空。 /etc/opkg/customfeeds.conf ：自定义源，把我们需要的内容粘贴到这里，内容如下： src/gz reboot_core https://mirrors.ustc.edu.cn/lede/releases/17.01.4/targets/mvebu/generic/packages src/gz reboot_base https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/base src/gz reboot_luci https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/luci src/gz reboot_packages https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/packages src/gz reboot_routing https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/routing src/gz reboot_telephony https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/telephony #src/gz reboot_core https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/targets/mvebu/generic/packages #src/gz reboot_base https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/base #src/gz reboot_luci https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/luci #src/gz reboot_packages https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/packages #src/gz reboot_routing https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/routing #src/gz reboot_telephony https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/telephony 更新系统 镜像源替换完成后，把所有已安装程序全部更新到最新 opkg update opkg list-upgradable | cut -f 1 -d ' ' | xargs opkg upgrade 其他 汉化 opkg update opkg install luci-i18n-base-zh-cn 参考链接 How to get rid of LuCI https certificate warnings Extroot configuration","tags":"IT 笔记","url":"https://www.solarck.com/lede-media-center1.html"},{"title":"CentOS6 数据库服务器配置","text":"本文章仅用于记录在公司服务器上通过 yum repo 来安装官方提供的数据库程序，而非通过编译方式来安装。通过官方仓库来安装有很多好处，比如升级、打补丁都很方便，不用编译浪费时间，更不需要安装多个版本的 gcc 来满足各种不同软件的要求。 Mysql 下载安装 mysql repo rpm -Uvh https://repo.mysql.com//mysql80-community-release-el6-1.noarch.rpm 升级至 57 版本 yum --disablerepo=mysql80-community --enablerepo=mysql57-community upgrade 当前默认是 80 版本，如果未来需要升级，如果未来一直要维持在 57 版本，那么建议修改配置文件，以免每次都带上两个参数 vim /etc/yum.repos.d/mysql-community.repo # Enable to use MySQL 5.7 [mysql57-community] name = MySQL 5.7 Community Server baseurl = http://repo.mysql.com/yum/mysql-5.7-community/el/6/$basearch/ enabled = 1 gpgcheck = 1 gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql [mysql80-community] name = MySQL 8.0 Community Server baseurl = http://repo.mysql.com/yum/mysql-8.0-community/el/6/$basearch/ enabled = 0 gpgcheck = 1 gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 安装 mysql-server yum install mysql-community-server 开启服务 service mysqld start 当然这时候还未配置 mysql，开启服务可能会失败。默认配置文件在 /etc/my.cnf 。 更多安装细节可以参照 mysql 官方指南 。 Mongo 创建 repo 文件 vim /etc/yum.repos.d/mongodb-org-3.6.repo [mongodb-org-3.6] name = MongoDB Repository baseurl = https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/ gpgcheck = 1 enabled = 1 gpgkey = https://www.mongodb.org/static/pgp/server-3.6.asc 安装 mongo 组件合集 yum install -y mongodb-org mongo-org 是一个合集，如果想精简安装各个组件，请参照下表。 Package Name Description mongodb-org A metapackage that will automatically install the four component packages listed below. mongodb-org-server Contains the mongod daemon and associated configuration and init scripts. mongodb-org-mongos Contains the mongos daemon. mongodb-org-shell Contains the mongo shell. mongodb-org-tools Contains the following MongoDB tools: mongoimport bsondump, mongodump, mongoexport, mongofiles, mongoperf, mongorestore, mongostat, and mongotop. 启动服务 mongod -f /etc/mongod.conf mongo 默认不加载 conf 文件，所以用 service 方法是无法正常启动的，暂时使用自带方法开启服务。 更多安装细节可以参照 mongo 官方指南 。 Nginx 创建 repo 文件 vim /etc/yum.repos.d/nginx.repo [nginx] name = nginx repo baseurl = http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck = 0 enabled = 1 安装和开启服务 yum install -y nginx service nginx start service 方法启动 nginx 默认会加载 /etc/nginx/nginx.conf 配置。 查看系统安装路径 使用仓库安装有一点不是很清晰，那就是安装目录并非自己指定，有时需要修改一些文件时找不到文件在哪里，我们可以通过如下方法找到软件的所有文件目录。 rpm -qa |grep mongodb mongodb-org-mongos-3.6.5-1.el6.x86_64 mongodb-org-server-3.6.5-1.el6.x86_64 mongodb-org-tools-3.6.5-1.el6.x86_64 mongodb-org-3.6.5-1.el6.x86_64 mongodb-org-shell-3.6.5-1.el6.x86_64 例如我们要查看 server 的所有文件目录，则执行 rpm -ql mongodb-org-server-3.6.5-1.el6.x86_64 /etc/init.d/mongod /etc/mongod.conf /etc/sysconfig/mongod /usr/bin/mongod /usr/share/doc/mongodb-org-server-3.6.5 /usr/share/doc/mongodb-org-server-3.6.5/GNU-AGPL-3.0 /usr/share/doc/mongodb-org-server-3.6.5/MPL-2 /usr/share/doc/mongodb-org-server-3.6.5/README /usr/share/doc/mongodb-org-server-3.6.5/THIRD-PARTY-NOTICES /usr/share/man/man1/mongod.1 /var/lib/mongo /var/log/mongodb /var/log/mongodb/mongod.log /var/run/mongodb SSH 免密登录服务器 Linux 上免密登录通常用 RSA 公钥和密钥实现，本地生成钥匙后，公钥上传至服务器，之后便可以免密登录了。 本地生成公钥密钥 ssh-keygen -t rsa -b 4096 默认公钥会存储在 ~/.ssh/id_rsa.pub ，备用。 修改服务器 sshd 配置 vim /etc/ssh/sshd_config PubkeyAuthentication yes #解开注释 AuthorizedKeysFile .ssh/authorized_keys #解开注释 上传本地公钥至服务器 ssh-copy-id -i .ssh/id_rsa.pub -p port user@ip 修改上面的端口、用户名和 ip，再在本地 .bashrc 或 .zshrc 新建一条 alias 就可以非常方便快捷的登录了。","tags":"IT 笔记","url":"https://www.solarck.com/centos6-datebase-server.html"},{"title":"使用 Python 发送 Gmail","text":"本文基于一个真实的项目，使用 python3.6 和最新官方 smtplib 接口。项目的目的是爬取网站，然后通过邮件给自己发送邮件提醒新文章。最后使用 linux 系统的 crond 服务定时执行。 发邮件方法 在定义发邮件方法之前，我们还定义了一个类和类中的爬虫，单拿出来发邮件来说，代码如下： def sent_email ( self ): fromaddr = 'princelailai@gmail.com' toaddrs = [ 'princelailai@gmail.com' ] subject = \"{}{}\" . format ( datetime . now () . strftime ( '%Y年%m月 %d 日' ), '共有产权房信息' ) msg = '' . join ([ '日期: \\t {} \\n 标题: \\t {} \\n 地址: \\t {} \\n\\n ' . format ( v [ 0 ], v [ 1 ], k ) for k , v in self . result . items ()]) message = MIMEText ( msg , 'plain' , 'utf-8' ) message [ 'From' ] = Header ( fromaddr , 'utf-8' ) message [ 'To' ] = Header ( ',' . join ( toaddrs ), 'utf-8' ) message [ 'Subject' ] = Header ( subject , 'utf-8' ) #message = f\"From: {fromaddr}\\nTo: {','.join(toaddrs)}\\nSubject: {subject}\\n\\n{msg}\" username = 'princelailai@gmail.com' password = 'app password' try : server = smtplib . SMTP ( 'smtp.gmail.com' , '587' ) server . ehlo () server . starttls () server . login ( username , password ) server . sendmail ( fromaddr , toaddrs , message . as_string ()) server . quit () logging . info ( 'Send Email Successful.' ) except : logging . info ( 'Send Email Failed.' ) 需要注意的有几点： 邮件正文需要是 MIMEText 格式的 发信人、收信人、主题要用 Header 添加 如果你的 Google 账号开启了两步验证，那么你的邮箱密码就不是登录密码，而是 app 密码，关于 app 密码怎么生成可以查看这篇文章 Sign in using App Passwords 其他关于 smtp 地址和端口的问题，可以查看这篇文章 Use IMAP to check Gmail on other email clients 定时启动 创建一个文本文件，用于创建单一用户的 crond 文件 0 6 */3 * * /root/miniconda3/bin/python /root/monitor_house_info/monitor_house_info.py 关于 crond 配置，网上教程很多，或者 man 5 crontab 就可以看到详细的用法。 最后输入 crontab file 导入文件，就可以坐等收邮件了。 全部代码 #!/usr/bin/env python3 # -*- coding: utf-8 -*- from requests_html import HTMLSession import smtplib import os import json import logging from datetime import datetime from email.mime.text import MIMEText from email.header import Header logging . basicConfig ( format = ' %(asctime)s : %(levelname)s : %(message)s ' , level = logging . INFO ) class monitor_house_info : def __init__ ( self ): self . realpath = os . path . split ( os . path . realpath ( __file__ ))[ 0 ] self . realdb = os . path . join ( self . realpath , 'db.json' ) self . result = {} self . url = [ 'http://cpzjw.bjchp.gov.cn/cpzjw/336693/index.html' , 'http://cpzjw.bjchp.gov.cn/cpzjw/336551/336554/index.html' ] def read_json ( self ): if not os . path . exists ( self . realdb ): self . db = {} else : with open ( self . realdb ) as f : self . db = json . loads ( f . read ()) logging . info ( 'Readed json db.' ) def get_news ( self , url ): session = HTMLSession () resp = session . get ( url ) element_date = resp . html . find ( 'div.easysite-article-content > ul > li > span.date04' ) date = [ i . text [ 1 : - 1 ] for i in element_date ] element_content = resp . html . find ( 'div.easysite-article-content > ul > li > span.title04' ) content = [ i . text . strip () for i in element_content ] link = [ list ( i . absolute_links )[ 0 ] for i in element_content ] for l , d , c in zip ( link , date , content ): self . result [ l ] = [ d , c ] logging . info ( 'geted web content.' ) def valid_news ( self ): for k in self . result . keys (): if k in self . db : self . result . pop ( k ) with open ( self . realdb , 'w' ) as fp : self . db . update ( self . result ) fp . write ( json . dumps ( self . db , ensure_ascii = False )) logging . info ( 'valided news.' ) def sent_email ( self ): fromaddr = 'princelailai@gmail.com' toaddrs = [ 'princelailai@gmail.com' ] subject = \"{}{}\" . format ( datetime . now () . strftime ( '%Y年%m月 %d 日' ), '共有产权房信息' ) msg = '' . join ([ '日期: \\t {} \\n 标题: \\t {} \\n 地址: \\t {} \\n\\n ' . format ( v [ 0 ], v [ 1 ], k ) for k , v in self . result . items ()]) message = MIMEText ( msg , 'plain' , 'utf-8' ) message [ 'From' ] = Header ( fromaddr , 'utf-8' ) message [ 'To' ] = Header ( ',' . join ( toaddrs ), 'utf-8' ) message [ 'Subject' ] = Header ( subject , 'utf-8' ) username = 'princelailai@gmail.com' password = 'app password' try : server = smtplib . SMTP ( 'smtp.gmail.com' , '587' ) server . ehlo () server . starttls () server . login ( username , password ) server . sendmail ( fromaddr , toaddrs , message . as_string ()) server . quit () logging . info ( 'Send Email Successful.' ) except : logging . info ( 'Send Email Failed.' ) def run ( self ): self . read_json () for u in self . url : self . get_news ( u ) self . valid_news () if len ( self . result ) != 0 : self . sent_email () if __name__ == '__main__' : moni = monitor_house_info () moni . run ()","tags":"IT 笔记","url":"https://www.solarck.com/python-send-gmail.html"},{"title":"Pandas 时间处理函数速度对比","text":"Pandas 非常擅长处理时间序列，拥有多种处理时间序列的函数和方法，自己做了几个小测试，看看内置函数都能适配哪种格式、哪种情况，速度又有多快。 我用到的时间处理主要是对细粒度的时间重采样至粗粒度，之后再对重采样后的时间进行分组再进行后续操作，如求和、求平均或取最后值。 所以我就设计两个场景，第一个场景是对频率为秒的时间序列重采样至一分钟然后求平均；第二个场景就是对频率为秒的时间序列重采样至 3 分钟然后对新的时间序列取每个时间的最新值。 所以首先是要生成一组数据 import pandas as pd rng = pd . date_range ( start = '2018-04-07' , end = '2018-04-08' , freq = 's' ) df = pd . DataFrame ( pd . np . random . randn ( rng . size ), index = rng ) ser = pd . Series ( pd . np . random . randn ( rng . size ), index = rng ) df . columns = [ 'random' ] ser . name = 'random' df 和 ser 分别对应 DataFrame 和 Series，查看下数据格式 df.head() random 2018-04-07 00:00:00 0.163995 2018-04-07 00:00:01 0.756485 2018-04-07 00:00:02 -0.179441 2018-04-07 00:00:03 0.120944 2018-04-07 00:00:04 -1.558763 ser.tail() 2018-04-07 23:59:56 1.276893 2018-04-07 23:59:57 0.275050 2018-04-07 23:59:58 1.029358 2018-04-07 23:59:59 0.461299 2018-04-08 00:00:00 1.222731 Freq: S, Name: random, dtype: float64 接下来定义六个函数方法 def method1 ( data ): data . index = data . index . to_period ( 'Min' ) . to_timestamp () data . groupby ( data . index ) . mean () def method2 ( data ): data . index = pd . to_datetime ( data . index . strftime ( '%Y-%m- %d %H:%M' )) data . groupby ( data . index ) . mean () def method3 ( data ): ser_idx = pd . Series ( data . index ) data . index = pd . to_datetime ( ser_idx . apply ( lambda x : str ( x )[: - 2 ] + '00' )) data . groupby ( data . index ) . mean () def method4 ( data ): data . resample ( 'Min' ) . mean () def method5 ( data ): data . asfreq ( '3Min' , method = 'ffill' ) def method6 ( data ): data . resample ( '3Min' ) . last () 方法 1-方法 4 适用于场景一，方法 5-方法 6 适用于场景二，接下来具体说说这六个函数和为什么要这么设计场景。 方法 1 使用的是内置 to_period 方法转换周期，to_timestamp 方法是为了后续操作使用 timestamp 更方便。 方法 2 对索引日期进行字符串格式化然后再用内置的 to_datetime 方法转换回日期格式达到重采样效果。 方法 3 看似复杂，其实和方法二类似，我之所以加上方法三是因为我本以为这个办法处理会慢很多，但是最终结果还是有点出乎我的意料的。 方法 4 是内置的 resample 方法 方法 5 是内置的 asfreq 方法 方法 6 还是内置的 resample 方法 可以看到 resample 方法适用范围最广，既可以对时间采取多种细粒度的操作，也能对重采样后的数据进行后续操作；而 asfreq 方法只能对数据进行重采样，无法进行复杂的后续操作，只能用向前/向后填充数值；to_period 方法和字符串操作只能对时间进行整数采样，像 45 分钟，1 小时 30 分这种更细腻的操作是不支持的。 比较速度 场景 1 %timeit method1 ( df ) %timeit method2 ( df ) %timeit method3 ( df ) %timeit method4 ( df ) 16.4 ms ± 391 µ s per loop ( mean ± std . dev . of 7 runs , 10 loops each ) 439 ms ± 2.52 ms per loop ( mean ± std . dev . of 7 runs , 1 loop each ) 485 ms ± 10.8 ms per loop ( mean ± std . dev . of 7 runs , 1 loop each ) 2.13 ms ± 9.92 µ s per loop ( mean ± std . dev . of 7 runs , 100 loops each ) %timeit method1 ( ser ) %timeit method2 ( ser ) %timeit method3 ( ser ) %timeit method4 ( ser ) 23.8 ms ± 72.2 µ s per loop ( mean ± std . dev . of 7 runs , 10 loops each ) 446 ms ± 2.71 ms per loop ( mean ± std . dev . of 7 runs , 1 loop each ) 492 ms ± 3.61 ms per loop ( mean ± std . dev . of 7 runs , 1 loop each ) 1.63 ms ± 15.1 µ s per loop ( mean ± std . dev . of 7 runs , 1000 loops each ) 从上面对比数据得出结论，resample 方法最快，to_period 方法其次，两种字符串方法最慢，最快和最慢差距巨大。 场景 2 %timeit method5 ( df ) %timeit method6 ( df ) 746 µ s ± 32.5 µ s per loop ( mean ± std . dev . of 7 runs , 1000 loops each ) 2.42 ms ± 24 µ s per loop ( mean ± std . dev . of 7 runs , 100 loops each ) %timeit method5 ( ser ) %timeit method6 ( ser ) 772 µ s ± 20.2 µ s per loop ( mean ± std . dev . of 7 runs , 1000 loops each ) 1.87 ms ± 50.5 µ s per loop ( mean ± std . dev . of 7 runs , 100 loops each ) 在场景二的测试中 asfreq 比 resample 快 2 倍多，如果不需要更多的后续操作，asfreq 是很好的选择，否则 resample 方法更为全能。 下方的表格总结了几种方法的优劣： 函数 时间细粒度操作 时间分组后续操作 速度 asfreq X X ✓ resample ✓ ✓ ✓ to_period X ✓ ✓ 字符串 X ✓ X Pandas Offset Aliases Alias Description B business day frequency C custom business day frequency D calendar day frequency W weekly frequency M month end frequency SM semi-month end frequency (15th and end of month) BM business month end frequency CBM custom business month end frequency MS month start frequency SMS semi-month start frequency (1st and 15th) BMS business month start frequency CBMS custom business month start frequency Q quarter end frequency BQ business quarter end frequency QS quarter start frequency BQS business quarter start frequency A, Y year end frequency BA , BY business year end frequency AS , YS year start frequency BAS , BYS business year start frequency BH business hour frequency H hourly frequency T, min minutely frequency S secondly frequency L, ms milliseconds U, us microseconds N nanoseconds 参考 官方文档","tags":"IT 笔记","url":"https://www.solarck.com/pandas-timeseries.html"},{"title":"用数据验证定投是否优于直接投资","text":"一直以来，定投的营销话术都是分批建仓，上涨时投资少降低成本，下跌时投资多赚取低估价值，但定投是否真的如宣传的那么美好？今天就用数据来模拟两种投资方式，看看孰优孰劣。 数据说明 本次实验使用三只 ETF 基金作为投资和定投标的，分别为华夏上证 50ETF （510050），华泰柏瑞沪深 300ETF （510300），广发中证 500ETF （510510），时间区间为 2013 年 5 月 27 日至 2018 年 6 月 7 日。 先上图了解下这段时间 ETF 基金大致走势。 50ETF 月线 500ETF 周线 这段区间整体来看是上涨的，大盘股涨的多，小盘股涨得少。分段来看 2013 年中至 2014 年中，属于震荡行情，2014 年中至 2015 年中是暴涨行情，2015 年中至 2016 年初是暴跌行情，2016 年初至 2018 年中行情分化，大盘股再次进入牛市，中盘股属于慢牛，小盘股是横盘震荡走势。 选择这个区间的行情，是因为这五年属于一个完整的周期，活跃时波动率大，行情过后的低迷时期波动率又小，是典型的中国股市。另外从长期来看，股票波动向上才应该是上市公司内在价值增长的表现。 当然，用这个区间的数据做分析是有一个缺点的，就是这三只 ETF 基金整体涨幅都在 40%-50%之间，如果在一开始就持有至当前日期，那么一定是一次性直接投资要优于定投，不过放心，后面编程不会让这种事情发生，我会加入时间随机项，尽量减小整体上涨带来的影响。 开始实验 首先要导入用到的包 import tushare as ts import pandas as pd import random import matplotlib.pyplot as plt 之后利用 tushare 包，获取到三只 ETF 基金的收盘价，放入一个 DataFrame 内，这里我创建了一个类，主要是为了代码整洁考虑。 class AutoInvestmentPlan : def __init__ ( self ): plt . style . use ( 'ggplot' ) self . code_list = [ '510050' , '510300' , '510510' ] self . start_date = '2013-05-27' def get_etf_close ( self , code , start ): df = ts . get_k_data ( code , start = start ) df . set_index ( 'date' , inplace = True ) df . index = pd . to_datetime ( df . index ) return df . close def combin_to_df ( self ): close_list = [] for code in self . code_list : close_list . append ( self . get_etf_close ( code , self . start_date )) self . data = pd . concat ( close_list , axis = 1 ) self . data . columns = [ 'ETF50' , 'ETF300' , 'ETF500' ] def get_data ( self ): self . combin_to_df () self . monthly = self . data . asfreq ( 'M' , method = 'pad' ) self . weekly = self . data . asfreq ( 'W' , method = 'pad' ) 获取数据需要对类实例化，然后就得到了周和月数据 aip = AutoInvestmentPlan () aip . get_data () 这里需要等待几秒种，运行完成后就可以查看我们的数据了 周数据最新的 5 个收盘价 aip.weekly.tail() ETF50 ETF300 ETF500 date 2018-05-06 2.634 3.770 1.646 2018-05-13 2.716 3.873 1.667 2018-05-20 2.733 3.899 1.670 2018-05-27 2.654 3.811 1.649 2018-06-03 2.643 3.777 1.588 月收益率数据 aip.monthly.pct_change().describe() ETF50 ETF300 ETF500 count 60.000000 60.000000 60.000000 mean 0.008889 0.009014 0.009978 std 0.076945 0.073923 0.081489 min -0.182533 -0.224457 -0.279845 25% -0.022543 -0.018264 -0.025160 50% 0.002254 0.006061 0.015203 75% 0.035246 0.041125 0.049516 max 0.334728 0.254035 0.204142 接下来在定义用来比较的函数 def compare ( underlying , df_period , times = 15 , money = 1000 , plot = False ): df_period [ underlying ] . plot ( figsize = ( 9 , 6 ), title = '{} close price' . format ( underlying )) result = [] for _ in range ( times ): start = random . choice ( df_period . index [: int ( df_period . index . size / 2 )]) end = random . choice ( df_period . loc [ start + pd . Timedelta ( 18 , unit = 'M' ):] . index ) d = df_period . loc [ start : end ,:] cumsum_values = pd . DataFrame (( money / d . loc [:, underlying ])) cumsum_values . columns = [ 'share_period' ] cumsum_values [ 'share_cum' ] = cumsum_values [ 'share_period' ] . cumsum () cumsum_values [ 'values' ] = cumsum_values . share_cum * d . loc [:, underlying ] cumsum_values [ 'payoff' ] = [ i * money for i in range ( 1 , cumsum_values . index . size + 1 )] a = d . loc [:, underlying ] / d . loc [ d . index [ 0 ], underlying ] b = cumsum_values [ 'values' ] / cumsum_values [ 'payoff' ] b . name = 'AIP' df = pd . concat ([ a , b ], axis = 1 ) if plot : df . plot () exceed = pd . np . subtract ( * df . iloc [ - 1 ]) print ( 'from {} to {},dirctly invest ETF exceed AIP {:.2%}' . format ( start . strftime ( '%Y-%m- %d ' ), end . strftime ( '%Y-%m- %d ' ), exceed )) result . append ( exceed ) print ( ' \\n In {} times simulation,dirctly invest ETF exceed AIP \\' s mean is {:.2%}' . format ( times , pd . np . mean ( result ))) 这个比较函数从给定的 ETF 基金中的前半段时间随机选取一个日期，然后至少持有 18 个月，至多持有到当前日期，用这段时间的数据分别模拟在初始日期全部投资至结束和在区间内定投的收益情况。使用方法如下： #用每月定投1000元ETF50来比较 compare('ETF50',aip.monthly) #用每周定投1000元ETF500来比较 compare('ETF500',aip.weekly) #用每周定投500元ETF300来比较，共模拟10次，每次打印出走势对比图 compare('ETF300',aip.weekly,times=10,money=500,plot=True) 比较结果 compare('ETF50',aip.monthly) from 2015-09-30 to 2017-08-31,dirctly invest ETF exceed AIP 8.07% from 2014-07-31 to 2016-06-30,dirctly invest ETF exceed AIP 30.34% from 2014-09-30 to 2017-08-31,dirctly invest ETF exceed AIP 45.93% from 2015-05-31 to 2017-12-31,dirctly invest ETF exceed AIP -26.74% from 2014-03-31 to 2017-06-30,dirctly invest ETF exceed AIP 54.43% from 2015-09-30 to 2017-04-30,dirctly invest ETF exceed AIP 4.29% from 2015-07-31 to 2017-04-30,dirctly invest ETF exceed AIP -9.27% from 2014-06-30 to 2016-10-31,dirctly invest ETF exceed AIP 47.17% from 2015-07-31 to 2017-09-30,dirctly invest ETF exceed AIP -7.44% from 2014-10-31 to 2016-06-30,dirctly invest ETF exceed AIP 31.91% from 2014-07-31 to 2017-11-30,dirctly invest ETF exceed AIP 46.67% from 2015-06-30 to 2017-08-31,dirctly invest ETF exceed AIP -22.72% from 2014-04-30 to 2017-06-30,dirctly invest ETF exceed AIP 52.55% from 2014-04-30 to 2016-12-31,dirctly invest ETF exceed AIP 44.92% from 2014-04-30 to 2015-10-31,dirctly invest ETF exceed AIP 41.97% In 15 times simulation,dirctly invest ETF exceed AIP's mean is 22.81% compare('ETF500',aip.weekly) from 2014-09-28 to 2017-07-09,dirctly invest ETF exceed AIP 28.72% from 2014-06-08 to 2017-05-07,dirctly invest ETF exceed AIP 56.41% from 2015-05-10 to 2018-04-29,dirctly invest ETF exceed AIP -20.97% from 2014-02-09 to 2017-06-18,dirctly invest ETF exceed AIP 45.50% from 2014-06-29 to 2016-07-17,dirctly invest ETF exceed AIP 55.89% from 2015-07-12 to 2017-10-15,dirctly invest ETF exceed AIP -15.83% from 2013-06-02 to 2017-04-30,dirctly invest ETF exceed AIP 40.71% from 2014-06-08 to 2016-10-02,dirctly invest ETF exceed AIP 57.17% from 2014-05-11 to 2018-01-07,dirctly invest ETF exceed AIP 64.35% from 2014-09-07 to 2017-04-02,dirctly invest ETF exceed AIP 33.36% from 2014-07-20 to 2018-03-25,dirctly invest ETF exceed AIP 47.74% from 2014-03-30 to 2017-06-11,dirctly invest ETF exceed AIP 50.51% from 2013-09-15 to 2015-11-22,dirctly invest ETF exceed AIP 44.02% from 2015-03-08 to 2017-04-09,dirctly invest ETF exceed AIP 6.61% from 2015-04-05 to 2017-01-29,dirctly invest ETF exceed AIP -13.85% In 15 times simulation,dirctly invest ETF exceed AIP's mean is 32.02% 从上面的运行结果来看，把资金一次性全部投入比定投的平均收益是要高的，如果有兴趣，可以自己修改程序，改变开始和结束时间来验证结果，相信结论应该上面的相差不会太多。 当然，定投也不是一无是处，至少对于当前资金不足，只想从每月工资中拿出一部分来投资的人来说，还是一种很好的投资方式的。 完整代码 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import tushare as ts import pandas as pd import random import matplotlib.pyplot as plt class AutoInvestmentPlan : def __init__ ( self ): plt . style . use ( 'ggplot' ) self . code_list = [ '510050' , '510300' , '510510' ] self . start_date = '2013-05-27' def get_etf_close ( self , code , start ): df = ts . get_k_data ( code , start = start ) df . set_index ( 'date' , inplace = True ) df . index = pd . to_datetime ( df . index ) return df . close def combin_to_df ( self ): close_list = [] for code in self . code_list : close_list . append ( self . get_etf_close ( code , self . start_date )) self . data = pd . concat ( close_list , axis = 1 ) self . data . columns = [ 'ETF50' , 'ETF300' , 'ETF500' ] def get_data ( self ): self . combin_to_df () self . monthly = self . data . asfreq ( 'M' , method = 'pad' ) self . weekly = self . data . asfreq ( 'W' , method = 'pad' ) def compare ( underlying , df_period , times = 15 , money = 1000 , plot = False ): df_period [ underlying ] . plot ( figsize = ( 9 , 6 ), title = '{} close price' . format ( underlying )) result = [] for _ in range ( times ): start = random . choice ( df_period . index [: int ( df_period . index . size / 2 )]) end = random . choice ( df_period . loc [ start + pd . Timedelta ( 18 , unit = 'M' ):] . index ) d = df_period . loc [ start : end ,:] cumsum_values = pd . DataFrame (( money / d . loc [:, underlying ])) cumsum_values . columns = [ 'share_period' ] cumsum_values [ 'share_cum' ] = cumsum_values [ 'share_period' ] . cumsum () cumsum_values [ 'values' ] = cumsum_values . share_cum * d . loc [:, underlying ] cumsum_values [ 'payoff' ] = [ i * money for i in range ( 1 , cumsum_values . index . size + 1 )] a = d . loc [:, underlying ] / d . loc [ d . index [ 0 ], underlying ] b = cumsum_values [ 'values' ] / cumsum_values [ 'payoff' ] b . name = 'AIP' df = pd . concat ([ a , b ], axis = 1 ) if plot : df . plot () exceed = pd . np . subtract ( * df . iloc [ - 1 ]) print ( 'from {} to {},dirctly invest ETF exceed AIP {:.2%}' . format ( start . strftime ( '%Y-%m- %d ' ), end . strftime ( '%Y-%m- %d ' ), exceed )) result . append ( exceed ) print ( ' \\n In {} times simulation,dirctly invest ETF exceed AIP \\' s mean is {:.2%}' . format ( times , pd . np . mean ( result )))","tags":"金融笔记","url":"https://www.solarck.com/Is-AIP-better-than-ETF.html"},{"title":"git 和 github 主要使用方法","text":"ssh 和密钥 ssh-keygen -t rsa -b 4096 -C \"princelailai@gmail.com\" ：生成密钥 cat ~/.ssh/id_rsa.pub ：查看密钥 ssh -T git@github.com ：测试密钥是否可以正常登录 设置 git config --list ：列出当前 repo 所有设置 git config --global user.name \"princelai\" ：设置用户名 git config --global user.email \"princelailai@gmail.com\" ：设置 E-mail echo \"# mydotfiles\" > README.md ： 基本操作 git init ：初始化，创建.git 文件夹 git status ：查看当前工作区/缓存区状态 添加和提交 git add <文件> ：添加文件至缓存区 git commit -m \"说明\" ：从缓存区提交至仓库 git commit -am \"说明\" ：前面两种的合并版 git commit --amend \"说明\" ：替换掉上一次的提交 删除文件 git rm <文件> ：从 repo 中删除文件 git rm --cached <文件> ： 恢复 git checkout -- <文件> ：撤销文件工作区的修改 git reset HEAD <文件> ：撤销文件暂存区的修改，放回工作区 git reset --hard ad93b89 ：所有文件退回至指定版本 版本和日志 git log --oneline :简版 log git log --graph ：带合并图形版 log 远程仓库 git remote show origin ：查看远程仓库详情 git clone git-url ：从远程仓库克隆至本地 git remote add origin git-url ：关联远程和本地仓库 远程仓库的提交和拉取 git pull origin master ：把远程仓库拉取到本地仓库 git push origin master ：本地仓库推送至远程仓库，-u 用于第一次关联 分支 git branch ：列出本地分支 git branch -r ：列出远程分支 git branch -a ：列出所有分支 git branch <分支> ：创建分支 git branch -d <分支> ：删除分支 git branch --set-upstream-to=origin/分支 分支 ：本地和远程分支关联 checkout git checkout 分支 ：切换到指定分支 git checkout -b 分支 ：创建并切换到分支 合并 git merge 分支 ：把指定分支合并到当前分支 git merge --no-ff -m \"说明\" 分支 ：禁止 Fast forward 模式，创建新的 commit 参考 简书 廖雪峰 阮一峰","tags":"IT 笔记","url":"https://www.solarck.com/git-and-github.html"},{"title":"用股票数据说明方差和标准差的特性","text":"方差 （Variance），应用数学里的专有名词。在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。一个实随机变量的方差也称为它的二阶矩或二阶中心动差，恰巧也是它的二阶累积量。这里把复杂说白了，就是将各个误差将之平方（而非取绝对值，使之肯定为正数），相加之后再除以总数，透过这样的方式来算出各个数据分布、零散（相对中心点）的程度。继续延伸的话，方差的算术平方根称为该随机变量的标准差（此为相对各个数据点间）。 标准差 （Standard Deviation， SD ），数学符号 \\(\\sigma\\) （sigma），在概率统计中最常使用作为测量一组数值的离散程度之用。标准差定义：为方差开算术平方根，反映组内个体间的离散程度；标准差与期望值之比为标准离差率。 1.定义 方差的定义如下公式： $$Var(X)=\\sigma&#94;2=E[(X-\\mu)&#94;2]$$ 对上式化简后可得到如下公式： $$\\sigma&#94;2=E[X&#94;2]-(E[X])&#94;2$$ 上面两个公式也可以写为下面这样： $$\\sigma&#94;2=\\frac{1}{N}\\sum*{i=1}&#94;{N}(x_i-\\mu)&#94;2=\\frac{(\\sum*{i=1}&#94;{N}x_i&#94;2-\\mu&#94;2)}{N}$$ 标准差的定义和公式和方差类似，就是对方差开平方根即可得到。 $$SD(X) = \\sigma = \\sqrt{E(X-E(X))&#94;2}$$ $$\\sigma = \\sqrt{\\frac{\\sum*{i=1}&#94;NX_i&#94;2}{N}-\\mu&#94;2}$$ $$\\sigma = \\sqrt{\\frac{(\\sum*{i=1}&#94;{N}x_i&#94;2-\\mu&#94;2)}{N}}$$ 2.准备数据 这里使用一个开源免费的股票数据模块 tushare，获取贵州茅台的数据，并截取数据的前 600 天，把数据平分为 2 部分。获取后的数据格式为 DataFrame。 import tushare as ts import numpy as np stock = ts . get_k_data ( '600519' ) stock = stock . iloc [: 600 , stock . columns . get_loc ( 'close' )] stock_part1 = stock . iloc [: stock . index . size // 2 ] stock_part2 = stock . iloc [ stock . index . size // 2 :] stock_part2 . index = range ( 300 ) 3.特性验证 对于方差的计算，我们可以把数据带入公式直接计算，python 代码可以这样写，这里使用的是无偏估计，所以分母是 N-1。 (( stock - stock . mean ()) ** 2 ) . sum () / ( stock . size - 1 ) 不过幸好 Numpy 和 Pandas 都提供了快速计算方差和标准差的方法，我们可以调用 var() 方法和 std() 方法使用。 性质 1，一个常数被加至变量数列中，此数列方差不变。 $$Var(X+c) = Var(X)$$ $$SD(X+c) = SD(X)$$ In [ 1 ]: np . isclose (( stock + 5 ) . var (), stock . var ()) Out [ 1 ]: True #方差 In [ 2 ]: np . isclose (( stock + 8 ) . std (), stock . std ()) Out [ 2 ]: True #标准差 性质 2，数列被放大一个常数倍，此数列的方差变大常数的平方倍 $$Var(cX) = c&#94;2 \\times Var(X)$$ $$SD(cX) = c \\times SD(X)$$ In [ 3 ]: np . isclose (( stock * 3 ) . var (), 3 ** 2 * stock . var ()) Out [ 3 ]: True #方差 In [ 4 ]: np . isclose (( stock * 4 ) . std (), 4 * stock . std ()) Out [ 4 ]: True #标准差 性质 3，两个数列和（差）的方差 $$Var(aX+bY)=a&#94;2Var(X)+b&#94;2Var(Y)+2 \\times ab \\times Cov(X,Y)$$ $$Var(X-Y)=Var(X)+Var(Y)-2 \\times Cov(X,Y)$$ 标准差也有同样的性质 $$SD(X+Y)=\\sqrt{\\sigma&#94;2(X)+\\sigma&#94;2(Y)+2 \\times Cov(X,Y)}$$ In [ 5 ]: np . isclose (( stock_part1 + stock_part2 ) . var (), stock_part1 . var () + stock_part2 . var () + 2 * stock_part1 . cov ( stock_part2 )) Out [ 5 ]: True #方差 In [ 6 ]: np . isclose (( stock_part1 + stock_part2 ) . std (), np . sqrt ( stock_part1 . var () + stock_part2 . var () + 2 * stock_part1 . cov ( stock_part2 ))) Out [ 6 ]: True #标准差 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"金融笔记","url":"https://www.solarck.com/using-python-descript-vaiance-std.html"},{"title":"argparse模块简要用法","text":"argparse是Python用于解析命令行参数的模块，拥有更强大的功能、更友好的使用方法，用来替代原始的sys.argv。 argparse的大致用法如下： import argparse #导入模块 parser = argparse . ArgumentParser () #创建解析器 parser . add_argument () #添加参数 args = parser . parse_args () #解析参数 创建解析器时的可选参数很多，但没有特殊需求的情况下，默认参数就能很好的工作，所以这部分使用时临时查文档就能解决，不做过多记录。 这里仅记录下添加参数时的各种选项搭配，使用方法和选项如下： ArgumentParser . add_argument ( name or flags ... [, action ][, nargs ][, const ][, default ][, type ][, choices ][, required ][, help ][, metavar ][, dest ]) 每一个参数的含义： name or flags - 名称或选项字符串列表，例如。foo或-f, —foo。 action - 在命令行遇到此参数时要执行的操作的基本类型。 nargs - 应该使用的命令行参数数。 const - 某些动作和nargs选择所需的常量值。 default - 如果参数在命令行中不存在，则生成的值。 type - 应转换命令行参数的类型。 choices - 参数的允许值的容器。 required - 是否可以省略命令行选项（仅针对可选参数）。 help - 参数的简要说明。 metavar - 使用消息中参数的名称。 dest - 要添加到由parse_args()返回的对象的属性的名称。 1. name or flags 唯一的必填参数，可以创建位置参数（必填）和可选参数 parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( '-s' , '--save' ) parser . add_argument ( 'db' ) parser . parse_args ([ 'mysql' ]) Out [ 1 ]: Namespace ( db = 'mysql' , save = None ) 可选参数以 - 或 -- 开始，其余的均为位置参数 大部分情况下，未填的可选参数默认都是 None ,如果有 -- 开始的参数，则参数名以后面的字符串命名。 2. action action用于将命令和动作关联起来，常用的动作有如下几种： store - 仅保存参数后的值 store_const - 保存一个常量，由const参数给出 store_true - 给出参数则保存True值，不给出则为False store_false - 与上面相反 append - 把多次调用的值保存为一个列表 append_const - 把多次调用的常量保存为一个列表 count - 计算参数出现的次数 help - 打印帮助信息，默认自动添加 version - 打印版本信息，配合version选项使用 举几个例子 parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( '-sh' , '--show' , action = 'store_true' ) parser . parse_args ([ '-sh' ]) Out [ 2 ]: Namespace ( show = True ) 给出 -sh 参数，则show值为True parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( '-a1' , '--arg1' , action = 'store_const' , const = 0 ) parser . add_argument ( '-a2' , '--arg2' , action = 'store_const' , const = 10 , default = None ) parser . add_argument ( '-a3' , '--arg3' , action = 'store_const' , const = True , default = False ) parser . parse_args ([ '-a1' ]) Out [ 22 ]: Namespace ( arg1 = 0 , arg2 = None , arg3 = False ) 只给出a1参数，arg1的值为0。 没有给出a2参数，则a2的const没有被调用，使用default的值，当然default默认就是None，不写也可以。 a3参数其实就是store_true的实现。 const和default的区别就是当命令给出但是后面未接值时，使用const值，如果命令那个都没有给出，则使用default的值。 3. nargs nargs定义参数后面值的个数，可选值有几种： N (一个整数) ? * + 如果懂正则表达式，那nargs的参数就很好理解，这里就不做过多解释，不过要注意一点，当nargs=1的时候，他的行为和不给出nargs是不一样的，前者是一个列表，后者是一个值。直接看例子： parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( 'a1' , nargs = 2 ) parser . add_argument ( '-a2' , '--args2' , nargs = '?' , const = 0 ) parser . add_argument ( '-a3' , '--args3' , nargs = '+' , default = False ) parser . parse_args ([ 'a' , 'b' , '-a3' , 'aa' , 'bb' ]) Out [ 3 ]: Namespace ( a1 = [ 'a' , 'b' ], args2 = None , args3 = [ 'aa' , 'bb' ]) 结果很好理解，?可以配合const使用，其他的可以配合default使用，调用了就是一个列表，使用const或default就是一个值。 4. type和metavar 这两个参数偶尔能用到， parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( 'a1' , type = float ) parser . add_argument ( '-a2' , '--args2' , metavar = 'STR' , default = argparse . SUPPRESS ) parser . parse_args ([ '3' ]) default=argparse.SUPPRESS 指出不给参数不存储变量，否则默认是None， 打印help说明看看 parser . print_help () usage : PROG [ - h ] [ - a2 STR ] a1 positional arguments : a1 optional arguments : - h , -- help show this help message and exit - a2 STR , -- args2 STR metavar仅改变了help说明里的变量名。 参考文档 官方文档 中文文档","tags":"IT笔记","url":"https://www.solarck.com/argparse-brief-usage.html"},{"title":"matplotlib 中文字体配置","text":"matplotlib 是 Python 的优秀绘图包，但是不论是在 Windows 还是 Linux 中默认都是不支持中文的，尤其是在 Linux 中设置更加复杂一点，设置方法如下： 首先我们需要获取到 matplotlib 配置文件的文件夹 python -c \"import matplotlib as mpl;print(mpl.get_configdir())\" /home/kevin/.config/matplotlib 然后需要一个默认的 matplotlibrc 文件用于修改 python -c \"import matplotlib as mpl;print(mpl.matplotlib_fname())\" /opt/anaconda/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc 这个位置会根据每个人安装位置不同而改变 然后把默认的 rc 文件拷贝到用户的配置文件夹 cp /opt/anaconda/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc ~/.config/matplotlib 之后的工作都是围绕这个 rc 文件，一般情况下只需要修改如下两个字段，把注释打开。 font.sans-serif : DejaVu Sans, Bitstream Vera Sans, Lucida Grande, Verdana, Geneva axes.unicode_minus : False 第一个字段负责中文字体显示，但是目前还没有，第二个负责正负号的显示。 由于 matplotlib 不使用系统字体，所以需要找到一个 matplotlib 支持的字体且已在系统中 fc-list :lang=zh |grep -i ttf 在 shell 中执行这个命令，就能找到几个字体，选择一个填到上面第一行第一个即可，通常建议选择 Droid Sans Fallback 修改好后重启整个 python 或 ipython 之后应该就可以看到中文，不过还是不可以的话可以使用下面方案二查找，这个方法出自 segmentfault 。 #! /usr/bin/env python # -*- coding: utf-8 -*- from matplotlib.font_manager import FontManager import subprocess fm = FontManager () mat_fonts = set ( f . name for f in fm . ttflist ) output = subprocess . check_output ( 'fc-list :lang=zh -f \"%{family} \\n \"' , shell = True ) output = output . decode ( 'utf8' ) zh_fonts = set ( f . split ( ',' , 1 )[ 0 ] for f in output . split ( ' \\n ' )) available = mat_fonts & zh_fonts print ( '*' * 10 , '可用的字体' , '*' * 10 ) for f in available : print ( f ) 如果不想使用 rc 文件来配置，那么可以在每次使用的时候在 python 中执行以下命令即可。 import matplotlib.pyplot as plt plt . rcParams [ 'font.sans-serif' ] = [ 'Droid Sans Fallback' ] plt . rcParams [ 'axes.unicode_minus' ] = False","tags":"IT 笔记","url":"https://www.solarck.com/matplotlib-chinese-fonts.html"},{"title":"自定义 Linux 桌面启动程序","text":"Anaconda 自带的 Spyder 是一个我最喜欢使用的 IDE ，对于科学计算有很好的支持，但是在 Linux 上它并没有自带.desktop 文件，所以并不能在程序列表里找到，每次都要手动在命令行执行才能开启，非常不方便，所以决定自己搜索下方法，自己给它添加一个桌面快捷方式。 Linux 的主流 DE 的桌面文件都遵循 桌面配置项规范 ，按照这个规范配置一个相应的.desktop 文件，放在指定的目录即可，当然你也可以放在 ~/.local/share/applications/ 目录里，这样这个快捷方式只针对当前用户。 sudo vim / usr / share / applications / spyder . desktop [ Desktop Entry ] Version = 1.0 Type = Application Name = Spyder GenericName = Spyder Comment = Scientific Python Development EnviRonment TryExec =/ opt / anaconda / bin / spyder Exec =/ opt / anaconda / bin / spyder Categories = Development ; Science ; IDE ; Qt ; Icon =/ opt / anaconda / lib / python3 .6 / site - packages / spyder / images / spyder . png Terminal = false StartupNotify = false TryExec 和 Exec 后面是可执行文件的地址，可以只写后者 Icon 是快捷方式的图标，没有的话可以去网上下载一个或者根据自己喜好随便放一个。 更多内容可以参考这篇 Wiki","tags":"IT 笔记","url":"https://www.solarck.com/linux-desktop-entries.html"},{"title":"VPS 搭梯子指南——shadowsocks+ BBR +obfs","text":"近期开会导致墙越来越高，迫不得已升级自建的 ss 服务，由于 shadowsocks 原版已经停更，shadowsocksR 也已经删库，所以就锁定 libev 版本。 注：以下服务器端内容请切换到 root 操作 1. 升级 Debian 在升级之前，我需要先把服务器从 Debian 8 升级到 Debian 9，如果不是 Debian 用户，或者不想升级的可以跳过，这一步不影响后续操作，但是部分代码可能需要修改。 首先要把 Debian 8 升级到最新版本 apt update apt upgrade 备份源列表 cp /etc/apt/sources.list /etc/apt/sources.list-jessie 修改源列表，把 jessie 替换为 stretch vim /etc/apt/sources.list :s/jessie/stretch/g 再次更新升级 apt update apt upgrade apt dist-upgrade apt autoremove 2. 开启 BBR 使用一键脚本安装并开启 bbr，此步除 OpenVZ 以外的服务器都可以开启，跳过不影响后续内容。 wget --no-check-certificate https://raw.githubusercontent.com/princelai/across/master/bbr.sh chmod +x bbr.sh ./bbr.sh echo \"net.core.default_qdisc=fq\" >> /etc/sysctl.conf echo \"net.ipv4.tcp_congestion_control=bbr\" >> /etc/sysctl.conf sysctl -p lsmod | grep bbr 3. 安装 shadowsocks-libev 和 simple-obfs 混淆 需要从 stretch-backports 库中安装，非 Debian 9 用户请参考 文档 sh -c 'printf \"deb http://deb.debian.org/debian stretch-backports main\" > /etc/apt/sources.list.d/stretch-backports.list' apt update apt -t stretch-backports install shadowsocks-libev simple-obfs 4. 优化 TCP 网络 编辑 sysctl 文件，把下面的内容复制过去， 如果第二步中没有开启 bbr，那么请删除前两行。 vim /etc/sysctl.conf net.core.default_qdisc = fq net.ipv4.tcp_congestion_control = bbr net.ipv4.tcp_fastopen = 3 fs.file-max = 1024000 net.core.rmem_max = 67108864 net.core.wmem_max = 67108864 net.core.rmem_default = 65536 net.core.wmem_default = 65536 net.core.netdev_max_backlog = 4096 net.core.somaxconn = 4096 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 0 net.ipv4.tcp_fin_timeout = 30 net.ipv4.tcp_keepalive_time = 1200 net.ipv4.ip_local_port_range = 10000 65000 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_rmem = 4096 87380 67108864 net.ipv4.tcp_wmem = 4096 65536 67108864 net.ipv4.tcp_mtu_probing = 1 net.ipv4.ip_forward = 1 更改保存后执行 sysctl -p 5. 配置服务端 修改配置 编辑配置文件，填上自己的密码，端口建议使用 443，别的端口封杀的太严重。 关于加密方式，现在新版都支持 AEAD 加密方式，详细内容请点 这里 。 vim /etc/shadowsocks-libev/config.json { \"server\" : \"0.0.0.0\" , \"server_port\" : 443 , \"local_port\" : 1080 , \"password\" : \"\" , \"timeout\" : 100 , \"method\" : \"chacha20-ietf-poly1305\" , \"mode\" : \"tcp_and_udp\" , \"fast_open\" : true , \"plugin\" : \"obfs-server\" , \"plugin_opts\" : \"obfs=tls\" } 启动服务器端服务 如果已经按照上面编辑好配置文件，那么就可以直接用文件模式启动服务。 ss-server -c config.json #测试模式 systemctl start shadowsocks-libev #后台启动 systemctl enable shadowsocks-libev #开机启动 6. 配置客户端 Windows 下载 shadowsocks-windows 解压缩， 下载 simple-obfs 中的 obfs-local.exe 和 msys-2.0.dll 放到 shadowsocks-windows 目录中,obfs-host 随意写一个中国可以访问的网站。 Linux 安装客户端和 obfs sudo pacman -Syu sudo pacman -S shadowsocks-libev simple-obfs 开启本地服务 nohup ss-local -c config.json --plugin obfs-local --plugin-opts \"obfs=tls;obfs-host=cn.bing.com\" 开机启动，编辑启动文件 ，添加 obfs 混淆 vim /usr/lib/systemd/system/shadowsocks-libev@.service [Unit] Description = Shadowsocks-Libev Client Service After = network.target [Service] Type = simple User = nobody CapabilityBoundingSet = CAP_NET_BIND_SERVICE ExecStart = /usr/bin/ss-local -c /etc/shadowsocks/%i.json --plugin obfs-local --plugin-opts \"obfs=tls;obfs-host=cn.bing.com\" [Install] WantedBy = multi-user.target 编辑配置文件 vim /etc/shadowsocks/libev.json { \"server\" : \"你的服务器IP\" , \"server_port\" : 443 , \"local_address\" : \"127.0.0.1\" , \"local_port\" : 65509 , \"password\" : \"你的密码\" , \"timeout\" : 300 , \"method\" : \"chacha20-ietf-poly1305\" , \"fast_open\" : true , \"workers\" : 1 , \"prefer_ipv6\" : false } 开启服务，@后面要和 json 文件同名 sudo systemctl start shadowsocks-libev@libev sudo systemctl enable shadowsocks-libev@libev 其他内容请参考 Archlinux Wiki shadowsocks-qt5 目前功能严重缺失，不建议使用，Linux 平台最好是命令行模式 SwitchyOmega 是目前 Chome 最好的代理插件，可以在 官网 下载最新版本安装。 7.Android 客户端配置 如果 Android 手机可以访问 Google Play，则可以直接在上面搜 shadowsocks 和 obfs 分别安装后再配置即可。 如果当前手机不能访问 Play，可以在 github releases 上分别下载 shadowsocks-android 和 simple-obfs-android ，安装后再配置自己的服务端信息。 8.socks5 转 http/https 实际使用中，经常会遇到命令行终端或本地程序需要代理，但是他们只支持 http 或 https 协议，所以就需要把 socks5 协议的代理转换协议，以 Archlinux 为例，方法也很简单。 安装 privoxy sudo pacman -S privoxy 修改配置，找到如下两行打开注释，注意 listen 后的端口是未来我们要使用的端口，默认为 8118，forward 后的端口是 shadowsocks 使用的本地端口，这个依据自己的配置修改，不要忘了最后的\".\"。 sudo vim /etc/privoxy/config listen-address 127 .0.0.1:8118 forward-socks5t / 127 .0.0.1:65509 . 保存配置后，启动或重启服务 sudo systemctl start privoxy sudo systemctl restart privoxy 以后需要使用时，修改两个本地变量即可 echo https_proxy = 127 .0.0.1:8118 echo http_proxy = 127 .0.0.1:8118 9. 服务器端常用的命令 #测试ss+obfs是否正常启动 ss-server -c config.json --plugin obfs-server --plugin-opts \"obfs=http\" #查看obfs的进程编号 ps ax | grep obfs #查看ss的进程编号 ps ax | grep ss-server #查看ss监听端口 netstat -nlp | grep ss-server","tags":"IT 笔记","url":"https://www.solarck.com/shadowsocks-libev.html"},{"title":"配置 pip 和 conda","text":"首先需要确认已经安装 Python 环境，建议用于科学计算的朋友下载安装 Anaconda 或者 Miniconda 。 环境变量和启用配置 安装好后还需要把安装路径添加到系统环境变量 Linux 用户查看系统环境变量 echo $PATH Windows 用户查看系统环境变量 echo %PATH% 如果没有 Anaconda 的路径，就需要自己手动添加 Linux 用户编辑~/.bashrc，在最后添加以下内容，注意自己修改安装路径 export PATH = \" $HOME /anaconda3/bin: $PATH \" 最后再执行 source ~/.bashrc 如果没有效果，可是尝试编辑~/.profile 或 ~/.bash_profile 文件 zsh 或其他 shell 用户可以自行修改 Windows 用户在 cmd 执行如下命令，如果不是默认安装到用户目录，需要手动修改下路径。如果创建了自定义 env，那么 root 改为你自己的 env 名字。 set PATH = %USERPROFILE% \\A naconda3 ; %USERPROFILE% \\A naconda3 \\L ibrary \\b in ; %USERPROFILE% \\A naconda3 \\S cripts ; %PATH% activate root 更换源 conda 官方源非常慢，甚至有时候经常无法连接；pip 时快时慢，也是经常无法连接，所以我们把更新源换为国内的，加快更新速度。 pip 目前国内常用的 pip 源有 阿里云 和豆瓣。 Linux 用户编辑~/.pip/pip.conf 文件，粘贴以下内容 [global] index-url = https://pypi.doubanio.com/simple/ format = columns 或 [global] index-url = https://mirrors.aliyun.com/pypi/simple/ format = columns Windows 用户编辑% USERPROFILE %\\pip\\pip.ini，没有就新建一个，内容和 Linux 一样。 conda 目前国内常用的 conda 源有 清华 和 中科大 两个 Linux 和 Windows 用户执行下面的命令添加 conda 源 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes 更新 conda conda 常用更新命令 conda update XXX #更新XXX包 conda update --all #更新所有可更新的包到最新 conda update conda #conda整体升级，并不一定最新，但是稳定 conda update anaconda #同上 conda 其他常用命令 conda info #当前conda环境信息 conda install XXX #安装XXX conda search XXX #搜索XXX conda clean --all #清除无用包和缓存 conda list > a.txt #输出所有已安装的包 conda remove XXX #卸载XXX conda config --get channels #获取当前使用的源，配合下面的命令使用 conda config --remove channels https://XXX pip pip 常用更新命令 pip search XXX #搜索 pip install XXX #安装 pip uninstall XXX #卸载 pip list > b.txt #列出所有已安装的包 pip list -o #列出所有可更新的包 pip show XXX #查看包的路径和依赖等信息","tags":"IT 笔记","url":"https://www.solarck.com/config-pip-conda.html"},{"title":"openwrt 开启 Samba 作为共享中心","text":"为 Openwrt 接入一个大 U 盘，不用来作共享中心的话实在没什么用处了，这也是为日后脱机 BT 下载提供一个基础。 安装 opkg update opkg install samba36-server luci-app-samba 配置文件 samba 的配置文件只有两个，而且默认配置稍作修改就可以使用 root@openwrt:~# vi /etc/samba/smb.conf.template [ global ] netbios name = OpenWrt display charset = UTF-8 interfaces = 127 .0.0.1/8 lo 192 .168.3.1/24 fd73:3a9a:156::1/60 br-lan #内网IP server string = OpenWrt unix charset = UTF-8 workgroup = WORKGROUP browseable = yes deadtime = 30 domain master = yes encrypt passwords = true enable core files = no guest account = nobody #匿名用户 guest ok = yes #匿名用户 invalid users = root local master = yes load printers = no map to guest = Bad User max protocol = SMB2 min receivefile size = 16384 null passwords = yes #无需密码 obey pam restrictions = yes os level = 20 passdb backend = smbpasswd preferred master = yes printable = no security = user smb encrypt = disabled smb passwd file = /etc/samba/smbpasswd socket options = TCP_NODELAY IPTOS_LOWDELAY syslog = 2 use sendfile = yes writeable = yes #可写 root@openwrt:~# vi /etc/config/samba config samba option 'name' 'OpenWrt' option 'workgroup' 'WORKGROUP' option 'description' 'OpenWrt' option 'homes' '1' config 'sambashare' option 'name' 'Shares' option 'path' '/share' #samba所在目录 # option 'users' 'sandra' option 'guest_ok' 'yes' option 'create_mask' '0777' #所有用户可写 option 'dir_mask' '0777' #所有用户可写 option 'read_only' 'no' 我的配置是无需密码所有用户都可以访问，可上传可下载。 配置完还需要对目录进行权限提升 chmod a+w /share 或者更改文件夹用户 chown nobody:nobody /share 最后重启 samba 服务并开机启动 /etc/init.d/samba restart /etc/init.d/samba enable 访问 Windows 用户很容易访问，在网络邻居（网络）里就可以看到 WORKGROUP —> OPENWRT —>Share 文件夹了，但是 linux 用户需要一些其他命令。 1. 安装 g2sc yaourt -S g2sc 安装完就可以像 Windows 一样看到工作组和文件夹，但是只能下载，没有上传功能。 2. sambclient 安装工具 yaourt -S sambaclient 连接主机 kevin@kevin:pts/2 ~$: smbclient -L OPENWRT Enter kevins password: #没设密码直接回车 Sharename Type Comment --------- ---- ------- Shares Disk IPC$ IPC IPC Service ( OpenWrt ) Server Comment --------- ------- CHEN-PC OPENWRT OpenWrt Workgroup Master --------- ------- WORKGROUP OPENWRT kevin@kevin:pts/2 ~$: smbclient //OPENWRT/Shares #格式为//Servername/Sharename smb: \\> 出现了 smb 的命令行 get **** #下载某个文件 put **** #上传某个文件 更多命令输入?查看 3. mount 挂载 kevin@kevin:pts/2 ~$: mkdir /mnt/samba kevin@kevin:pts/2 ~$: sudo mount -t cifs -l //OPENWRT/Shares /mnt/samba 完成 由于安装了 Luci，所以开启了 uhttp 服务，把共享目录链接到/www 目录同样可以通过浏览器直接下载，相当于把 Samba 目录同样做成了 FTP 目录。 kevin@kevin:pts/2 ~$: ln -s /share /www/share Samba 共享就全部完成，之后再继续研究 BT 下载，配合 Samba 的共享就等于免费拥有了一个简版 NAS 。","tags":"IT 笔记","url":"https://www.solarck.com/openwrt-samba.html"},{"title":"用 extroot 为 openwrt 扩充存储空间","text":"水星这款 MW4350r 内存为 128M，运行很多程序都不在话下。但是却只提供了 8M Flash 存储空间，而路由器系统还占了 1.9M，剩下的 5M 空间不足以支持安装很多软件，比如我在安装 python 的时候就报错提示存储空间不足，这确实很郁闷，但幸好 Openwrt 还提供了 extroot 方式来扩展存储，来发挥路由器和 Openwrt 系统的真正实力。 pivot-overlay 还是 pivot-root？ 我把两种方式都试过，pivot-overlay 方式不能够把安装程序的位置移到 USB 存储装置上，但是 pivot-root 方式可以，所以我选择了后者。pivot-root 方式使/覆盖掉了/overlay 成为 rootfs，我认为这种方式更接近原生的 Linux 系统。 而从官方的文档来看，目前 pivot-root 已经没有以前的缺点和不足，选择哪个已经是个人需求而不是技术问题了。 网上大部分文章帖子都是 2009-2010 年间的，所以大部分可能都是 pivot-overlay 的。如果对这部分不太理解，请仔细阅读官方 Wiki： ExtRoot: How it works , The OpenWrt Flash Layout 安装必要的包 opkg update opkg install e2fsprogs kmod-usb-core kmod-usb2 kmod-usb-storage usbutils kmod-fs-ext4 block-mount e2fsprogs 包提供了 mkfs（mkfs.ext3,mkfs.ext4）、fsck 等工具。 kmod-usb2 只提供了 USb2.0 的驱动，如果你的是 USB1 .0（1.1）的，还需要单独安装驱动。 kmod-fs-ext4 是用来挂载 ext4 文件系统的，如果你想使用 ext3 文件格式就安装相应的包。 usbutils 不是必装，仅提供了 lsusb 命令。 格式化 U 盘 插好 U 盘后，先查看下是否被系统识别出来 root@openwrt: ~# lsusb Bus 001 Device 002 : ID 0781 :5571 SanDisk Corp. Cruzer Fit Bus 001 Device 001 : ID 1d6b:0002 Linux Foundation 2 .0 root hub root@openwrt: ~# ls /dev/sd* /dev/sda /dev/sda1 已经正确识别出来了，格式化系统为 ext4 mkfs.ext4 /dev/sda1 挂载到当前系统 mount /dev/sda1 /mnt 创建一个 128M 的 swap 文件 dd if = /dev/zero of = /mnt/swap bs = 2048 count = 65536 mkswap /mnt/swap swapon /mnt/swap extroot 把/目录下的文件迁移到 U 盘,pivot-root 方式，适用于 Barrier Breaker（trunk）版本 mkdir -p /tmp/cproot mount --bind / /tmp/cproot tar -C /tmp/cproot -cvf - . | tar -C /mnt/ -xf - umount /tmp/cproot 编辑 fstab 我的系统默认没有/etc/config/fstab 文件，可以用命令生成一个 block detect > /etc/config/fstab 编辑这个文件，添加下面这段配置 config mount option target / option device /dev/sda1 option fstype ext4 option options rw,sync option enabled 1 option enabled_fsck 0 重启后，查看下空间，如果类似我这样就是成功了 root@openwrt: ~# df -h Filesystem Size Used Available Use% Mounted on rootfs 7 .2G 169 .9M 6 .7G 2 % / /dev/root 1 .8M 1 .8M 0 100 % /rom tmpfs 61 .7M 1 .0M 60 .7M 2 % /tmp /dev/sda1 7 .2G 169 .9M 6 .7G 2 % / tmpfs 512 .0K 0 512 .0K 0 % /dev 大功告成，现在系统空间足够大了，任你怎么安装怎么下载。","tags":"IT 笔记","url":"https://www.solarck.com/openwrt-extroot.html"},{"title":"水星（Mercury）MW4530r 刷 Openwrt","text":"经过两天的不屑折腾，终于为我的 Mw4530r 安装上了 Openwrt。从最后安装成功往回看，其实整个过程非常简单，但是由于是第一次接触，走了不少弯路，本应该一个小时就完成的工作，却整整花了我两天时间。再次发篇文章庆祝下，也给其他朋友一些参考。 下载文件 水星这款路由器是 ar71xx 芯片的，因为较新，所以还没有官方的稳定版。在 Openwrt 的 snapshots/trunk 目录搜索下载我们需要的刷机文件，一般情况一个型号有两个文件，一个名字里带 factory，从其他固件系统刷 Openwrt 下载这个文件；一个名字带 sysupgrade，已经是 Openwrt 系统的用此文件升级。 刷机 组装好路由器，接通电源，电脑网卡口连接路由器任意 Lan 口，打开浏览器访问http://192.168.1.1 就可以看见水星的原厂界面。利用原厂固件的升级功能，提交下载好的 Openwrt 刷机文件即可直接刷机，非常的方便。稍等片刻等待路由器自动重启，此时刷机完成。 初始化 Openwrt 的固件是不带 UI 界面的，在安装用户界面之前，用户需要先进行简单的初始化工作。 使用 telnet 登陆路由器 telnet 192 .168.1.1 Linux 系统自带命令，Windows 用户需要在控制面板—>程序里面启用 telnet 功能。 修改登录密码 passwd 更改好密码后，dropbear（ssh）登录方式开启，telnet 登录方式关闭。 退出 telnet，用 ssh 方式登陆，Windows 用户可以下载 putty 登陆 exit ssh root@192.168.1.1 到此我们已经成功初始化了 Openwrt。 网络配置 强烈建议基础配置尤其是网络设置都使用 CLI 界面，切勿乱修改原始配置，我就在这里经历的惨痛的教训 我使用的是联通 ADSL ，所以需要拨号（pppoe）才能上网。 配置网络连接，修改 wan 部分 root@openwrt:~# vi /etc/config/network config interface 'wan' option ifname 'eth0.2' option proto 'pppoe' option username 'ISP提供的用户名' option password '密码' 或者用 uci 方式进行配置 uci set network.wan.proto = pppoe uci set network.wan.username = 'ISP提供的用户名' uci set network.wan.password = '密码' uci commit network ifup wan 配置 wifi，根据你的路由器配置生成一个默认的配置文件 wifi detect > /etc/config/wireless 重启后，互联网和 wifi 都应该已经正常工作，wifi 的密码和名称我们之后可以在 UI 界面修改，接下来安装用户界面。 用户界面 安装 Luci opkg update opkg install luci luci-ssl luci-i18n-chinese 启动 Luci 服务 /etc/init.d/uhttpd start /etc/init.d/uhttpd enable 打开浏览器输入http://192.168.1.1 ，就可以进入 WebUI 界面了，现在就可以向普通路由器一样进行管理了。 小提示 1.MW4530r 进入 failsafe 的方法是：路由器断电—>接通电源—>断续的按面板前的 WPS 键，直到 SYS 指示灯从慢闪变为快闪就是成功进入了 failsafe 模式了。 2.初始配置尽量用 CLI 方式配置（或 uci），最好不要用 WebUI。 3.不要乱动乱删配置文件，尤其是端口路由表（switch0）。 贴一张 Openwrt 的路由架构图，这张图帮助我理解了端口和路由的关系。","tags":"IT 笔记","url":"https://www.solarck.com/install-openwrt-on-mw4530r.html"},{"title":"修复变砖的 WNR2200","text":"手中有个 NetGear WNR2200 路由器，当初买这个就是看重可以刷机,但是买回来才发现只能刷 DD -wrt，于是就刷了 DD 安心的用了半年。 最近看到 Openwrt 的 trunk 目录里有我这款机器的固件了，立刻操刀刷起。不幸的是刷完后 telnet 不通网关，failsafe 模式也无法开启。无奈中发现 NetGear 官网提供了 tftp 小工具确实有效，让我变砖的路由器起死回生。 方法也很简单，官方文库里说明的很详细，这里简单记录下要点。 1.下载工具和路由器官方固件 2.打开下载好的软件，设置好网关 192.168.1.1，加载下载好的固件，密码不用填 3.断开路由器电源 10 秒左右，之后接通电源，立刻点击软件上的 Upgrade，等待修复完成 修复好后决定这个路由器还是老实的用 DD -wrt，抛开扩展性和一些不是特别常用的功能， DD -wrt 确实和所有路由器官方提供的固件一样人性化，当初刷完 DD -wrt 稳定运行了半年多，无重启、无断流，稳定性不是盖的。不想受 Openwrt 折磨的人可以在 DD -wrt 的 FTP 目录 里按照日期和型号索引自己的路由器。 当然自己也不会放弃 Openwrt，自己又入手了一个水星 MW4530r，300 元内可刷 Openwrt 的性价比神器,继续折腾 Openwrt 去了。 网件官方文库 工具下载地址 如果地址不可用，可 Google tftp2.exe","tags":"IT 笔记","url":"https://www.solarck.com/repair-wnr2200.html"}]}