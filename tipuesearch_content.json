{"pages":[{"title":"关于我","text":"还没写任何东西","tags":"pages","url":"https://www.solarck.com/pages/aboutme.html"},{"title":"简历","text":"还没制作","tags":"pages","url":"https://www.solarck.com/pages/resume.html"},{"title":"解决Haproxy用Systemd启动失败的问题","text":"问题描述 配置好Haproxy的配置文件，手动可以无错误开启，但是 Systemctl enable haproxy.service 开机启动每次都报错，系统启动后，手动开启还是没有问题。 分析原因 haproxy配置问题 /etc/haproxy.cfg 是配置文件，因为手动指定配合文件可以启动，而且测试配置文件也没有报错或警报，所以首先排除是配置的问题。 systemd服务配置问题 haproxy.service 是systemd用来启动服务的配置文件，第一眼看配置后，以为是创建PID没有权限，增加 User=root 字段，但是重启后依然报错。原版配置只有 After=network.target ，手动添加 Wants=network.target 重启后，依然报错。 查看日志 正要灰心的时候，决定最后一搏，查看systemd启动日志，看看能不能找到点线索。 查看最近一次启动中haproxy的日志 journalctl -b -0 -u haproxy Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : haproxy.service: Main process exited, code = exited, status = 1 /FAILURE Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : haproxy.service: Failed with result 'exit-code' . Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : Failed to start HAProxy Load Balancer. Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : haproxy.service: Service RestartSec = 100ms expired, scheduling restart. Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : haproxy.service: Scheduled restart job, restart counter is at 1 . Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : Stopped HAProxy Load Balancer. Jul 13 10 :32:20 kevin-pc systemd [ 1 ] : Starting HAProxy Load Balancer... Jul 13 10 :32:20 kevin-pc haproxy [ 554 ] : [ ALERT ] 193 /103220 ( 554 ) : parsing [ /etc/haproxy/haproxy.cfg:36 ] : 'server server1' : could not resolve address 'xxxx.com' . Jul 13 10 :32:20 kevin-pc haproxy [ 554 ] : [ ALERT ] 193 /103220 ( 554 ) : parsing [ /etc/haproxy/haproxy.cfg:37 ] : 'server server2' : could not resolve address 'xxxx.com' . Jul 13 10 :32:20 kevin-pc haproxy [ 554 ] : [ ALERT ] 193 /103220 ( 554 ) : parsing [ /etc/haproxy/haproxy.cfg:38 ] : 'server server3' : could not resolve address 'xxxx.com' . 原因找到了，原来是我在haproxy配置文件的backend段中，使用了域名而不是IP，导致解析失败。但是明明我已经指定了haproxy的启动在network之后了，为什么还是会这个样子呢？ 答案只能从network的服务中找 journalctl -b -0 -u NetworkManager Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2279 ] dhcp4 ( enp0s25 ) : activation: beginning transaction ( timeout in 45 seconds ) Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2566 ] dhcp4 ( enp0s25 ) : address 172 .168.201.33 Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2566 ] dhcp4 ( enp0s25 ) : plen 24 Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2566 ] dhcp4 ( enp0s25 ) : expires in 86400 seconds Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2567 ] dhcp4 ( enp0s25 ) : nameserver '172.168.13.100' Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2567 ] dhcp4 ( enp0s25 ) : nameserver '202.106.0.20' Jul 13 10 :32:22 kevin-pc NetworkManager [ 493 ] : <info> [ 1531449142 .2567 ] dhcp4 ( enp0s25 ) : gateway 172 .168.201.1 对比两段日志的时间，原来虽然haproxy启动在network之后，但是network刚刚启动haproxy就开始启动，而network的启动内容比较多，还有很多网络通信，可能完全启动完需要一点时间。haproxy的启动时间比dhcp启动要早了2秒，这时无法进行DNS解析，所以就会造成启动失败，之前的所有问题也都说的通了。 解决方法 知道了问题的原因，那么就要解决它。只要让haproxy在network完全启动后再启动，就应该可以正常启动了。那么如何做呢？ 首先要替换 haproxy.service 中的 After 和 Wants 字段，用 network-online.target 替换 network.target After = network-online.target Wants = network-online.target 然后启动一个自带的网络等待服务 sudo systemctl enable NetworkManager-wait-online.service 如果你是使用 systemd-network 来管理网络服务，那么需要启动另外一个服务 sudo systemctl enable systemd-networkd-wait-online.service 重启后，一切问题都解决了。 参考 Running Services After the Network is up","tags":"IT笔记","url":"https://www.solarck.com/systemd-wait-network-online.html"},{"title":"快速配置V2ray","text":"服务器端配置 服务器系统使用的是Debian 9 x86_64，Ubuntu大部分操作都通用。如果是CentOS的话，该文章仅作为参考。 优化网络 主要涉及bbr的安装配置，需要VPS是KVM架构，具体可以参照 之前的文章 。 安装V2ray 官方提供了安装脚本，需要系统使用systemd管理系统 wget https://install.direct/go.sh bash go.sh 安装好后，主要文件如下： /etc/systemd/system/v2ray.service ：启动服务 /etc/v2ray/config.json ：配置文件 /usr/bin/v2ray/v2ray ：主程序 TLS域名证书 因为最终配置要用到TLS链接，在这步之前，你需要一个域名，免费的也无所谓。 工具使用 acme.sh ，这是用来签发 Let's Encrypt 免费证书的脚本，非常好用。 安装acme 安装依赖工具 apt-get install -y socat netcat 安装acme.sh脚本 curl https://get.acme.sh | sh 默认是安装在 ～/.acme.sh/ 签发证书 我使用的是ecc证书，需要把domain换成自己的域名 ~/.acme.sh/acme.sh --issue -d domain --standalone -k ec-256 安装证书 证书会被安装到 /etc/v2ray 目录下 ~/.acme.sh/acme.sh --installcert -d domain --fullchainpath /etc/v2ray/v2ray.crt --keypath /etc/v2ray/v2ray.key --ecc 证书续期 执行完签发命令后，系统已经加上了crond自动签发，如果你想手动签发，可以执行下面的命令。 ~/.acme.sh/acme.sh --renew -d domain --force --ecc 本地配置 安装 因为我使用的是Manjaro，一个基于Archlinux的Linux版本，所有安装只要一条命令 yaourt -Sy v2ray 如果你用的是其他系统，可以参考服务器的安装脚本。 配置文件 配置说明 我当前使用的连接方式是TCP+TLS这种，根据官方和网上收集的信息，据说当前最好的配置是WebSocket+ WEB + TLS + CDN ，我没有选择这种连接方式有以下几点原因： Websocket效率低于TCP 多层转发导致速度可能会变慢 配置较麻烦 如果你的ISP没有QOS，没有TCP阻断，你连接服务器的流量没有很大的话，是没有必要折腾这种连接方式的。当然我在写这篇文章之前还使用过H2+TLS的连接方式，但是不知是服务器没有加Caddy转发还是H2方式不稳定，断流严重，换成TCP+TLS后，连接稳定，速度尚可，未出现断流。 每个人每个地区的ISP情况不尽相同，所以多试才能找到最适合你的配置，更多配置可以参考 配置模板 。 TCP +TLS配置 配置说明 我有三台性能较弱的VPS，所以三台分别安装并部署了服务端的配置，而在本地客户端的outbound中连接三个服务器，v2ray可以进行简单的轮寻进行负载均衡。 为了简化操作，UUID设置为相同，当然不嫌麻烦的话可以设置为不同，但要和每台服务器的UUID相对应。 因为我认为vmess协议加密已经足够强壮，所以每台就没有再设置内容加密，如果不放心，可以使用auto或者AEAD方式加密。另外根据官方的测试，貌似 aes-256-gcm 和 chacha20-ietf-poly1305 两种加密方式传输效率比不加密的效率还要高，可能与硬件加密有关系吧。 所有配置的详细内容都可以在官方文档或白话文教程里找到，其实配置v2ray并没有那么复杂。 最后贴上我的自用配置，生成UUID可以使用 UUID Generator 这个网站，或者Linux用户可以使用下面命令 cat /proc/sys/kernel/random/uuid 生成。 服务端 { \"log\" : { \"loglevel\" : \"warning\" , \"access\" : \"/var/log/v2ray/access.log\" , \"error\" : \"/var/log/v2ray/error.log\" }, \"inbound\" : { \"port\" : 443 , \"protocol\" : \"vmess\" , \"settings\" : { \"clients\" : [ { \"id\" : \"xxxxxxxxx-xxxxxxxxxxx-xxxxxx\" , \"alterId\" : 32 , \"security\" : \"none\" , \"udp\" : true } ] }, \"streamSettings\" : { \"network\" : \"tcp\" , \"security\" : \"tls\" , \"tlsSettings\" : { \"certificates\" : [ { \"certificateFile\" : \"/etc/v2ray/v2ray.crt\" , \"keyFile\" : \"/etc/v2ray/v2ray.key\" } ] } } }, \"outbound\" : { \"protocol\" : \"freedom\" , \"settings\" : {} }, \"outboundDetour\" : [ { \"protocol\" : \"blackhole\" , \"settings\" : {}, \"tag\" : \"blocked\" } ], \"routing\" : { \"strategy\" : \"rules\" , \"settings\" : { \"rules\" : [ { \"type\" : \"field\" , \"ip\" : [ \"geoip:private\" ], \"outboundTag\" : \"blocked\" } ] } } } 客户端 { \"log\" : { \"loglevel\" : \"warning\" , \"access\" : \"/var/log/v2ray/access.log\" , \"error\" : \"/var/log/v2ray/error.log\" }, \"inbound\" : { \"port\" : 1080 , \"protocol\" : \"socks\" , \"domainOverride\" : [ \"tls\" , \"http\" ], \"settings\" : { \"auth\" : \"noauth\" , \"udp\" : true } }, \"outbound\" : { \"protocol\" : \"vmess\" , \"settings\" : { \"vnext\" : [ { \"address\" : \"domain.com\" , \"port\" : 443 , \"users\" : [ { \"id\" : \"xxxxxxxxx-xxxxxxxxxxx-xxxxxx\" , \"alterId\" : 32 , \"security\" : \"none\" } ] }, { \"address\" : \"domain.com\" , \"port\" : 443 , \"users\" : [ { \"id\" : \"xxxxxxxxx-xxxxxxxxxxx-xxxxxx\" , \"alterId\" : 32 , \"security\" : \"none\" } ] }, { \"address\" : \"domain.com\" , \"port\" : 443 , \"users\" : [ { \"id\" : \"xxxxxxxxx-xxxxxxxxxxx-xxxxxx\" , \"alterId\" : 32 , \"security\" : \"none\" } ] } ] }, \"streamSettings\" : { \"network\" : \"tcp\" , \"security\" : \"tls\" } }, \"outboundDetour\" : [ { \"protocol\" : \"freedom\" , \"settings\" : {}, \"tag\" : \"direct\" } ], \"dns\" : { \"servers\" : [ \"101.6.6.6\" , \"101.132.183.99\" , \"193.112.15.186\" , \"8.8.8.8\" ] }, \"routing\" : { \"strategy\" : \"rules\" , \"settings\" : { \"domainStrategy\" : \"IPIfNonMatch\" , \"rules\" : [ { \"type\" : \"field\" , \"port\" : 53 , \"network\" : \"udp\" , \"outboundTag\" : \"direct\" }, { \"type\" : \"field\" , \"ip\" : [ \"geoip:cn\" , \"geoip:private\" , \"172.168.0.0/16\" ], \"port\" : \"0-10000\" , \"network\" : \"tcp,udp\" , \"outboundTag\" : \"direct\" }, { \"type\" : \"field\" , \"domain\" : [ \"geosite:cn\" ], \"port\" : \"0-10000\" , \"network\" : \"tcp,udp\" , \"outboundTag\" : \"direct\" } ] } } } 参考 v2ray官方文档 v2ray白话文教程 acme.sh wiki","tags":"IT笔记","url":"https://www.solarck.com/v2ray-quick-config.html"},{"title":"LEDE /OpenWRT路由器打造家庭媒体影音中心（二）","text":"USB驱动 查看已安装的驱动 opkg update opkg list-installed | grep usb 安装驱动和工具 如果下列驱动未出现在上一步的结果中，请务必首先安装缺失的驱动 opkg install kmod-usb-core kmod-usb-storage kmod-usb-core :USB核心驱动 kmod-usb-storage :大容量存储设备驱动 kmod-usb2 :WRT1900ACS有一个USB2.0/eSATA口，可以不安装 kmod-ata-marvell-sata :Marvell SATA接口驱动，可以不安装 网上搜到的教程和官方指南里还让安装一些其他的应用，但这些都是不必要或已被编译至内核中，包括： kmod-usb-ohci 、 kmod-usb-uhci 、 kmod-usb3 、 kmod-usb-storage-uas 安装相关工具 opkg install usbutils block-mount e2fsprogs kmod-fs-ext4 gdisk fdisk mount-utils :提供unmount,findmnt usbutils :提供lsusb block-mount :提供block，查看挂载点信息 e2fsprogs :格式化工具mkfs kmod-fs-ext4 :格式化为ext4格式 kmod-fs-ntfs :我不用ntfs格式，所以不安装这个，需要可以安装上 gdisk :分区工具，支持GPT，硬盘容量超过2T需要用这个工具，当然容量小的也可以用这个 fdisk :分区工具，不支持GPT，常用来查看分区信息 以下几个命令查看已连接/挂载的USB设备 df -h lsusb -t ls -l /dev/sd* block info | grep \"/dev/sd\" 小提示：硬盘格式化为什么格式最好？ 在Linux和LEDE平台上，微软的NTFS和FAT32绝对不是一个好的格式，设计的优劣不谈，这两个格式不是Linux平台原生支持的，安装额外的驱动可能会带来发热、读写速度慢、不稳定等多种负面效果。所以，对于机械硬盘来说，EXT4和BTRFS是最好的，对于SSD来说，F2FS格式是最好的。 硬盘相关操作 硬盘分区 gdisk /dev/sda 根据软件提示进行操作，主要命令有： n :新建分区 w :保存分区内容 d :删除分区 p :打印分区列表 ? :查看帮助 这里我把一块硬盘分为两个区 /dev/sda1 ， /dev/sda2 ，分区1大小700G，分区2大小231G，总计1T。 格式化硬盘 mkfs.ext4 /dev/sda1 mkfs.ext4 /dev/sda2 如果是SSD硬盘，则可以按照如下方式安装操作 opkg install f2fs-tools opkg install kmod-fs-f2fs mkfs.f2fs /dev/sda1 自动挂载分区 这一部分请根据自己 fstab 实际内容修改使用 block detect > /etc/config/fstab uci set fstab.@mount [ 1 ] .enabled = '1' uci set fstab.@mount [ 2 ] .enabled = '1' uci set fstab.@mount [ 1 ] .options = 'rw' uci set fstab.@mount [ 2 ] .options = 'rw' uci set fstab.@global [ 0 ] .check_fs = '1' uci commit 查看当前挂载点设置 uci show fstab 卸载/挂载服务 block umount && block mount 硬盘休眠 hdparm opkg update opkg install hdparm luci-app-hd-idle 执行下面的命令启动休眠 hdparm -S 120 /dev/sda1 hdparm -S 120 /dev/sda2 -S后的参数含义为： 0:关闭休眠 1-240：数字乘以5秒是时间，在设定时间内未使用则休眠 241-251：以30分钟为步进，时间为30分钟-5.5小时 hd-idle 更简单的方法就是安装Luci管理工具 opkg update opkg install hd-idle luci-app-hd-idle Samba 安装Samba 查看可安装的版本 opkg update opkg list | grep samba 根据结果，安装适当的版本 opkg install samba36-server luci-app-samba luci-i18n-samba-zh-cn 配置防火墙 vim /etc/config/firewall config 'rule' option 'src' 'lan' option 'proto' 'udp' option 'dest_port' '137-138' option 'target' 'ACCEPT' config 'rule' option 'src' 'lan' option 'proto' 'tcp' option 'dest_port' '139' option 'target' 'ACCEPT' config 'rule' option 'src' 'lan' option 'proto' 'tcp' option 'dest_port' '445' option 'target' 'ACCEPT' Samba配置 官方 强烈建议 使用luci来配置Samba，然后通过修改临时文件来完成配置。 路由器每次重启， /etc/samba/smb.conf 文件都将从 /etc/samba/smb.conf.template 文件重新创建，所以修改配置时请修改后者。 全局和共享配置可以在LuCi界面编辑也可以直接编辑文件，按照我的配置实现如下几个功能： 禁止root用户访问，防止权限出现问题 允许匿名用户访问 /mnt/sda1 ，即Media文件夹 访问 /mnt/sda2 ，即Document文件夹必须登录，用户只能访问到自己创建的文件夹和文件 全局配置 vim /etc/samba/smb.conf.template [ global ] #netbios name = LEDE #不设置默认是路由器host名 #workgroup = LEDE #不设置默认是WORKGROUP server string = Samba on LEDE syslog = 5 encrypt passwords = true socket options = TCP_NODELAY IPTOS_LOWDELAY unix charset = UTF-8 browseable = yes local master = yes preferred master = yes security = user null passwords = yes guest account = nobody invalid users = root passdb backend = smbpasswd smb passwd file = /etc/samba/smbpasswd map to guest = Bad User 共享文件夹设置 vim /etc/config/samba config samba option charset 'UTF-8' option homes '0' option interface 'loopback lan' option name 'Lede' option description 'Samba on Lede' option workgroup 'Lede' config sambashare option name 'Media' option path '/mnt/sda1' option read_only 'no' option guest_ok 'yes' option create_mask '0777' option dir_mask '0777' config sambashare option path '/mnt/sda2' option read_only 'no' option create_mask '0700' option dir_mask '0700' option name 'Document' option guest_ok 'no' 文件夹初始权限设置 /mnt/sda2 其实没必要更改所属用户和组，但是强迫症就是要给统一了。 chown -R nobody /mnt/sda1 chgrp -R nogroup /mnt/sda1 chmod -R 777 /mnt/sda1 chown -R nobody /mnt/sda2 chgrp -R nogroup /mnt/sda2 chmod -R 777 /mnt/sda2 添加用户 LEDE默认不带 useradd 命令，需要手动安装 opkg update opkg install shadow-useradd 添加用户和设置密码要分两步走，首先要添加系统用户，然后再为该用户设置Samba密码。 useradd newuser passwd newuser smbpasswd -a newuser 最后启动/重启服务 /etc/init.d/samba restart /etc/init.d/samba enable 至此，Samba设置完成，也达到了我的目的，有可以匿名随意访问的共享文件夹，也有实现了权限控制的私有文件夹。而且是全平台都可以访问，Windows、Linux和手机（需要有支持SMB协议的软件）。 参考链接 Installing USB Drivers Using storage devices Share USB Hard-drive with Samba using the Luci web-interface SMB Samba share overview cifs.server Samba","tags":"IT笔记","url":"https://www.solarck.com/lede-media-center2.html"},{"title":"LEDE /OpenWRT路由器打造家庭媒体影音中心（一）","text":"前言 软/硬件 软件：本文系统都是基于LEDE 17.01.4 硬件：Linksys WRT1900ACS V2 其他：一台电脑，最好是Linux带SSH，Windows的话可以下个putty安装上 前提：我不会从头写起，而是从路由器已刷好LEDE 17.01.4，WAN口已联网，且已经可以SSH登录之后开始，其他外设，如硬盘、硬盘盒、用于Extroot的U盘都已准备好。 实现目的 基于Linksys WRT1900ACS强悍的性能和扩展功能丰富的LEDE，打造一个有权限控制的NAS，支持DLNA，可以离线下载和远程访问的DDNS系统的多媒体中心。 Extroot extroot的作用就是扩充存储空间，这样就可以安装更多的软件。详细介绍可以查看很早之前我写过的一篇文章—— 用extroot为openwrt扩充存储空间 ，这里就不赘述了。由于那篇文章比较老，LEDE也早已经升级了好几个含本，所以实际的操作还是以下面的内容为主。 安装工具 这里我准备把U盘格式化为f2fs格式，关于各种存储格式和下面需要安装的工具的作用，我会放在下一篇文章一起讲，这一步照着做就可以了。 opkg update opkg install block-mount kmod-fs-ext4 kmod-usb-storage e2fsprogs kmod-fs-f2fs f2fs-tools 格式化U盘 mkfs.f2fs /dev/sda1 迁移系统 mount /dev/sda1 /mnt ; tar -C /overlay -cvf - . | tar -C /mnt -xf - ; umount /mnt 生成分区表 block detect > /etc/config/fstab uci set fstab.@mount[0].target='/overlay' uci set fstab.@mount[0].enabled='1' uci set fstab.@mount[0].options='rw' uci set fstab.@mount[0].fstype='f2fs' uci commit 最后 fstab 应该如下 cat /etc/config/fstab config global option anon_swap '0' option anon_mount '0' option auto_swap '1' option auto_mount '1' option delay_root '5' option check_fs '1' config mount option enabled '1' option uuid 'd9aa4451-780a-4fe5-b08d-d7f0a7ae0ba4' option target '/overlay' option fstype 'f2fs' option options 'rw' 验证 重启系统后执行命令 df -h Filesystem Size Used Available Use% Mounted on /dev/root 2.8M 2.8M 0 100% /rom tmpfs 250.8M 556.0K 250.2M 0% /tmp /dev/sdb1 14.3G 496.6M 13.7G 3% /overlay overlayfs:/overlay 14.3G 496.6M 13.7G 3% / ubi1:syscfg 29.6M 268.0K 27.8M 1% /tmp/syscfg tmpfs 512.0K 0 512.0K 0% /dev 如果 /overlay 分区已经变为U盘容量大小，那就是成功了。 block info 信息也已经显示正确 /dev/mtdblock7: TYPE=\"jffs2\" /dev/ubiblock0_0: UUID=\"9f419b56-31564c19-0a0c1b12-a2f9b77b\" VERSION=\"4.0\" MOUNT=\"/rom\" TYPE=\"squashfs\" /dev/ubi0_1: UUID=\"1361ff26-cc87-40f1-8b99-00caf223093c\" VERSION=\"w4r0\" TYPE=\"ubifs\" /dev/ubi1_0: UUID=\"413d13a9-0f0a-4811-a0cb-3e3786ce26d7\" VERSION=\"w4r0\" TYPE=\"ubifs\" /dev/sda1: UUID=\"d9aa4451-780a-4fe5-b08d-d7f0a7ae0ba4\" VERSION=\"1.8\" MOUNT=\"/overlay\" TYPE=\"f2fs\" 更换源 添加对https的支持 如果你在替换源后执行更新，那么会收到一条错误消息： SSL support not available, please install one of the libustream-ssl-* libraries as well as the ca-bundle and ca-certificates packages. 很明显，系统还不支持SSL，因为官方的源都是http的，而我们添加的源都是https的。不过也很简单，按照错误信息的提示安装相应的包就可以了。 这一步一定要在替换源之前执行 opkg update opkg install ca-certificates luci-ssl-openssl 更换源 国内访问LEDE官方源比较不稳定，速度也很慢，幸好 中科大 和 清华 都提供了LEDE的软件镜像源，为了后边操作能够顺利进行，首先需要更换源。 LEDE OPKG的软件源配置文件有两个： /etc/opkg/distfeeds.conf ：发行版本自带的官方源，需要把里面的内容全部注释掉或者清空。 /etc/opkg/customfeeds.conf ：自定义源，把我们需要的内容粘贴到这里，内容如下： src/gz reboot_core https://mirrors.ustc.edu.cn/lede/releases/17.01.4/targets/mvebu/generic/packages src/gz reboot_base https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/base src/gz reboot_luci https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/luci src/gz reboot_packages https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/packages src/gz reboot_routing https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/routing src/gz reboot_telephony https://mirrors.ustc.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/telephony #src/gz reboot_core https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/targets/mvebu/generic/packages #src/gz reboot_base https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/base #src/gz reboot_luci https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/luci #src/gz reboot_packages https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/packages #src/gz reboot_routing https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/routing #src/gz reboot_telephony https://mirrors.tuna.tsinghua.edu.cn/lede/releases/17.01.4/packages/arm_cortex-a9_vfpv3/telephony 更新系统 镜像源替换完成后，把所有已安装程序全部更新到最新 opkg update opkg list-upgradable | cut -f 1 -d ' ' | xargs opkg upgrade 其他 汉化 opkg update opkg install luci-i18n-base-zh-cn 参考链接 How to get rid of LuCI https certificate warnings Extroot configuration","tags":"IT笔记","url":"https://www.solarck.com/lede-media-center1.html"},{"title":"CentOS6数据库服务器配置","text":"本文章仅用于记录在公司服务器上通过yum repo来安装官方提供的数据库程序，而非通过编译方式来安装。通过官方仓库来安装有很多好处，比如升级、打补丁都很方便，不用编译浪费时间，更不需要安装多个版本的gcc来满足各种不同软件的要求。 Mysql 下载安装mysql repo rpm -Uvh https://repo.mysql.com//mysql80-community-release-el6-1.noarch.rpm 升级至57版本 yum --disablerepo=mysql80-community --enablerepo=mysql57-community upgrade 当前默认是80版本，如果未来需要升级，如果未来一直要维持在57版本，那么建议修改配置文件，以免每次都带上两个参数 vim /etc/yum.repos.d/mysql-community.repo # Enable to use MySQL 5.7 [mysql57-community] name = MySQL 5.7 Community Server baseurl = http://repo.mysql.com/yum/mysql-5.7-community/el/6/$basearch/ enabled = 1 gpgcheck = 1 gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql [mysql80-community] name = MySQL 8.0 Community Server baseurl = http://repo.mysql.com/yum/mysql-8.0-community/el/6/$basearch/ enabled = 0 gpgcheck = 1 gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 安装mysql-server yum install mysql-community-server 开启服务 service mysqld start 当然这时候还未配置mysql，开启服务可能会失败。默认配置文件在 /etc/my.cnf 。 更多安装细节可以参照 mysql官方指南 。 Mongo 创建repo文件 vim /etc/yum.repos.d/mongodb-org-3.6.repo [mongodb-org-3.6] name = MongoDB Repository baseurl = https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/ gpgcheck = 1 enabled = 1 gpgkey = https://www.mongodb.org/static/pgp/server-3.6.asc 安装mongo组件合集 yum install -y mongodb-org mongo-org是一个合集，如果想精简安装各个组件，请参照下表。 Package Name Description mongodb-org A metapackage that will automatically install the four component packages listed below. mongodb-org-server Contains the mongod daemon and associated configuration and init scripts. mongodb-org-mongos Contains the mongos daemon. mongodb-org-shell Contains the mongo shell. mongodb-org-tools Contains the following MongoDB tools: mongoimport bsondump, mongodump, mongoexport, mongofiles, mongoperf, mongorestore, mongostat, and mongotop. 启动服务 mongod -f /etc/mongod.conf mongo默认不加载conf文件，所以用service方法是无法正常启动的，暂时使用自带方法开启服务。 更多安装细节可以参照 mongo官方指南 。 Nginx 创建repo文件 vim /etc/yum.repos.d/nginx.repo [nginx] name = nginx repo baseurl = http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck = 0 enabled = 1 安装和开启服务 yum install -y nginx service nginx start service方法启动nginx默认会加载 /etc/nginx/nginx.conf 配置。 查看系统安装路径 使用仓库安装有一点不是很清晰，那就是安装目录并非自己指定，有时需要修改一些文件时找不到文件在哪里，我们可以通过如下方法找到软件的所有文件目录。 rpm -qa |grep mongodb mongodb-org-mongos-3.6.5-1.el6.x86_64 mongodb-org-server-3.6.5-1.el6.x86_64 mongodb-org-tools-3.6.5-1.el6.x86_64 mongodb-org-3.6.5-1.el6.x86_64 mongodb-org-shell-3.6.5-1.el6.x86_64 例如我们要查看server的所有文件目录，则执行 rpm -ql mongodb-org-server-3.6.5-1.el6.x86_64 /etc/init.d/mongod /etc/mongod.conf /etc/sysconfig/mongod /usr/bin/mongod /usr/share/doc/mongodb-org-server-3.6.5 /usr/share/doc/mongodb-org-server-3.6.5/GNU-AGPL-3.0 /usr/share/doc/mongodb-org-server-3.6.5/MPL-2 /usr/share/doc/mongodb-org-server-3.6.5/README /usr/share/doc/mongodb-org-server-3.6.5/THIRD-PARTY-NOTICES /usr/share/man/man1/mongod.1 /var/lib/mongo /var/log/mongodb /var/log/mongodb/mongod.log /var/run/mongodb SSH免密登录服务器 Linux上免密登录通常用RSA公钥和密钥实现，本地生成钥匙后，公钥上传至服务器，之后便可以免密登录了。 本地生成公钥密钥 ssh-keygen -t rsa -b 4096 默认公钥会存储在 ~/.ssh/id_rsa.pub ，备用。 修改服务器sshd配置 vim /etc/ssh/sshd_config PubkeyAuthentication yes #解开注释 AuthorizedKeysFile .ssh/authorized_keys #解开注释 上传本地公钥至服务器 ssh-copy-id -i .ssh/id_rsa.pub -p port user@ip 修改上面的端口、用户名和ip，再在本地 .bashrc 或 .zshrc 新建一条alias就可以非常方便快捷的登录了。","tags":"IT笔记","url":"https://www.solarck.com/centos6-datebase-server.html"},{"title":"使用Python发送Gmail","text":"本文基于一个真实的项目，使用python3.6和最新官方smtplib接口。项目的目的是爬取网站，然后通过邮件给自己发送邮件提醒新文章。最后使用linux系统的crond服务定时执行。 发邮件方法 在定义发邮件方法之前，我们还定义了一个类和类中的爬虫，单拿出来发邮件来说，代码如下： def sent_email ( self ): fromaddr = 'princelailai@gmail.com' toaddrs = [ 'princelailai@gmail.com' ] subject = \"{}{}\" . format ( datetime . now () . strftime ( '%Y年%m月 %d 日' ), '共有产权房信息' ) msg = '' . join ([ '日期: \\t {} \\n 标题: \\t {} \\n 地址: \\t {} \\n\\n ' . format ( v [ 0 ], v [ 1 ], k ) for k , v in self . result . items ()]) message = MIMEText ( msg , 'plain' , 'utf-8' ) message [ 'From' ] = Header ( fromaddr , 'utf-8' ) message [ 'To' ] = Header ( ',' . join ( toaddrs ), 'utf-8' ) message [ 'Subject' ] = Header ( subject , 'utf-8' ) #message = f\"From: {fromaddr}\\nTo: {','.join(toaddrs)}\\nSubject: {subject}\\n\\n{msg}\" username = 'princelailai@gmail.com' password = 'app password' try : server = smtplib . SMTP ( 'smtp.gmail.com' , '587' ) server . ehlo () server . starttls () server . login ( username , password ) server . sendmail ( fromaddr , toaddrs , message . as_string ()) server . quit () logging . info ( 'Send Email Successful.' ) except : logging . info ( 'Send Email Failed.' ) 需要注意的有几点： 邮件正文需要是MIMEText格式的 发信人、收信人、主题要用Header添加 如果你的Google账号开启了两步验证，那么你的邮箱密码就不是登录密码，而是app密码，关于app密码怎么生成可以查看这篇文章 Sign in using App Passwords 其他关于smtp地址和端口的问题，可以查看这篇文章 Use IMAP to check Gmail on other email clients 定时启动 创建一个文本文件，用于创建单一用户的crond文件 0 6 */3 * * /root/miniconda3/bin/python /root/monitor_house_info/monitor_house_info.py 关于crond配置，网上教程很多，或者 man 5 crontab 就可以看到详细的用法。 最后输入 crontab file 导入文件，就可以坐等收邮件了。 全部代码 #!/usr/bin/env python3 # -*- coding: utf-8 -*- from requests_html import HTMLSession import smtplib import os import json import logging from datetime import datetime from email.mime.text import MIMEText from email.header import Header logging . basicConfig ( format = ' %(asctime)s : %(levelname)s : %(message)s ' , level = logging . INFO ) class monitor_house_info : def __init__ ( self ): self . realpath = os . path . split ( os . path . realpath ( __file__ ))[ 0 ] self . realdb = os . path . join ( self . realpath , 'db.json' ) self . result = {} self . url = [ 'http://cpzjw.bjchp.gov.cn/cpzjw/336693/index.html' , 'http://cpzjw.bjchp.gov.cn/cpzjw/336551/336554/index.html' ] def read_json ( self ): if not os . path . exists ( self . realdb ): self . db = {} else : with open ( self . realdb ) as f : self . db = json . loads ( f . read ()) logging . info ( 'Readed json db.' ) def get_news ( self , url ): session = HTMLSession () resp = session . get ( url ) element_date = resp . html . find ( 'div.easysite-article-content > ul > li > span.date04' ) date = [ i . text [ 1 : - 1 ] for i in element_date ] element_content = resp . html . find ( 'div.easysite-article-content > ul > li > span.title04' ) content = [ i . text . strip () for i in element_content ] link = [ list ( i . absolute_links )[ 0 ] for i in element_content ] for l , d , c in zip ( link , date , content ): self . result [ l ] = [ d , c ] logging . info ( 'geted web content.' ) def valid_news ( self ): for k in self . result . keys (): if k in self . db : self . result . pop ( k ) with open ( self . realdb , 'w' ) as fp : self . db . update ( self . result ) fp . write ( json . dumps ( self . db , ensure_ascii = False )) logging . info ( 'valided news.' ) def sent_email ( self ): fromaddr = 'princelailai@gmail.com' toaddrs = [ 'princelailai@gmail.com' ] subject = \"{}{}\" . format ( datetime . now () . strftime ( '%Y年%m月 %d 日' ), '共有产权房信息' ) msg = '' . join ([ '日期: \\t {} \\n 标题: \\t {} \\n 地址: \\t {} \\n\\n ' . format ( v [ 0 ], v [ 1 ], k ) for k , v in self . result . items ()]) message = MIMEText ( msg , 'plain' , 'utf-8' ) message [ 'From' ] = Header ( fromaddr , 'utf-8' ) message [ 'To' ] = Header ( ',' . join ( toaddrs ), 'utf-8' ) message [ 'Subject' ] = Header ( subject , 'utf-8' ) username = 'princelailai@gmail.com' password = 'app password' try : server = smtplib . SMTP ( 'smtp.gmail.com' , '587' ) server . ehlo () server . starttls () server . login ( username , password ) server . sendmail ( fromaddr , toaddrs , message . as_string ()) server . quit () logging . info ( 'Send Email Successful.' ) except : logging . info ( 'Send Email Failed.' ) def run ( self ): self . read_json () for u in self . url : self . get_news ( u ) self . valid_news () if len ( self . result ) != 0 : self . sent_email () if __name__ == '__main__' : moni = monitor_house_info () moni . run ()","tags":"IT笔记","url":"https://www.solarck.com/python-send-gmail.html"},{"title":"Pandas时间处理函数速度对比","text":"Pandas非常擅长处理时间序列，拥有多种处理时间序列的函数和方法，自己做了几个小测试，看看内置函数都能适配哪种格式、哪种情况，速度又有多快。 我用到的时间处理主要是对细粒度的时间重采样至粗粒度，之后再对重采样后的时间进行分组再进行后续操作，如求和、求平均或取最后值。 所以我就设计两个场景，第一个场景是对频率为秒的时间序列重采样至一分钟然后求平均；第二个场景就是对频率为秒的时间序列重采样至3分钟然后对新的时间序列取每个时间的最新值。 所以首先是要生成一组数据 import pandas as pd rng = pd . date_range ( start = '2018-04-07' , end = '2018-04-08' , freq = 's' ) df = pd . DataFrame ( pd . np . random . randn ( rng . size ), index = rng ) ser = pd . Series ( pd . np . random . randn ( rng . size ), index = rng ) df . columns = [ 'random' ] ser . name = 'random' df和ser分别对应DataFrame和Series，查看下数据格式 df.head() random 2018-04-07 00:00:00 0.163995 2018-04-07 00:00:01 0.756485 2018-04-07 00:00:02 -0.179441 2018-04-07 00:00:03 0.120944 2018-04-07 00:00:04 -1.558763 ser.tail() 2018-04-07 23:59:56 1.276893 2018-04-07 23:59:57 0.275050 2018-04-07 23:59:58 1.029358 2018-04-07 23:59:59 0.461299 2018-04-08 00:00:00 1.222731 Freq: S, Name: random, dtype: float64 接下来定义六个函数方法 def method1 ( data ): data . index = data . index . to_period ( 'Min' ) . to_timestamp () data . groupby ( data . index ) . mean () def method2 ( data ): data . index = pd . to_datetime ( data . index . strftime ( '%Y-%m- %d %H:%M' )) data . groupby ( data . index ) . mean () def method3 ( data ): ser_idx = pd . Series ( data . index ) data . index = pd . to_datetime ( ser_idx . apply ( lambda x : str ( x )[: - 2 ] + '00' )) data . groupby ( data . index ) . mean () def method4 ( data ): data . resample ( 'Min' ) . mean () def method5 ( data ): data . asfreq ( '3Min' , method = 'ffill' ) def method6 ( data ): data . resample ( '3Min' ) . last () 方法1-方法4适用于场景一，方法5-方法6适用于场景二，接下来具体说说这六个函数和为什么要这么设计场景。 方法1使用的是内置to_period方法转换周期，to_timestamp方法是为了后续操作使用timestamp更方便。 方法2对索引日期进行字符串格式化然后再用内置的to_datetime方法转换回日期格式达到重采样效果。 方法3看似复杂，其实和方法二类似，我之所以加上方法三是因为我本以为这个办法处理会慢很多，但是最终结果还是有点出乎我的意料的。 方法4是内置的resample方法 方法5是内置的asfreq方法 方法6还是内置的resample方法 可以看到resample方法适用范围最广，既可以对时间采取多种细粒度的操作，也能对重采样后的数据进行后续操作；而asfreq方法只能对数据进行重采样，无法进行复杂的后续操作，只能用向前/向后填充数值；to_period方法和字符串操作只能对时间进行整数采样，像45分钟，1小时30分这种更细腻的操作是不支持的。 比较速度 场景1 %timeit method1 ( df ) %timeit method2 ( df ) %timeit method3 ( df ) %timeit method4 ( df ) 16.4 ms ± 391 µ s per loop ( mean ± std . dev . of 7 runs , 10 loops each ) 439 ms ± 2.52 ms per loop ( mean ± std . dev . of 7 runs , 1 loop each ) 485 ms ± 10.8 ms per loop ( mean ± std . dev . of 7 runs , 1 loop each ) 2.13 ms ± 9.92 µ s per loop ( mean ± std . dev . of 7 runs , 100 loops each ) %timeit method1 ( ser ) %timeit method2 ( ser ) %timeit method3 ( ser ) %timeit method4 ( ser ) 23.8 ms ± 72.2 µ s per loop ( mean ± std . dev . of 7 runs , 10 loops each ) 446 ms ± 2.71 ms per loop ( mean ± std . dev . of 7 runs , 1 loop each ) 492 ms ± 3.61 ms per loop ( mean ± std . dev . of 7 runs , 1 loop each ) 1.63 ms ± 15.1 µ s per loop ( mean ± std . dev . of 7 runs , 1000 loops each ) 从上面对比数据得出结论，resample方法最快，to_period方法其次，两种字符串方法最慢，最快和最慢差距巨大。 场景2 %timeit method5 ( df ) %timeit method6 ( df ) 746 µ s ± 32.5 µ s per loop ( mean ± std . dev . of 7 runs , 1000 loops each ) 2.42 ms ± 24 µ s per loop ( mean ± std . dev . of 7 runs , 100 loops each ) %timeit method5 ( ser ) %timeit method6 ( ser ) 772 µ s ± 20.2 µ s per loop ( mean ± std . dev . of 7 runs , 1000 loops each ) 1.87 ms ± 50.5 µ s per loop ( mean ± std . dev . of 7 runs , 100 loops each ) 在场景二的测试中asfreq比resample快2倍多，如果不需要更多的后续操作，asfreq是很好的选择，否则resample方法更为全能。 下方的表格总结了几种方法的优劣： 函数 时间细粒度操作 时间分组后续操作 速度 asfreq X X ✓ resample ✓ ✓ ✓ to_period X ✓ ✓ 字符串 X ✓ X Pandas Offset Aliases Alias Description B business day frequency C custom business day frequency D calendar day frequency W weekly frequency M month end frequency SM semi-month end frequency (15th and end of month) BM business month end frequency CBM custom business month end frequency MS month start frequency SMS semi-month start frequency (1st and 15th) BMS business month start frequency CBMS custom business month start frequency Q quarter end frequency BQ business quarter end frequency QS quarter start frequency BQS business quarter start frequency A, Y year end frequency BA , BY business year end frequency AS , YS year start frequency BAS , BYS business year start frequency BH business hour frequency H hourly frequency T, min minutely frequency S secondly frequency L, ms milliseconds U, us microseconds N nanoseconds 参考 官方文档","tags":"IT笔记","url":"https://www.solarck.com/pandas-timeseries.html"},{"title":"用数据验证定投是否优于直接投资","text":"一直以来，定投的营销话术都是分批建仓，上涨时投资少降低成本，下跌时投资多赚取低估价值，但定投是否真的如宣传的那么美好？今天就用数据来模拟两种投资方式，看看孰优孰劣。 数据说明 本次实验使用三只ETF基金作为投资和定投标的，分别为华夏上证50ETF（510050），华泰柏瑞沪深300ETF（510300），广发中证500ETF（510510），时间区间为2013年5月27日至2018年6月7日。 先上图了解下这段时间ETF基金大致走势。 50ETF月线 500ETF周线 这段区间整体来看是上涨的，大盘股涨的多，小盘股涨得少。分段来看2013年中至2014年中，属于震荡行情，2014年中至2015年中是暴涨行情，2015年中至2016年初是暴跌行情，2016年初至2018年中行情分化，大盘股再次进入牛市，中盘股属于慢牛，小盘股是横盘震荡走势。 选择这个区间的行情，是因为这五年属于一个完整的周期，活跃时波动率大，行情过后的低迷时期波动率又小，是典型的中国股市。另外从长期来看，股票波动向上才应该是上市公司内在价值增长的表现。 当然，用这个区间的数据做分析是有一个缺点的，就是这三只ETF基金整体涨幅都在40%-50%之间，如果在一开始就持有至当前日期，那么一定是一次性直接投资要优于定投，不过放心，后面编程不会让这种事情发生，我会加入时间随机项，尽量减小整体上涨带来的影响。 开始实验 首先要导入用到的包 import tushare as ts import pandas as pd import random import matplotlib.pyplot as plt 之后利用tushare包，获取到三只ETF基金的收盘价，放入一个DataFrame内，这里我创建了一个类，主要是为了代码整洁考虑。 class AutoInvestmentPlan : def __init__ ( self ): plt . style . use ( 'ggplot' ) self . code_list = [ '510050' , '510300' , '510510' ] self . start_date = '2013-05-27' def get_etf_close ( self , code , start ): df = ts . get_k_data ( code , start = start ) df . set_index ( 'date' , inplace = True ) df . index = pd . to_datetime ( df . index ) return df . close def combin_to_df ( self ): close_list = [] for code in self . code_list : close_list . append ( self . get_etf_close ( code , self . start_date )) self . data = pd . concat ( close_list , axis = 1 ) self . data . columns = [ 'ETF50' , 'ETF300' , 'ETF500' ] def get_data ( self ): self . combin_to_df () self . monthly = self . data . asfreq ( 'M' , method = 'pad' ) self . weekly = self . data . asfreq ( 'W' , method = 'pad' ) 获取数据需要对类实例化，然后就得到了周和月数据 aip = AutoInvestmentPlan () aip . get_data () 这里需要等待几秒种，运行完成后就可以查看我们的数据了 周数据最新的5个收盘价 aip.weekly.tail() ETF50 ETF300 ETF500 date 2018-05-06 2.634 3.770 1.646 2018-05-13 2.716 3.873 1.667 2018-05-20 2.733 3.899 1.670 2018-05-27 2.654 3.811 1.649 2018-06-03 2.643 3.777 1.588 月收益率数据 aip.monthly.pct_change().describe() ETF50 ETF300 ETF500 count 60.000000 60.000000 60.000000 mean 0.008889 0.009014 0.009978 std 0.076945 0.073923 0.081489 min -0.182533 -0.224457 -0.279845 25% -0.022543 -0.018264 -0.025160 50% 0.002254 0.006061 0.015203 75% 0.035246 0.041125 0.049516 max 0.334728 0.254035 0.204142 接下来在定义用来比较的函数 def compare ( underlying , df_period , times = 15 , money = 1000 , plot = False ): df_period [ underlying ] . plot ( figsize = ( 9 , 6 ), title = '{} close price' . format ( underlying )) result = [] for _ in range ( times ): start = random . choice ( df_period . index [: int ( df_period . index . size / 2 )]) end = random . choice ( df_period . loc [ start + pd . Timedelta ( 18 , unit = 'M' ):] . index ) d = df_period . loc [ start : end ,:] cumsum_values = pd . DataFrame (( money / d . loc [:, underlying ])) cumsum_values . columns = [ 'share_period' ] cumsum_values [ 'share_cum' ] = cumsum_values [ 'share_period' ] . cumsum () cumsum_values [ 'values' ] = cumsum_values . share_cum * d . loc [:, underlying ] cumsum_values [ 'payoff' ] = [ i * money for i in range ( 1 , cumsum_values . index . size + 1 )] a = d . loc [:, underlying ] / d . loc [ d . index [ 0 ], underlying ] b = cumsum_values [ 'values' ] / cumsum_values [ 'payoff' ] b . name = 'AIP' df = pd . concat ([ a , b ], axis = 1 ) if plot : df . plot () exceed = pd . np . subtract ( * df . iloc [ - 1 ]) print ( 'from {} to {},dirctly invest ETF exceed AIP {:.2%}' . format ( start . strftime ( '%Y-%m- %d ' ), end . strftime ( '%Y-%m- %d ' ), exceed )) result . append ( exceed ) print ( ' \\n In {} times simulation,dirctly invest ETF exceed AIP \\' s mean is {:.2%}' . format ( times , pd . np . mean ( result ))) 这个比较函数从给定的ETF基金中的前半段时间随机选取一个日期，然后至少持有18个月，至多持有到当前日期，用这段时间的数据分别模拟在初始日期全部投资至结束和在区间内定投的收益情况。使用方法如下： #用每月定投1000元ETF50来比较 compare('ETF50',aip.monthly) #用每周定投1000元ETF500来比较 compare('ETF500',aip.weekly) #用每周定投500元ETF300来比较，共模拟10次，每次打印出走势对比图 compare('ETF300',aip.weekly,times=10,money=500,plot=True) 比较结果 compare('ETF50',aip.monthly) from 2015-09-30 to 2017-08-31,dirctly invest ETF exceed AIP 8.07% from 2014-07-31 to 2016-06-30,dirctly invest ETF exceed AIP 30.34% from 2014-09-30 to 2017-08-31,dirctly invest ETF exceed AIP 45.93% from 2015-05-31 to 2017-12-31,dirctly invest ETF exceed AIP -26.74% from 2014-03-31 to 2017-06-30,dirctly invest ETF exceed AIP 54.43% from 2015-09-30 to 2017-04-30,dirctly invest ETF exceed AIP 4.29% from 2015-07-31 to 2017-04-30,dirctly invest ETF exceed AIP -9.27% from 2014-06-30 to 2016-10-31,dirctly invest ETF exceed AIP 47.17% from 2015-07-31 to 2017-09-30,dirctly invest ETF exceed AIP -7.44% from 2014-10-31 to 2016-06-30,dirctly invest ETF exceed AIP 31.91% from 2014-07-31 to 2017-11-30,dirctly invest ETF exceed AIP 46.67% from 2015-06-30 to 2017-08-31,dirctly invest ETF exceed AIP -22.72% from 2014-04-30 to 2017-06-30,dirctly invest ETF exceed AIP 52.55% from 2014-04-30 to 2016-12-31,dirctly invest ETF exceed AIP 44.92% from 2014-04-30 to 2015-10-31,dirctly invest ETF exceed AIP 41.97% In 15 times simulation,dirctly invest ETF exceed AIP's mean is 22.81% compare('ETF500',aip.weekly) from 2014-09-28 to 2017-07-09,dirctly invest ETF exceed AIP 28.72% from 2014-06-08 to 2017-05-07,dirctly invest ETF exceed AIP 56.41% from 2015-05-10 to 2018-04-29,dirctly invest ETF exceed AIP -20.97% from 2014-02-09 to 2017-06-18,dirctly invest ETF exceed AIP 45.50% from 2014-06-29 to 2016-07-17,dirctly invest ETF exceed AIP 55.89% from 2015-07-12 to 2017-10-15,dirctly invest ETF exceed AIP -15.83% from 2013-06-02 to 2017-04-30,dirctly invest ETF exceed AIP 40.71% from 2014-06-08 to 2016-10-02,dirctly invest ETF exceed AIP 57.17% from 2014-05-11 to 2018-01-07,dirctly invest ETF exceed AIP 64.35% from 2014-09-07 to 2017-04-02,dirctly invest ETF exceed AIP 33.36% from 2014-07-20 to 2018-03-25,dirctly invest ETF exceed AIP 47.74% from 2014-03-30 to 2017-06-11,dirctly invest ETF exceed AIP 50.51% from 2013-09-15 to 2015-11-22,dirctly invest ETF exceed AIP 44.02% from 2015-03-08 to 2017-04-09,dirctly invest ETF exceed AIP 6.61% from 2015-04-05 to 2017-01-29,dirctly invest ETF exceed AIP -13.85% In 15 times simulation,dirctly invest ETF exceed AIP's mean is 32.02% 从上面的运行结果来看，把资金一次性全部投入比定投的平均收益是要高的，如果有兴趣，可以自己修改程序，改变开始和结束时间来验证结果，相信结论应该上面的相差不会太多。 当然，定投也不是一无是处，至少对于当前资金不足，只想从每月工资中拿出一部分来投资的人来说，还是一种很好的投资方式的。 完整代码 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import tushare as ts import pandas as pd import random import matplotlib.pyplot as plt class AutoInvestmentPlan : def __init__ ( self ): plt . style . use ( 'ggplot' ) self . code_list = [ '510050' , '510300' , '510510' ] self . start_date = '2013-05-27' def get_etf_close ( self , code , start ): df = ts . get_k_data ( code , start = start ) df . set_index ( 'date' , inplace = True ) df . index = pd . to_datetime ( df . index ) return df . close def combin_to_df ( self ): close_list = [] for code in self . code_list : close_list . append ( self . get_etf_close ( code , self . start_date )) self . data = pd . concat ( close_list , axis = 1 ) self . data . columns = [ 'ETF50' , 'ETF300' , 'ETF500' ] def get_data ( self ): self . combin_to_df () self . monthly = self . data . asfreq ( 'M' , method = 'pad' ) self . weekly = self . data . asfreq ( 'W' , method = 'pad' ) def compare ( underlying , df_period , times = 15 , money = 1000 , plot = False ): df_period [ underlying ] . plot ( figsize = ( 9 , 6 ), title = '{} close price' . format ( underlying )) result = [] for _ in range ( times ): start = random . choice ( df_period . index [: int ( df_period . index . size / 2 )]) end = random . choice ( df_period . loc [ start + pd . Timedelta ( 18 , unit = 'M' ):] . index ) d = df_period . loc [ start : end ,:] cumsum_values = pd . DataFrame (( money / d . loc [:, underlying ])) cumsum_values . columns = [ 'share_period' ] cumsum_values [ 'share_cum' ] = cumsum_values [ 'share_period' ] . cumsum () cumsum_values [ 'values' ] = cumsum_values . share_cum * d . loc [:, underlying ] cumsum_values [ 'payoff' ] = [ i * money for i in range ( 1 , cumsum_values . index . size + 1 )] a = d . loc [:, underlying ] / d . loc [ d . index [ 0 ], underlying ] b = cumsum_values [ 'values' ] / cumsum_values [ 'payoff' ] b . name = 'AIP' df = pd . concat ([ a , b ], axis = 1 ) if plot : df . plot () exceed = pd . np . subtract ( * df . iloc [ - 1 ]) print ( 'from {} to {},dirctly invest ETF exceed AIP {:.2%}' . format ( start . strftime ( '%Y-%m- %d ' ), end . strftime ( '%Y-%m- %d ' ), exceed )) result . append ( exceed ) print ( ' \\n In {} times simulation,dirctly invest ETF exceed AIP \\' s mean is {:.2%}' . format ( times , pd . np . mean ( result )))","tags":"金融笔记","url":"https://www.solarck.com/Is-AIP-better-than-ETF.html"},{"title":"git和github主要使用方法","text":"ssh和密钥 ssh-keygen -t rsa -b 4096 -C \"princelailai@gmail.com\" ：生成密钥 cat ~/.ssh/id_rsa.pub ：查看密钥 ssh -T git@github.com ：测试密钥是否可以正常登录 设置 git config --list ：列出当前repo所有设置 git config --global user.name \"princelai\" ：设置用户名 git config --global user.email \"princelailai@gmail.com\" ：设置E-mail echo \"# mydotfiles\" > README.md ： 基本操作 git init ：初始化，创建.git文件夹 git status ：查看当前工作区/缓存区状态 添加和提交 git add <文件> ：添加文件至缓存区 git commit -m \"说明\" ：从缓存区提交至仓库 git commit -am \"说明\" ：前面两种的合并版 git commit --amend \"说明\" ：替换掉上一次的提交 删除文件 git rm <文件> ：从repo中删除文件 git rm --cached <文件> ： 恢复 git checkout -- <文件> ：撤销文件工作区的修改 git reset HEAD <文件> ：撤销文件暂存区的修改，放回工作区 git reset --hard ad93b89 ：所有文件退回至指定版本 版本和日志 git log --oneline :简版log git log --graph ：带合并图形版log 远程仓库 git remote show origin ：查看远程仓库详情 git clone git-url ：从远程仓库克隆至本地 git remote add origin git-url ：关联远程和本地仓库 远程仓库的提交和拉取 git pull origin master ：把远程仓库拉取到本地仓库 git push origin master ：本地仓库推送至远程仓库，-u用于第一次关联 分支 git branch ：列出本地分支 git branch -r ：列出远程分支 git branch -a ：列出所有分支 git branch <分支> ：创建分支 git branch -d <分支> ：删除分支 git branch --set-upstream-to=origin/分支 分支 ：本地和远程分支关联 checkout git checkout 分支 ：切换到指定分支 git checkout -b 分支 ：创建并切换到分支 合并 git merge 分支 ：把指定分支合并到当前分支 git merge --no-ff -m \"说明\" 分支 ：禁止Fast forward模式，创建新的commit 参考 简书 廖雪峰 阮一峰","tags":"IT笔记","url":"https://www.solarck.com/git-and-github.html"},{"title":"用股票数据说明方差和标准差的特性","text":"方差 （Variance），应用数学里的专有名词。在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。一个实随机变量的方差也称为它的二阶矩或二阶中心动差，恰巧也是它的二阶累积量。这里把复杂说白了，就是将各个误差将之平方（而非取绝对值，使之肯定为正数），相加之后再除以总数，透过这样的方式来算出各个数据分布、零散（相对中心点）的程度。继续延伸的话，方差的算术平方根称为该随机变量的标准差（此为相对各个数据点间）。 标准差 （Standard Deviation， SD ），数学符号 \\(\\sigma\\) （sigma），在概率统计中最常使用作为测量一组数值的离散程度之用。标准差定义：为方差开算术平方根，反映组内个体间的离散程度；标准差与期望值之比为标准离差率。 1.定义 方差的定义如下公式： $$Var(X)=\\sigma&#94;2=E[(X-\\mu)&#94;2]$$ 对上式化简后可得到如下公式： $$\\sigma&#94;2=E[X&#94;2]-(E[X])&#94;2$$ 上面两个公式也可以写为下面这样： $$\\sigma&#94;2=\\frac{1}{N}\\sum_{i=1}&#94;{N}(x_i-\\mu)&#94;2=\\frac{(\\sum_{i=1}&#94;{N}x_i&#94;2-\\mu&#94;2)}{N}$$ 标准差的定义和公式和方差类似，就是对方差开平方根即可得到。 $$SD(X) = \\sigma = \\sqrt{E(X-E(X))&#94;2}$$ $$\\sigma = \\sqrt{\\frac{\\sum_{i=1}&#94;NX_i&#94;2}{N}-\\mu&#94;2}$$ $$\\sigma = \\sqrt{\\frac{(\\sum_{i=1}&#94;{N}x_i&#94;2-\\mu&#94;2)}{N}}$$ 2.准备数据 这里使用一个开源免费的股票数据模块tushare，获取贵州茅台的数据，并截取数据的前600天，把数据平分为2部分。获取后的数据格式为DataFrame。 import tushare as ts import numpy as np stock = ts . get_k_data ( '600519' ) stock = stock . iloc [: 600 , stock . columns . get_loc ( 'close' )] stock_part1 = stock . iloc [: stock . index . size // 2 ] stock_part2 = stock . iloc [ stock . index . size // 2 :] stock_part2 . index = range ( 300 ) 3.特性验证 对于方差的计算，我们可以把数据带入公式直接计算，python代码可以这样写，这里使用的是无偏估计，所以分母是N-1。 (( stock - stock . mean ()) ** 2 ) . sum () / ( stock . size - 1 ) 不过幸好Numpy和Pandas都提供了快速计算方差和标准差的方法，我们可以调用 var() 方法和 std() 方法使用。 性质1，一个常数被加至变量数列中，此数列方差不变。 $$Var(X+c) = Var(X)$$ $$SD(X+c) = SD(X)$$ In [ 1 ]: np . isclose (( stock + 5 ) . var (), stock . var ()) Out [ 1 ]: True #方差 In [ 2 ]: np . isclose (( stock + 8 ) . std (), stock . std ()) Out [ 2 ]: True #标准差 性质2，数列被放大一个常数倍，此数列的方差变大常数的平方倍 $$Var(cX) = c&#94;2 \\times Var(X)$$ $$SD(cX) = c \\times SD(X)$$ In [ 3 ]: np . isclose (( stock * 3 ) . var (), 3 ** 2 * stock . var ()) Out [ 3 ]: True #方差 In [ 4 ]: np . isclose (( stock * 4 ) . std (), 4 * stock . std ()) Out [ 4 ]: True #标准差 性质3，两个数列和（差）的方差 $$Var(aX+bY)=a&#94;2Var(X)+b&#94;2Var(Y)+2 \\times ab \\times Cov(X,Y)$$ $$Var(X-Y)=Var(X)+Var(Y)-2 \\times Cov(X,Y)$$ 标准差也有同样的性质 $$SD(X+Y)=\\sqrt{\\sigma&#94;2(X)+\\sigma&#94;2(Y)+2 \\times Cov(X,Y)}$$ In [ 5 ]: np . isclose (( stock_part1 + stock_part2 ) . var (), stock_part1 . var () + stock_part2 . var () + 2 * stock_part1 . cov ( stock_part2 )) Out [ 5 ]: True #方差 In [ 6 ]: np . isclose (( stock_part1 + stock_part2 ) . std (), np . sqrt ( stock_part1 . var () + stock_part2 . var () + 2 * stock_part1 . cov ( stock_part2 ))) Out [ 6 ]: True #标准差 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"金融笔记","url":"https://www.solarck.com/using-python-descript-vaiance-std.html"},{"title":"argparse模块简要用法","text":"argparse是Python用于解析命令行参数的模块，拥有更强大的功能、更友好的使用方法，用来替代原始的sys.argv。 argparse的大致用法如下： import argparse #导入模块 parser = argparse . ArgumentParser () #创建解析器 parser . add_argument () #添加参数 args = parser . parse_args () #解析参数 创建解析器时的可选参数很多，但没有特殊需求的情况下，默认参数就能很好的工作，所以这部分使用时临时查文档就能解决，不做过多记录。 这里仅记录下添加参数时的各种选项搭配，使用方法和选项如下： ArgumentParser . add_argument ( name or flags ... [, action ][, nargs ][, const ][, default ][, type ][, choices ][, required ][, help ][, metavar ][, dest ]) 每一个参数的含义： name or flags - 名称或选项字符串列表，例如。foo或-f, —foo。 action - 在命令行遇到此参数时要执行的操作的基本类型。 nargs - 应该使用的命令行参数数。 const - 某些动作和nargs选择所需的常量值。 default - 如果参数在命令行中不存在，则生成的值。 type - 应转换命令行参数的类型。 choices - 参数的允许值的容器。 required - 是否可以省略命令行选项（仅针对可选参数）。 help - 参数的简要说明。 metavar - 使用消息中参数的名称。 dest - 要添加到由parse_args()返回的对象的属性的名称。 1. name or flags 唯一的必填参数，可以创建位置参数（必填）和可选参数 parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( '-s' , '--save' ) parser . add_argument ( 'db' ) parser . parse_args ([ 'mysql' ]) Out [ 1 ]: Namespace ( db = 'mysql' , save = None ) 可选参数以 - 或 -- 开始，其余的均为位置参数 大部分情况下，未填的可选参数默认都是 None ,如果有 -- 开始的参数，则参数名以后面的字符串命名。 2. action action用于将命令和动作关联起来，常用的动作有如下几种： store - 仅保存参数后的值 store_const - 保存一个常量，由const参数给出 store_true - 给出参数则保存True值，不给出则为False store_false - 与上面相反 append - 把多次调用的值保存为一个列表 append_const - 把多次调用的常量保存为一个列表 count - 计算参数出现的次数 help - 打印帮助信息，默认自动添加 version - 打印版本信息，配合version选项使用 举几个例子 parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( '-sh' , '--show' , action = 'store_true' ) parser . parse_args ([ '-sh' ]) Out [ 2 ]: Namespace ( show = True ) 给出 -sh 参数，则show值为True parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( '-a1' , '--arg1' , action = 'store_const' , const = 0 ) parser . add_argument ( '-a2' , '--arg2' , action = 'store_const' , const = 10 , default = None ) parser . add_argument ( '-a3' , '--arg3' , action = 'store_const' , const = True , default = False ) parser . parse_args ([ '-a1' ]) Out [ 22 ]: Namespace ( arg1 = 0 , arg2 = None , arg3 = False ) 只给出a1参数，arg1的值为0。 没有给出a2参数，则a2的const没有被调用，使用default的值，当然default默认就是None，不写也可以。 a3参数其实就是store_true的实现。 const和default的区别就是当命令给出但是后面未接值时，使用const值，如果命令那个都没有给出，则使用default的值。 3. nargs nargs定义参数后面值的个数，可选值有几种： N (一个整数) ? * + 如果懂正则表达式，那nargs的参数就很好理解，这里就不做过多解释，不过要注意一点，当nargs=1的时候，他的行为和不给出nargs是不一样的，前者是一个列表，后者是一个值。直接看例子： parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( 'a1' , nargs = 2 ) parser . add_argument ( '-a2' , '--args2' , nargs = '?' , const = 0 ) parser . add_argument ( '-a3' , '--args3' , nargs = '+' , default = False ) parser . parse_args ([ 'a' , 'b' , '-a3' , 'aa' , 'bb' ]) Out [ 3 ]: Namespace ( a1 = [ 'a' , 'b' ], args2 = None , args3 = [ 'aa' , 'bb' ]) 结果很好理解，?可以配合const使用，其他的可以配合default使用，调用了就是一个列表，使用const或default就是一个值。 4. type和metavar 这两个参数偶尔能用到， parser = argparse . ArgumentParser ( prog = 'PROG' ) parser . add_argument ( 'a1' , type = float ) parser . add_argument ( '-a2' , '--args2' , metavar = 'STR' , default = argparse . SUPPRESS ) parser . parse_args ([ '3' ]) default=argparse.SUPPRESS 指出不给参数不存储变量，否则默认是None， 打印help说明看看 parser . print_help () usage : PROG [ - h ] [ - a2 STR ] a1 positional arguments : a1 optional arguments : - h , -- help show this help message and exit - a2 STR , -- args2 STR metavar仅改变了help说明里的变量名。 参考文档 官方文档 中文文档","tags":"IT笔记","url":"https://www.solarck.com/argparse-brief-usage.html"},{"title":"matplotlib中文字体配置","text":"matplotlib是Python的优秀绘图包，但是不论是在Windows还是Linux中默认都是不支持中文的，尤其是在Linux中设置更加复杂一点，设置方法如下： 首先我们需要获取到matplotlib配置文件的文件夹 python -c \"import matplotlib as mpl;print(mpl.get_configdir())\" /home/kevin/.config/matplotlib 然后需要一个默认的matplotlibrc文件用于修改 python -c \"import matplotlib as mpl;print(mpl.matplotlib_fname())\" /opt/anaconda/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc 这个位置会根据每个人安装位置不同而改变 然后把默认的rc文件拷贝到用户的配置文件夹 cp /opt/anaconda/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc ~/.config/matplotlib 之后的工作都是围绕这个rc文件，一般情况下只需要修改如下两个字段，把注释打开。 font.sans-serif : DejaVu Sans, Bitstream Vera Sans, Lucida Grande, Verdana, Geneva axes.unicode_minus : False 第一个字段负责中文字体显示，但是目前还没有，第二个负责正负号的显示。 由于matplotlib不使用系统字体，所以需要找到一个matplotlib支持的字体且已在系统中 fc-list :lang=zh |grep -i ttf 在shell中执行这个命令，就能找到几个字体，选择一个填到上面第一行第一个即可，通常建议选择 Droid Sans Fallback 修改好后重启整个python或ipython之后应该就可以看到中文，不过还是不可以的话可以使用下面方案二查找，这个方法出自 segmentfault 。 #! /usr/bin/env python # -*- coding: utf-8 -*- from matplotlib.font_manager import FontManager import subprocess fm = FontManager () mat_fonts = set ( f . name for f in fm . ttflist ) output = subprocess . check_output ( 'fc-list :lang=zh -f \"%{family} \\n \"' , shell = True ) output = output . decode ( 'utf8' ) zh_fonts = set ( f . split ( ',' , 1 )[ 0 ] for f in output . split ( ' \\n ' )) available = mat_fonts & zh_fonts print ( '*' * 10 , '可用的字体' , '*' * 10 ) for f in available : print ( f ) 如果不想使用rc文件来配置，那么可以在每次使用的时候在python中执行以下命令即可。 import matplotlib.pyplot as plt plt . rcParams [ 'font.sans-serif' ] = [ 'Droid Sans Fallback' ] plt . rcParams [ 'axes.unicode_minus' ] = False","tags":"IT笔记","url":"https://www.solarck.com/matplotlib-chinese-fonts.html"},{"title":"自定义Linux桌面启动程序","text":"Anaconda自带的Spyder是一个我最喜欢使用的IDE，对于科学计算有很好的支持，但是在Linux上它并没有自带.desktop文件，所以并不能在程序列表里找到，每次都要手动在命令行执行才能开启，非常不方便，所以决定自己搜索下方法，自己给它添加一个桌面快捷方式。 Linux的主流DE的桌面文件都遵循 桌面配置项规范 ，按照这个规范配置一个相应的.desktop文件，放在指定的目录即可，当然你也可以放在 ~/.local/share/applications/ 目录里，这样这个快捷方式只针对当前用户。 sudo vim / usr / share / applications / spyder . desktop [ Desktop Entry ] Version = 1.0 Type = Application Name = Spyder GenericName = Spyder Comment = Scientific Python Development EnviRonment TryExec =/ opt / anaconda / bin / spyder Exec =/ opt / anaconda / bin / spyder Categories = Development ; Science ; IDE ; Qt ; Icon =/ opt / anaconda / lib / python3 .6 / site - packages / spyder / images / spyder . png Terminal = false StartupNotify = false TryExec和Exec后面是可执行文件的地址，可以只写后者 Icon是快捷方式的图标，没有的话可以去网上下载一个或者根据自己喜好随便放一个。 更多内容可以参考这篇 Wiki","tags":"IT笔记","url":"https://www.solarck.com/linux-desktop-entries.html"},{"title":"VPS搭梯子指南——shadowsocks+ BBR +obfs","text":"近期开会导致墙越来越高，迫不得已升级自建的ss服务，由于shadowsocks原版已经停更，shadowsocksR也已经删库，所以就锁定libev版本。 注：以下服务器端内容请切换到root操作 1. 升级Debian 在升级之前，我需要先把服务器从Debian 8升级到Debian 9，如果不是Debian用户，或者不想升级的可以跳过，这一步不影响后续操作，但是部分代码可能需要修改。 首先要把Debian 8升级到最新版本 apt update apt upgrade 备份源列表 cp /etc/apt/sources.list /etc/apt/sources.list-jessie 修改源列表，把jessie 替换为 stretch vim /etc/apt/sources.list :s/jessie/stretch/g 再次更新升级 apt update apt upgrade apt dist-upgrade apt autoremove 2. 开启BBR 使用一键脚本安装并开启bbr，此步除OpenVZ以外的服务器都可以开启，跳过不影响后续内容。 wget --no-check-certificate https://raw.githubusercontent.com/princelai/across/master/bbr.sh chmod +x bbr.sh ./bbr.sh echo \"net.core.default_qdisc=fq\" >> /etc/sysctl.conf echo \"net.ipv4.tcp_congestion_control=bbr\" >> /etc/sysctl.conf sysctl -p lsmod | grep bbr 3. 安装shadowsocks-libev和simple-obfs混淆 需要从stretch-backports库中安装，非Debian 9用户请参考 文档 sh -c 'printf \"deb http://deb.debian.org/debian stretch-backports main\" > /etc/apt/sources.list.d/stretch-backports.list' apt update apt -t stretch-backports install shadowsocks-libev simple-obfs 4. 优化TCP网络 编辑sysctl文件，把下面的内容复制过去， 如果第二步中没有开启bbr，那么请删除前两行。 vim /etc/sysctl.conf net.core.default_qdisc = fq net.ipv4.tcp_congestion_control = bbr net.ipv4.tcp_fastopen = 3 fs.file-max = 1024000 net.core.rmem_max = 67108864 net.core.wmem_max = 67108864 net.core.rmem_default = 65536 net.core.wmem_default = 65536 net.core.netdev_max_backlog = 4096 net.core.somaxconn = 4096 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 0 net.ipv4.tcp_fin_timeout = 30 net.ipv4.tcp_keepalive_time = 1200 net.ipv4.ip_local_port_range = 10000 65000 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_rmem = 4096 87380 67108864 net.ipv4.tcp_wmem = 4096 65536 67108864 net.ipv4.tcp_mtu_probing = 1 net.ipv4.ip_forward = 1 更改保存后执行 sysctl -p 5. 配置服务端 修改配置 编辑配置文件，填上自己的密码，端口建议使用443，别的端口封杀的太严重。 关于加密方式，现在新版都支持AEAD加密方式，详细内容请点 这里 。 vim /etc/shadowsocks-libev/config.json { \"server\" : \"0.0.0.0\" , \"server_port\" : 443 , \"local_port\" : 1080 , \"password\" : \"\" , \"timeout\" : 100 , \"method\" : \"chacha20-ietf-poly1305\" , \"mode\" : \"tcp_and_udp\" , \"fast_open\" : true , \"plugin\" : \"obfs-server\" , \"plugin_opts\" : \"obfs=tls\" } 启动服务器端服务 如果已经按照上面编辑好配置文件，那么就可以直接用文件模式启动服务。 ss-server -c config.json #测试模式 systemctl start shadowsocks-libev #后台启动 systemctl enable shadowsocks-libev #开机启动 6. 配置客户端 Windows 下载 shadowsocks-windows 解压缩， 下载 simple-obfs 中的obfs-local.exe和msys-2.0.dll放到shadowsocks-windows目录中,obfs-host随意写一个中国可以访问的网站。 Linux 安装客户端和obfs sudo pacman -Syu sudo pacman -S shadowsocks-libev simple-obfs 开启本地服务 nohup ss-local -c config.json --plugin obfs-local --plugin-opts \"obfs=tls;obfs-host=cn.bing.com\" 开机启动，编辑启动文件 ，添加obfs混淆 vim /usr/lib/systemd/system/shadowsocks-libev@.service [Unit] Description = Shadowsocks-Libev Client Service After = network.target [Service] Type = simple User = nobody CapabilityBoundingSet = CAP_NET_BIND_SERVICE ExecStart = /usr/bin/ss-local -c /etc/shadowsocks/%i.json --plugin obfs-local --plugin-opts \"obfs=tls;obfs-host=cn.bing.com\" [Install] WantedBy = multi-user.target 编辑配置文件 vim /etc/shadowsocks/libev.json { \"server\" : \"你的服务器IP\" , \"server_port\" : 443 , \"local_address\" : \"127.0.0.1\" , \"local_port\" : 65509 , \"password\" : \"你的密码\" , \"timeout\" : 300 , \"method\" : \"chacha20-ietf-poly1305\" , \"fast_open\" : true , \"workers\" : 1 , \"prefer_ipv6\" : false } 开启服务，@后面要和json文件同名 sudo systemctl start shadowsocks-libev@libev sudo systemctl enable shadowsocks-libev@libev 其他内容请参考 Archlinux Wiki shadowsocks-qt5目前功能严重缺失，不建议使用，Linux平台最好是命令行模式 SwitchyOmega 是目前Chome最好的代理插件，可以在 官网 下载最新版本安装。 7.Android客户端配置 如果Android手机可以访问Google Play，则可以直接在上面搜shadowsocks和obfs分别安装后再配置即可。 如果当前手机不能访问Play，可以在github releases上分别下载 shadowsocks-android 和 simple-obfs-android ，安装后再配置自己的服务端信息。 8.socks5转http/https 实际使用中，经常会遇到命令行终端或本地程序需要代理，但是他们只支持http或https协议，所以就需要把socks5协议的代理转换协议，以Archlinux为例，方法也很简单。 安装privoxy sudo pacman -S privoxy 修改配置，找到如下两行打开注释，注意listen后的端口是未来我们要使用的端口，默认为8118，forward后的端口是shadowsocks使用的本地端口，这个依据自己的配置修改，不要忘了最后的\".\"。 sudo vim /etc/privoxy/config listen-address 127 .0.0.1:8118 forward-socks5t / 127 .0.0.1:65509 . 保存配置后，启动或重启服务 sudo systemctl start privoxy sudo systemctl restart privoxy 以后需要使用时，修改两个本地变量即可 echo https_proxy = 127 .0.0.1:8118 echo http_proxy = 127 .0.0.1:8118 9. 服务器端常用的命令 #测试ss+obfs是否正常启动 ss-server -c config.json --plugin obfs-server --plugin-opts \"obfs=http\" #查看obfs的进程编号 ps ax | grep obfs #查看ss的进程编号 ps ax | grep ss-server #查看ss监听端口 netstat -nlp | grep ss-server","tags":"IT笔记","url":"https://www.solarck.com/shadowsocks-libev.html"},{"title":"配置pip和conda","text":"首先需要确认已经安装Python环境，建议用于科学计算的朋友下载安装 Anaconda 或者 Miniconda 。 环境变量和启用配置 安装好后还需要把安装路径添加到系统环境变量 Linux用户查看系统环境变量 echo $PATH Windows用户查看系统环境变量 echo %PATH% 如果没有Anaconda的路径，就需要自己手动添加 Linux用户编辑~/.bashrc，在最后添加以下内容，注意自己修改安装路径 export PATH = \" $HOME /anaconda3/bin: $PATH \" 最后再执行 source ~/.bashrc 如果没有效果，可是尝试编辑~/.profile或 ~/.bash_profile文件 zsh或其他shell用户可以自行修改 Windows用户在cmd执行如下命令，如果不是默认安装到用户目录，需要手动修改下路径。如果创建了自定义env，那么root改为你自己的env名字。 set PATH = %USERPROFILE% \\A naconda3 ; %USERPROFILE% \\A naconda3 \\L ibrary \\b in ; %USERPROFILE% \\A naconda3 \\S cripts ; %PATH% activate root 更换源 conda官方源非常慢，甚至有时候经常无法连接；pip时快时慢，也是经常无法连接，所以我们把更新源换为国内的，加快更新速度。 pip 目前国内常用的pip源有 阿里云 和豆瓣。 Linux用户编辑~/.pip/pip.conf文件，粘贴以下内容 [global] index-url = https://pypi.doubanio.com/simple/ format = columns 或 [global] index-url = https://mirrors.aliyun.com/pypi/simple/ format = columns Windows用户编辑% USERPROFILE %\\pip\\pip.ini，没有就新建一个，内容和Linux一样。 conda 目前国内常用的conda源有 清华 和 中科大 两个 Linux和Windows用户执行下面的命令添加conda源 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes 更新 conda conda常用更新命令 conda update XXX #更新XXX包 conda update --all #更新所有可更新的包到最新 conda update conda #conda整体升级，并不一定最新，但是稳定 conda update anaconda #同上 conda其他常用命令 conda info #当前conda环境信息 conda install XXX #安装XXX conda search XXX #搜索XXX conda clean --all #清除无用包和缓存 conda list > a.txt #输出所有已安装的包 conda remove XXX #卸载XXX conda config --get channels #获取当前使用的源，配合下面的命令使用 conda config --remove channels https://XXX pip pip常用更新命令 pip search XXX #搜索 pip install XXX #安装 pip uninstall XXX #卸载 pip list > b.txt #列出所有已安装的包 pip list -o #列出所有可更新的包 pip show XXX #查看包的路径和依赖等信息","tags":"IT笔记","url":"https://www.solarck.com/config-pip-conda.html"},{"title":"openwrt开启Samba作为共享中心","text":"为Openwrt接入一个大U盘，不用来作共享中心的话实在没什么用处了，这也是为日后脱机BT下载提供一个基础。 安装 opkg update opkg install samba36-server luci-app-samba 配置文件 samba的配置文件只有两个，而且默认配置稍作修改就可以使用 root@openwrt:~# vi /etc/samba/smb.conf.template [ global ] netbios name = OpenWrt display charset = UTF-8 interfaces = 127 .0.0.1/8 lo 192 .168.3.1/24 fd73:3a9a:156::1/60 br-lan #内网IP server string = OpenWrt unix charset = UTF-8 workgroup = WORKGROUP browseable = yes deadtime = 30 domain master = yes encrypt passwords = true enable core files = no guest account = nobody #匿名用户 guest ok = yes #匿名用户 invalid users = root local master = yes load printers = no map to guest = Bad User max protocol = SMB2 min receivefile size = 16384 null passwords = yes #无需密码 obey pam restrictions = yes os level = 20 passdb backend = smbpasswd preferred master = yes printable = no security = user smb encrypt = disabled smb passwd file = /etc/samba/smbpasswd socket options = TCP_NODELAY IPTOS_LOWDELAY syslog = 2 use sendfile = yes writeable = yes #可写 root@openwrt:~# vi /etc/config/samba config samba option 'name' 'OpenWrt' option 'workgroup' 'WORKGROUP' option 'description' 'OpenWrt' option 'homes' '1' config 'sambashare' option 'name' 'Shares' option 'path' '/share' #samba所在目录 # option 'users' 'sandra' option 'guest_ok' 'yes' option 'create_mask' '0777' #所有用户可写 option 'dir_mask' '0777' #所有用户可写 option 'read_only' 'no' 我的配置是无需密码所有用户都可以访问，可上传可下载。 配置完还需要对目录进行权限提升 chmod a+w /share 或者更改文件夹用户 chown nobody:nobody /share 最后重启samba服务并开机启动 /etc/init.d/samba restart /etc/init.d/samba enable 访问 Windows用户很容易访问，在网络邻居（网络）里就可以看到WORKGROUP—> OPENWRT —>Share文件夹了，但是linux用户需要一些其他命令。 1. 安装g2sc yaourt -S g2sc 安装完就可以像Windows一样看到工作组和文件夹，但是只能下载，没有上传功能。 2. sambclient 安装工具 yaourt -S sambaclient 连接主机 kevin@kevin:pts/2 ~$: smbclient -L OPENWRT Enter kevins password: #没设密码直接回车 Sharename Type Comment --------- ---- ------- Shares Disk IPC$ IPC IPC Service ( OpenWrt ) Server Comment --------- ------- CHEN-PC OPENWRT OpenWrt Workgroup Master --------- ------- WORKGROUP OPENWRT kevin@kevin:pts/2 ~$: smbclient //OPENWRT/Shares #格式为//Servername/Sharename smb: \\> 出现了smb的命令行 get **** #下载某个文件 put **** #上传某个文件 更多命令输入?查看 3. mount挂载 kevin@kevin:pts/2 ~$: mkdir /mnt/samba kevin@kevin:pts/2 ~$: sudo mount -t cifs -l //OPENWRT/Shares /mnt/samba 完成 由于安装了Luci，所以开启了uhttp服务，把共享目录链接到/www目录同样可以通过浏览器直接下载，相当于把Samba目录同样做成了FTP目录。 kevin@kevin:pts/2 ~$: ln -s /share /www/share Samba共享就全部完成，之后再继续研究BT下载，配合Samba的共享就等于免费拥有了一个简版NAS。","tags":"IT笔记","url":"https://www.solarck.com/openwrt-samba.html"},{"title":"用extroot为openwrt扩充存储空间","text":"水星这款MW4350r内存为128M，运行很多程序都不在话下。但是却只提供了8M Flash存储空间，而路由器系统还占了1.9M，剩下的5M空间不足以支持安装很多软件，比如我在安装python的时候就报错提示存储空间不足，这确实很郁闷，但幸好Openwrt还提供了extroot方式来扩展存储，来发挥路由器和Openwrt系统的真正实力。 pivot-overlay还是pivot-root？ 我把两种方式都试过，pivot-overlay方式不能够把安装程序的位置移到USB存储装置上，但是pivot-root方式可以，所以我选择了后者。pivot-root方式使/覆盖掉了/overlay成为rootfs，我认为这种方式更接近原生的Linux系统。 而从官方的文档来看，目前pivot-root已经没有以前的缺点和不足，选择哪个已经是个人需求而不是技术问题了。 网上大部分文章帖子都是2009-2010年间的，所以大部分可能都是pivot-overlay的。如果对这部分不太理解，请仔细阅读官方Wiki： ExtRoot: How it works , The OpenWrt Flash Layout 安装必要的包 opkg update opkg install e2fsprogs kmod-usb-core kmod-usb2 kmod-usb-storage usbutils kmod-fs-ext4 block-mount e2fsprogs包提供了mkfs（mkfs.ext3,mkfs.ext4）、fsck等工具。 kmod-usb2只提供了USb2.0的驱动，如果你的是USB1.0（1.1）的，还需要单独安装驱动。 kmod-fs-ext4是用来挂载ext4文件系统的，如果你想使用ext3文件格式就安装相应的包。 usbutils不是必装，仅提供了lsusb命令。 格式化U盘 插好U盘后，先查看下是否被系统识别出来 root@openwrt: ~# lsusb Bus 001 Device 002 : ID 0781 :5571 SanDisk Corp. Cruzer Fit Bus 001 Device 001 : ID 1d6b:0002 Linux Foundation 2 .0 root hub root@openwrt: ~# ls /dev/sd* /dev/sda /dev/sda1 已经正确识别出来了，格式化系统为ext4 mkfs.ext4 /dev/sda1 挂载到当前系统 mount /dev/sda1 /mnt 创建一个128M的swap文件 dd if = /dev/zero of = /mnt/swap bs = 2048 count = 65536 mkswap /mnt/swap swapon /mnt/swap extroot 把/目录下的文件迁移到U盘,pivot-root方式，适用于Barrier Breaker（trunk）版本 mkdir -p /tmp/cproot mount --bind / /tmp/cproot tar -C /tmp/cproot -cvf - . | tar -C /mnt/ -xf - umount /tmp/cproot 编辑fstab 我的系统默认没有/etc/config/fstab文件，可以用命令生成一个 block detect > /etc/config/fstab 编辑这个文件，添加下面这段配置 config mount option target / option device /dev/sda1 option fstype ext4 option options rw,sync option enabled 1 option enabled_fsck 0 重启后，查看下空间，如果类似我这样就是成功了 root@openwrt: ~# df -h Filesystem Size Used Available Use% Mounted on rootfs 7 .2G 169 .9M 6 .7G 2 % / /dev/root 1 .8M 1 .8M 0 100 % /rom tmpfs 61 .7M 1 .0M 60 .7M 2 % /tmp /dev/sda1 7 .2G 169 .9M 6 .7G 2 % / tmpfs 512 .0K 0 512 .0K 0 % /dev 大功告成，现在系统空间足够大了，任你怎么安装怎么下载。","tags":"IT笔记","url":"https://www.solarck.com/openwrt-extroot.html"},{"title":"水星（Mercury）MW4530r刷Openwrt","text":"经过两天的不屑折腾，终于为我的Mw4530r安装上了Openwrt。从最后安装成功往回看，其实整个过程非常简单，但是由于是第一次接触，走了不少弯路，本应该一个小时就完成的工作，却整整花了我两天时间。再次发篇文章庆祝下，也给其他朋友一些参考。 下载文件 水星这款路由器是ar71xx芯片的，因为较新，所以还没有官方的稳定版。在Openwrt的 snapshots/trunk 目录搜索下载我们需要的刷机文件，一般情况一个型号有两个文件，一个名字里带factory，从其他固件系统刷Openwrt下载这个文件；一个名字带sysupgrade，已经是Openwrt系统的用此文件升级。 刷机 组装好路由器，接通电源，电脑网卡口连接路由器任意Lan口，打开浏览器访问http://192.168.1.1 就可以看见水星的原厂界面。利用原厂固件的升级功能，提交下载好的Openwrt刷机文件即可直接刷机，非常的方便。稍等片刻等待路由器自动重启，此时刷机完成。 初始化 Openwrt的固件是不带UI界面的，在安装用户界面之前，用户需要先进行简单的初始化工作。 使用telnet登陆路由器 telnet 192 .168.1.1 Linux系统自带命令，Windows用户需要在控制面板—>程序里面启用telnet功能。 修改登录密码 passwd 更改好密码后，dropbear（ssh）登录方式开启，telnet登录方式关闭。 退出telnet，用ssh方式登陆，Windows用户可以下载putty登陆 exit ssh root@192.168.1.1 到此我们已经成功初始化了Openwrt。 网络配置 强烈建议基础配置尤其是网络设置都使用CLI界面，切勿乱修改原始配置，我就在这里经历的惨痛的教训 我使用的是联通ADSL，所以需要拨号（pppoe）才能上网。 配置网络连接，修改wan部分 root@openwrt:~# vi /etc/config/network config interface 'wan' option ifname 'eth0.2' option proto 'pppoe' option username 'ISP提供的用户名' option password '密码' 或者用uci方式进行配置 uci set network.wan.proto = pppoe uci set network.wan.username = 'ISP提供的用户名' uci set network.wan.password = '密码' uci commit network ifup wan 配置wifi，根据你的路由器配置生成一个默认的配置文件 wifi detect > /etc/config/wireless 重启后，互联网和wifi都应该已经正常工作，wifi的密码和名称我们之后可以在UI界面修改，接下来安装用户界面。 用户界面 安装Luci opkg update opkg install luci luci-ssl luci-i18n-chinese 启动Luci服务 /etc/init.d/uhttpd start /etc/init.d/uhttpd enable 打开浏览器输入http://192.168.1.1 ，就可以进入WebUI界面了，现在就可以向普通路由器一样进行管理了。 小提示 1.MW4530r进入failsafe的方法是：路由器断电—>接通电源—>断续的按面板前的WPS键，直到SYS指示灯从慢闪变为快闪就是成功进入了failsafe模式了。 2.初始配置尽量用CLI方式配置（或uci），最好不要用WebUI。 3.不要乱动乱删配置文件，尤其是端口路由表（switch0）。 贴一张Openwrt的路由架构图，这张图帮助我理解了端口和路由的关系。","tags":"IT笔记","url":"https://www.solarck.com/install-openwrt-on-mw4530r.html"},{"title":"修复变砖的WNR2200","text":"手中有个NetGear WNR2200路由器，当初买这个就是看重可以刷机,但是买回来才发现只能刷DD-wrt，于是就刷了DD安心的用了半年。 最近看到Openwrt的trunk目录里有我这款机器的固件了，立刻操刀刷起。不幸的是刷完后telnet不通网关，failsafe模式也无法开启。无奈中发现NetGear官网提供了tftp小工具确实有效，让我变砖的路由器起死回生。 方法也很简单，官方文库里说明的很详细，这里简单记录下要点。 1.下载工具和路由器官方固件 2.打开下载好的软件，设置好网关192.168.1.1，加载下载好的固件，密码不用填 3.断开路由器电源10秒左右，之后接通电源，立刻点击软件上的Upgrade，等待修复完成 修复好后决定这个路由器还是老实的用DD-wrt，抛开扩展性和一些不是特别常用的功能， DD -wrt确实和所有路由器官方提供的固件一样人性化，当初刷完DD-wrt稳定运行了半年多，无重启、无断流，稳定性不是盖的。不想受Openwrt折磨的人可以在DD-wrt的 FTP目录 里按照日期和型号索引自己的路由器。 当然自己也不会放弃Openwrt，自己又入手了一个水星MW4530r，300元内可刷Openwrt的性价比神器,继续折腾Openwrt去了。 网件官方文库 工具下载地址 如果地址不可用，可Google tftp2.exe","tags":"IT笔记","url":"https://www.solarck.com/repair-wnr2200.html"}]}